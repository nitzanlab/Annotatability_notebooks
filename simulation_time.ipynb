{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-07T11:56:30.416361322Z",
     "start_time": "2024-07-07T11:56:30.168405169Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "from scipy import stats\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scanpy as sc\n",
    "from torch.utils.data import TensorDataset, DataLoader , WeightedRandomSampler\n",
    "\n",
    "from sklearn.metrics import roc_auc_score , pairwise_distances\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "epoch_num=50\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "import scipy.sparse as sp\n",
    "from numba import jit\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader , WeightedRandomSampler\n",
    "import torch.optim as optim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "sns.set_theme()\n",
    "# plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "plt.rcParams.update({'font.size': 18,\n",
    "                     'xtick.labelsize' : 18,\n",
    "                     'ytick.labelsize' : 18})\n",
    "\n",
    "mpl.rcParams['figure.facecolor'] = 'white'\n",
    "mpl.rcParams['axes.facecolor'] = 'white'\n",
    "\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "# plt.rcParams['lines.linewidth'] = 6  # Line thickness"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-07T11:56:30.418969646Z",
     "start_time": "2024-07-07T11:56:30.416561041Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [1, 2, 3, 4, 5]\n",
    "y = [2, 3, 5, 7, 11]\n",
    "\n",
    "plt.plot(x, y, label='Line plot')\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Example Plot')\n",
    "plt.legend()\n",
    "plt.savefig('example_plot.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-07T11:56:30.419151571Z",
     "start_time": "2024-07-07T11:56:30.416738758Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-07T11:56:30.419285625Z",
     "start_time": "2024-07-07T11:56:30.417221282Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "def modify_labels(orig_labeles, probability=0.1):\n",
    "    # Get the list of all possible labels\n",
    "    all_labels = list(set(orig_labeles))\n",
    "\n",
    "    # Create a list to store the modified labels\n",
    "    modified_labels = []\n",
    "\n",
    "    # Loop over the labels in the dataset\n",
    "    for label in orig_labeles:\n",
    "        # Generate a random number between 0 and 1\n",
    "        r = random.random()\n",
    "\n",
    "        # If the random number is smaller than the probability,\n",
    "        # modify the label by choosing a random label from the list of all labels,\n",
    "        # excluding the original label\n",
    "        if r < probability:\n",
    "            modified_label = random.choice([l for l in all_labels if l != label])\n",
    "        else:\n",
    "            modified_label = label\n",
    "\n",
    "        # Add the modified label to the list\n",
    "        modified_labels.append(modified_label)\n",
    "\n",
    "    # Create a DataFrame with the original and modified labels\n",
    "    df = pd.DataFrame({\"label\": orig_labeles, \"modified_label\": modified_labels})\n",
    "\n",
    "\n",
    "    return df , (np.where(df[\"label\"] != df[\"modified_label\"]))\n",
    "\n",
    "def one_hot_encode(labels):\n",
    "    \"\"\"\n",
    "    One-hot encodes an array of labels.\n",
    "\n",
    "    Args:\n",
    "        labels (numpy.ndarray): Array of labels.\n",
    "\n",
    "    Returns:\n",
    "        tuple: One-hot encoded array of labels, and a label encoder.\n",
    "    \"\"\"\n",
    "    values = np.array(labels)\n",
    "    print(values)\n",
    "    # integer encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    print(integer_encoded)\n",
    "    # binary encode\n",
    "    onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    # invert first example\n",
    "    inverted = label_encoder.inverse_transform([np.argmax(onehot_encoded[0, :])])\n",
    "    return onehot_encoded, label_encoder\n",
    "\n",
    "def create_intermediate_state(adata,key,labels):\n",
    "    bdata = adata.copy()\n",
    "    # change_weight= np.random.normal(0,0.5,adata.n_obs)\n",
    "    # change_weight  =np.clip(change_weight, a_max=0.5, a_min=0)\n",
    "    half_size = adata.n_obs // 2\n",
    "    zeros = np.zeros(half_size)\n",
    "    uniform_values = np.random.uniform(0.0, 1, adata.n_obs - half_size)\n",
    "    samples = np.concatenate((zeros, uniform_values))\n",
    "    np.random.shuffle(samples)\n",
    "    change_weight = samples\n",
    "    for i in range(adata.n_obs):\n",
    "        if adata.obs[key].iloc[i] in labels:\n",
    "            for label in labels:\n",
    "                if label != adata.obs[key].iloc[i]:\n",
    "                    adata_tmp= adata[adata.obs[key].isin([label])]\n",
    "                    bdata[i].X = (1-change_weight[i])*adata[i].X + change_weight[i]* adata_tmp[np.random.randint(adata_tmp.n_obs)].X\n",
    "        else:\n",
    "            change_weight[i]=0\n",
    "    bdata.obs['change_weight']+=change_weight\n",
    "    return bdata"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-07T11:56:30.419341130Z",
     "start_time": "2024-07-07T11:56:30.417350427Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, output_size,activation='relu',hidden_layers=2):\n",
    "        \"\"\"\n",
    "        Initializes a feedforward neural network with three fully-connected layers.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): Size of the input layer.\n",
    "            output_size (int): Size of the output layer.\n",
    "        \"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, int(input_size / 2))\n",
    "        self.fc2 = nn.Linear(int(input_size / 2), int(input_size / 4))\n",
    "        self.fc3 = nn.Linear(int(input_size / 4), int(input_size / 4))\n",
    "        self.fc4 = nn.Linear(int(input_size / 4), int(input_size / 4))\n",
    "        self.fc5 = nn.Linear(int(input_size / 4), output_size)\n",
    "        if activation == 'relu':\n",
    "            self.activation = F.relu\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = F.tanh\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = F.sigmoid\n",
    "        self.hidden_layers = hidden_layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Performs the forward pass of the neural network.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input data of shape (batch_size, input_size).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output data of shape (batch_size, output_size).\n",
    "        \"\"\"\n",
    "        if self.hidden_layers == 2:\n",
    "            x = self.fc1(x)\n",
    "            x = self.activation(x)\n",
    "            x = self.fc2(x)\n",
    "            x = self.activation(x)\n",
    "            x = self.fc5(x)\n",
    "        elif self.hidden_layers == 3:\n",
    "            x = self.fc1(x)\n",
    "            x = self.activation(x)\n",
    "            x = self.fc2(x)\n",
    "            x = self.activation(x)\n",
    "            x = self.fc3(x)\n",
    "            x = self.activation(x)\n",
    "            x = self.fc5(x)\n",
    "        elif self.hidden_layers == 4:\n",
    "            x = self.fc1(x)\n",
    "            x = self.activation(x)\n",
    "            x = self.fc2(x)\n",
    "            x = self.activation(x)\n",
    "            x = self.fc3(x)\n",
    "            x = self.activation(x)\n",
    "            x = self.fc4(x)\n",
    "            x = self.activation(x)\n",
    "            x = self.fc5(x)\n",
    "        output = F.log_softmax(x, dim=-1)\n",
    "        return output\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-07T11:56:30.419389612Z",
     "start_time": "2024-07-07T11:56:30.417522954Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "AnnData object with n_obs × n_vars = 50000 × 1000\n    obs: 'blobs', 'change_weight'\n    uns: 'pca', 'neighbors', 'umap'\n    obsm: 'X_pca', 'X_umap'\n    varm: 'PCs'\n    obsp: 'distances', 'connectivities'"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=1000\n",
    "p=50000\n",
    "adata = sc.datasets.blobs(n_variables=n,n_centers=4,cluster_std=1,n_observations=p)\n",
    "adata.obs['change_weight']= np.zeros(adata.n_obs)\n",
    "sc.pp.pca(adata)\n",
    "sc.pp.neighbors(adata)\n",
    "sc.tl.umap(adata)\n",
    "adata"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-07T11:57:06.884510021Z",
     "start_time": "2024-07-07T11:56:30.417614878Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "      label modified_label\n0         0              0\n1         0              0\n2         0              0\n3         0              0\n4         0              0\n...     ...            ...\n49995     3              3\n49996     2              2\n49997     0              0\n49998     1              1\n49999     2              2\n\n[50000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>modified_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "labeles = adata.obs['blobs']\n",
    "df , were_changed = modify_labels(labeles , probability=0.00)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-07T11:57:06.885838699Z",
     "start_time": "2024-07-07T11:57:06.884669153Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "y_train = adata.obs['blobs']\n",
    "y_train_indices = y_train.unique()\n",
    "class_sample_count = np.array(\n",
    "    [sum(y_train == t) for t in y_train_indices])\n",
    "weight = 1. / class_sample_count\n",
    "samples_weight= np.zeros(adata.n_obs)\n",
    "for i in range(adata.n_obs):\n",
    "    for j, t in enumerate(y_train_indices):\n",
    "        if adata.obs['blobs'].iloc[i]==t:\n",
    "            samples_weight[i]=weight[j]\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "# samples_weight"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-07T11:57:08.019395629Z",
     "start_time": "2024-07-07T11:57:06.884951959Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '0' '0' ... '0' '1' '2']\n",
      "[0 0 0 ... 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "one_hot_label , inverted_label = one_hot_encode(df['label'])\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-07T11:57:08.038347030Z",
     "start_time": "2024-07-07T11:57:08.028874024Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def probability_for_confidence(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Calculates the probability that the predicted class is correct, given the predicted class probabilities and the true class labels.\n",
    "\n",
    "    Args:\n",
    "        y_pred (torch.Tensor): Tensor of shape (batch_size, num_classes) with predicted class probabilities.\n",
    "        y_true (torch.Tensor): Tensor of shape (batch_size, num_classes) with true class labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Tensor of shape (batch_size,) with the probability that the predicted class is correct for each sample.\n",
    "    \"\"\"\n",
    "    prob = torch.exp(y_pred)\n",
    "    return torch.sum(prob * y_true, axis=1)\n",
    "import gc\n",
    "def probability_list_to_confidence_and_var(prob_list, n_obs, epoch_num):\n",
    "    \"\"\"\n",
    "    Calculates the confidence and variability of the predicted class probabilities, given a list of predicted class probabilities.\n",
    "\n",
    "    Args:\n",
    "        prob_list (list): List of tensors of shape (batch_size,) with predicted class probabilities.\n",
    "        n_obs (int): Number of observations.\n",
    "        epoch_num (int): Number of epochs.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Tensor of shape (batch_size,) with the confidence of the predicted class probabilities, and a tensor of shape (batch_size,) with the variability of the predicted class probabilities.\n",
    "    \"\"\"\n",
    "    confidence = torch.zeros(n_obs)\n",
    "    for i in range(epoch_num):\n",
    "        confidence += (prob_list[i])\n",
    "    confidence = confidence / epoch_num\n",
    "    variability = torch.zeros(n_obs)\n",
    "    for i in range(epoch_num):\n",
    "        variability += torch.square(confidence - (prob_list[i]))\n",
    "    variability = variability / epoch_num\n",
    "    variability = torch.sqrt(variability)\n",
    "    return confidence, variability\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-07T11:57:08.062103758Z",
     "start_time": "2024-07-07T11:57:08.037873322Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '0' '0' ... '0' '1' '2']\n",
      "[0 0 0 ... 0 1 2]\n",
      "[1,     2] loss: 0.250\n",
      "[1,    12] loss: 0.681\n",
      "[1,    22] loss: 0.516\n",
      "[1,    32] loss: 0.458\n",
      "[1,    42] loss: 0.448\n",
      "[1,    52] loss: 0.447\n",
      "[1,    62] loss: 0.461\n",
      "[1,    72] loss: 0.473\n",
      "[1,    82] loss: 0.471\n",
      "[1,    92] loss: 0.444\n",
      "[1,   102] loss: 0.436\n",
      "[1,   112] loss: 0.434\n",
      "[1,   122] loss: 0.439\n",
      "[1,   132] loss: 0.448\n",
      "[1,   142] loss: 0.465\n",
      "[1,   152] loss: 0.459\n",
      "[1,   162] loss: 0.453\n",
      "[1,   172] loss: 0.461\n",
      "[1,   182] loss: 0.450\n",
      "[1,   192] loss: 0.427\n",
      "[1,   202] loss: 0.414\n",
      "[1,   212] loss: 0.438\n",
      "[1,   222] loss: 0.443\n",
      "[1,   232] loss: 0.454\n",
      "[1,   242] loss: 0.454\n",
      "[1,   252] loss: 0.439\n",
      "[1,   262] loss: 0.443\n",
      "[1,   272] loss: 0.417\n",
      "[1,   282] loss: 0.435\n",
      "[1,   292] loss: 0.414\n",
      "[1,   302] loss: 0.419\n",
      "[1,   312] loss: 0.443\n",
      "[1,   322] loss: 0.421\n",
      "[1,   332] loss: 0.410\n",
      "[1,   342] loss: 0.460\n",
      "[1,   352] loss: 0.445\n",
      "[1,   362] loss: 0.423\n",
      "[1,   372] loss: 0.419\n",
      "[1,   382] loss: 0.430\n",
      "[2,     2] loss: 0.086\n",
      "[2,    12] loss: 0.439\n",
      "[2,    22] loss: 0.410\n",
      "[2,    32] loss: 0.441\n",
      "[2,    42] loss: 0.433\n",
      "[2,    52] loss: 0.409\n",
      "[2,    62] loss: 0.428\n",
      "[2,    72] loss: 0.400\n",
      "[2,    82] loss: 0.440\n",
      "[2,    92] loss: 0.435\n",
      "[2,   102] loss: 0.413\n",
      "[2,   112] loss: 0.429\n",
      "[2,   122] loss: 0.443\n",
      "[2,   132] loss: 0.410\n",
      "[2,   142] loss: 0.424\n",
      "[2,   152] loss: 0.428\n",
      "[2,   162] loss: 0.439\n",
      "[2,   172] loss: 0.403\n",
      "[2,   182] loss: 0.411\n",
      "[2,   192] loss: 0.428\n",
      "[2,   202] loss: 0.418\n",
      "[2,   212] loss: 0.420\n",
      "[2,   222] loss: 0.438\n",
      "[2,   232] loss: 0.396\n",
      "[2,   242] loss: 0.405\n",
      "[2,   252] loss: 0.421\n",
      "[2,   262] loss: 0.434\n",
      "[2,   272] loss: 0.436\n",
      "[2,   282] loss: 0.461\n",
      "[2,   292] loss: 0.445\n",
      "[2,   302] loss: 0.402\n",
      "[2,   312] loss: 0.427\n",
      "[2,   322] loss: 0.421\n",
      "[2,   332] loss: 0.432\n",
      "[2,   342] loss: 0.403\n",
      "[2,   352] loss: 0.414\n",
      "[2,   362] loss: 0.392\n",
      "[2,   372] loss: 0.409\n",
      "[2,   382] loss: 0.441\n",
      "[3,     2] loss: 0.089\n",
      "[3,    12] loss: 0.403\n",
      "[3,    22] loss: 0.408\n",
      "[3,    32] loss: 0.434\n",
      "[3,    42] loss: 0.420\n",
      "[3,    52] loss: 0.398\n",
      "[3,    62] loss: 0.412\n",
      "[3,    72] loss: 0.418\n",
      "[3,    82] loss: 0.404\n",
      "[3,    92] loss: 0.417\n",
      "[3,   102] loss: 0.423\n",
      "[3,   112] loss: 0.384\n",
      "[3,   122] loss: 0.401\n",
      "[3,   132] loss: 0.403\n",
      "[3,   142] loss: 0.413\n",
      "[3,   152] loss: 0.395\n",
      "[3,   162] loss: 0.423\n",
      "[3,   172] loss: 0.429\n",
      "[3,   182] loss: 0.411\n",
      "[3,   192] loss: 0.408\n",
      "[3,   202] loss: 0.436\n",
      "[3,   212] loss: 0.441\n",
      "[3,   222] loss: 0.421\n",
      "[3,   232] loss: 0.396\n",
      "[3,   242] loss: 0.417\n",
      "[3,   252] loss: 0.413\n",
      "[3,   262] loss: 0.413\n",
      "[3,   272] loss: 0.399\n",
      "[3,   282] loss: 0.404\n",
      "[3,   292] loss: 0.396\n",
      "[3,   302] loss: 0.432\n",
      "[3,   312] loss: 0.425\n",
      "[3,   322] loss: 0.419\n",
      "[3,   332] loss: 0.383\n",
      "[3,   342] loss: 0.404\n",
      "[3,   352] loss: 0.406\n",
      "[3,   362] loss: 0.377\n",
      "[3,   372] loss: 0.410\n",
      "[3,   382] loss: 0.406\n",
      "[4,     2] loss: 0.077\n",
      "[4,    12] loss: 0.404\n",
      "[4,    22] loss: 0.410\n",
      "[4,    32] loss: 0.404\n",
      "[4,    42] loss: 0.404\n",
      "[4,    52] loss: 0.411\n",
      "[4,    62] loss: 0.430\n",
      "[4,    72] loss: 0.408\n",
      "[4,    82] loss: 0.400\n",
      "[4,    92] loss: 0.420\n",
      "[4,   102] loss: 0.401\n",
      "[4,   112] loss: 0.422\n",
      "[4,   122] loss: 0.422\n",
      "[4,   132] loss: 0.404\n",
      "[4,   142] loss: 0.420\n",
      "[4,   152] loss: 0.403\n",
      "[4,   162] loss: 0.420\n",
      "[4,   172] loss: 0.408\n",
      "[4,   182] loss: 0.388\n",
      "[4,   192] loss: 0.411\n",
      "[4,   202] loss: 0.399\n",
      "[4,   212] loss: 0.372\n",
      "[4,   222] loss: 0.398\n",
      "[4,   232] loss: 0.395\n",
      "[4,   242] loss: 0.407\n",
      "[4,   252] loss: 0.388\n",
      "[4,   262] loss: 0.428\n",
      "[4,   272] loss: 0.401\n",
      "[4,   282] loss: 0.440\n",
      "[4,   292] loss: 0.416\n",
      "[4,   302] loss: 0.415\n",
      "[4,   312] loss: 0.393\n",
      "[4,   322] loss: 0.394\n",
      "[4,   332] loss: 0.432\n",
      "[4,   342] loss: 0.395\n",
      "[4,   352] loss: 0.406\n",
      "[4,   362] loss: 0.412\n",
      "[4,   372] loss: 0.415\n",
      "[4,   382] loss: 0.395\n",
      "[5,     2] loss: 0.078\n",
      "[5,    12] loss: 0.392\n",
      "[5,    22] loss: 0.361\n",
      "[5,    32] loss: 0.405\n",
      "[5,    42] loss: 0.412\n",
      "[5,    52] loss: 0.399\n",
      "[5,    62] loss: 0.417\n",
      "[5,    72] loss: 0.384\n",
      "[5,    82] loss: 0.426\n",
      "[5,    92] loss: 0.389\n",
      "[5,   102] loss: 0.413\n",
      "[5,   112] loss: 0.410\n",
      "[5,   122] loss: 0.397\n",
      "[5,   132] loss: 0.398\n",
      "[5,   142] loss: 0.413\n",
      "[5,   152] loss: 0.391\n",
      "[5,   162] loss: 0.370\n",
      "[5,   172] loss: 0.416\n",
      "[5,   182] loss: 0.412\n",
      "[5,   192] loss: 0.401\n",
      "[5,   202] loss: 0.388\n",
      "[5,   212] loss: 0.382\n",
      "[5,   222] loss: 0.404\n",
      "[5,   232] loss: 0.372\n",
      "[5,   242] loss: 0.408\n",
      "[5,   252] loss: 0.392\n",
      "[5,   262] loss: 0.402\n",
      "[5,   272] loss: 0.413\n",
      "[5,   282] loss: 0.421\n",
      "[5,   292] loss: 0.415\n",
      "[5,   302] loss: 0.408\n",
      "[5,   312] loss: 0.399\n",
      "[5,   322] loss: 0.419\n",
      "[5,   332] loss: 0.391\n",
      "[5,   342] loss: 0.393\n",
      "[5,   352] loss: 0.397\n",
      "[5,   362] loss: 0.401\n",
      "[5,   372] loss: 0.416\n",
      "[5,   382] loss: 0.400\n",
      "[6,     2] loss: 0.084\n",
      "[6,    12] loss: 0.406\n",
      "[6,    22] loss: 0.396\n",
      "[6,    32] loss: 0.424\n",
      "[6,    42] loss: 0.410\n",
      "[6,    52] loss: 0.377\n",
      "[6,    62] loss: 0.401\n",
      "[6,    72] loss: 0.401\n",
      "[6,    82] loss: 0.399\n",
      "[6,    92] loss: 0.407\n",
      "[6,   102] loss: 0.381\n",
      "[6,   112] loss: 0.393\n",
      "[6,   122] loss: 0.390\n",
      "[6,   132] loss: 0.408\n",
      "[6,   142] loss: 0.383\n",
      "[6,   152] loss: 0.403\n",
      "[6,   162] loss: 0.417\n",
      "[6,   172] loss: 0.399\n",
      "[6,   182] loss: 0.408\n",
      "[6,   192] loss: 0.395\n",
      "[6,   202] loss: 0.416\n",
      "[6,   212] loss: 0.406\n",
      "[6,   222] loss: 0.413\n",
      "[6,   232] loss: 0.380\n",
      "[6,   242] loss: 0.398\n",
      "[6,   252] loss: 0.403\n",
      "[6,   262] loss: 0.404\n",
      "[6,   272] loss: 0.380\n",
      "[6,   282] loss: 0.392\n",
      "[6,   292] loss: 0.384\n",
      "[6,   302] loss: 0.383\n",
      "[6,   312] loss: 0.414\n",
      "[6,   322] loss: 0.410\n",
      "[6,   332] loss: 0.411\n",
      "[6,   342] loss: 0.391\n",
      "[6,   352] loss: 0.389\n",
      "[6,   362] loss: 0.406\n",
      "[6,   372] loss: 0.408\n",
      "[6,   382] loss: 0.403\n",
      "[7,     2] loss: 0.074\n",
      "[7,    12] loss: 0.391\n",
      "[7,    22] loss: 0.410\n",
      "[7,    32] loss: 0.400\n",
      "[7,    42] loss: 0.410\n",
      "[7,    52] loss: 0.395\n",
      "[7,    62] loss: 0.395\n",
      "[7,    72] loss: 0.410\n",
      "[7,    82] loss: 0.386\n",
      "[7,    92] loss: 0.393\n",
      "[7,   102] loss: 0.402\n",
      "[7,   112] loss: 0.388\n",
      "[7,   122] loss: 0.404\n",
      "[7,   132] loss: 0.394\n",
      "[7,   142] loss: 0.370\n",
      "[7,   152] loss: 0.396\n",
      "[7,   162] loss: 0.378\n",
      "[7,   172] loss: 0.431\n",
      "[7,   182] loss: 0.390\n",
      "[7,   192] loss: 0.384\n",
      "[7,   202] loss: 0.405\n",
      "[7,   212] loss: 0.382\n",
      "[7,   222] loss: 0.379\n",
      "[7,   232] loss: 0.379\n",
      "[7,   242] loss: 0.390\n",
      "[7,   252] loss: 0.396\n",
      "[7,   262] loss: 0.388\n",
      "[7,   272] loss: 0.379\n",
      "[7,   282] loss: 0.372\n",
      "[7,   292] loss: 0.397\n",
      "[7,   302] loss: 0.387\n",
      "[7,   312] loss: 0.401\n",
      "[7,   322] loss: 0.408\n",
      "[7,   332] loss: 0.391\n",
      "[7,   342] loss: 0.386\n",
      "[7,   352] loss: 0.381\n",
      "[7,   362] loss: 0.398\n",
      "[7,   372] loss: 0.379\n",
      "[7,   382] loss: 0.386\n",
      "[8,     2] loss: 0.078\n",
      "[8,    12] loss: 0.395\n",
      "[8,    22] loss: 0.412\n",
      "[8,    32] loss: 0.410\n",
      "[8,    42] loss: 0.410\n",
      "[8,    52] loss: 0.398\n",
      "[8,    62] loss: 0.424\n",
      "[8,    72] loss: 0.393\n",
      "[8,    82] loss: 0.403\n",
      "[8,    92] loss: 0.380\n",
      "[8,   102] loss: 0.382\n",
      "[8,   112] loss: 0.395\n",
      "[8,   122] loss: 0.389\n",
      "[8,   132] loss: 0.378\n",
      "[8,   142] loss: 0.392\n",
      "[8,   152] loss: 0.404\n",
      "[8,   162] loss: 0.384\n",
      "[8,   172] loss: 0.402\n",
      "[8,   182] loss: 0.402\n",
      "[8,   192] loss: 0.390\n",
      "[8,   202] loss: 0.399\n",
      "[8,   212] loss: 0.394\n",
      "[8,   222] loss: 0.378\n",
      "[8,   232] loss: 0.375\n",
      "[8,   242] loss: 0.378\n",
      "[8,   252] loss: 0.406\n",
      "[8,   262] loss: 0.385\n",
      "[8,   272] loss: 0.414\n",
      "[8,   282] loss: 0.374\n",
      "[8,   292] loss: 0.414\n",
      "[8,   302] loss: 0.365\n",
      "[8,   312] loss: 0.405\n",
      "[8,   322] loss: 0.376\n",
      "[8,   332] loss: 0.386\n",
      "[8,   342] loss: 0.403\n",
      "[8,   352] loss: 0.401\n",
      "[8,   362] loss: 0.379\n",
      "[8,   372] loss: 0.386\n",
      "[8,   382] loss: 0.399\n",
      "[9,     2] loss: 0.071\n",
      "[9,    12] loss: 0.375\n",
      "[9,    22] loss: 0.367\n",
      "[9,    32] loss: 0.375\n",
      "[9,    42] loss: 0.410\n",
      "[9,    52] loss: 0.395\n",
      "[9,    62] loss: 0.381\n",
      "[9,    72] loss: 0.377\n",
      "[9,    82] loss: 0.401\n",
      "[9,    92] loss: 0.414\n",
      "[9,   102] loss: 0.376\n",
      "[9,   112] loss: 0.380\n",
      "[9,   122] loss: 0.395\n",
      "[9,   132] loss: 0.371\n",
      "[9,   142] loss: 0.420\n",
      "[9,   152] loss: 0.383\n",
      "[9,   162] loss: 0.390\n",
      "[9,   172] loss: 0.392\n",
      "[9,   182] loss: 0.386\n",
      "[9,   192] loss: 0.383\n",
      "[9,   202] loss: 0.389\n",
      "[9,   212] loss: 0.356\n",
      "[9,   222] loss: 0.375\n",
      "[9,   232] loss: 0.372\n",
      "[9,   242] loss: 0.368\n",
      "[9,   252] loss: 0.412\n",
      "[9,   262] loss: 0.403\n",
      "[9,   272] loss: 0.387\n",
      "[9,   282] loss: 0.401\n",
      "[9,   292] loss: 0.375\n",
      "[9,   302] loss: 0.384\n",
      "[9,   312] loss: 0.375\n",
      "[9,   322] loss: 0.420\n",
      "[9,   332] loss: 0.398\n",
      "[9,   342] loss: 0.382\n",
      "[9,   352] loss: 0.406\n",
      "[9,   362] loss: 0.387\n",
      "[9,   372] loss: 0.413\n",
      "[9,   382] loss: 0.372\n",
      "[10,     2] loss: 0.077\n",
      "[10,    12] loss: 0.381\n",
      "[10,    22] loss: 0.396\n",
      "[10,    32] loss: 0.389\n",
      "[10,    42] loss: 0.388\n",
      "[10,    52] loss: 0.365\n",
      "[10,    62] loss: 0.381\n",
      "[10,    72] loss: 0.394\n",
      "[10,    82] loss: 0.382\n",
      "[10,    92] loss: 0.386\n",
      "[10,   102] loss: 0.390\n",
      "[10,   112] loss: 0.388\n",
      "[10,   122] loss: 0.380\n",
      "[10,   132] loss: 0.377\n",
      "[10,   142] loss: 0.395\n",
      "[10,   152] loss: 0.392\n",
      "[10,   162] loss: 0.389\n",
      "[10,   172] loss: 0.417\n",
      "[10,   182] loss: 0.429\n",
      "[10,   192] loss: 0.377\n",
      "[10,   202] loss: 0.393\n",
      "[10,   212] loss: 0.421\n",
      "[10,   222] loss: 0.373\n",
      "[10,   232] loss: 0.410\n",
      "[10,   242] loss: 0.374\n",
      "[10,   252] loss: 0.419\n",
      "[10,   262] loss: 0.387\n",
      "[10,   272] loss: 0.391\n",
      "[10,   282] loss: 0.398\n",
      "[10,   292] loss: 0.398\n",
      "[10,   302] loss: 0.368\n",
      "[10,   312] loss: 0.384\n",
      "[10,   322] loss: 0.391\n",
      "[10,   332] loss: 0.368\n",
      "[10,   342] loss: 0.374\n",
      "[10,   352] loss: 0.373\n",
      "[10,   362] loss: 0.371\n",
      "[10,   372] loss: 0.386\n",
      "[10,   382] loss: 0.374\n",
      "[11,     2] loss: 0.075\n",
      "[11,    12] loss: 0.371\n",
      "[11,    22] loss: 0.387\n",
      "[11,    32] loss: 0.386\n",
      "[11,    42] loss: 0.379\n",
      "[11,    52] loss: 0.406\n",
      "[11,    62] loss: 0.398\n",
      "[11,    72] loss: 0.434\n",
      "[11,    82] loss: 0.389\n",
      "[11,    92] loss: 0.374\n",
      "[11,   102] loss: 0.359\n",
      "[11,   112] loss: 0.364\n",
      "[11,   122] loss: 0.374\n",
      "[11,   132] loss: 0.384\n",
      "[11,   142] loss: 0.399\n",
      "[11,   152] loss: 0.378\n",
      "[11,   162] loss: 0.387\n",
      "[11,   172] loss: 0.391\n",
      "[11,   182] loss: 0.392\n",
      "[11,   192] loss: 0.368\n",
      "[11,   202] loss: 0.425\n",
      "[11,   212] loss: 0.404\n",
      "[11,   222] loss: 0.384\n",
      "[11,   232] loss: 0.367\n",
      "[11,   242] loss: 0.410\n",
      "[11,   252] loss: 0.382\n",
      "[11,   262] loss: 0.393\n",
      "[11,   272] loss: 0.385\n",
      "[11,   282] loss: 0.375\n",
      "[11,   292] loss: 0.382\n",
      "[11,   302] loss: 0.396\n",
      "[11,   312] loss: 0.391\n",
      "[11,   322] loss: 0.368\n",
      "[11,   332] loss: 0.380\n",
      "[11,   342] loss: 0.394\n",
      "[11,   352] loss: 0.391\n",
      "[11,   362] loss: 0.388\n",
      "[11,   372] loss: 0.378\n",
      "[11,   382] loss: 0.408\n",
      "[12,     2] loss: 0.077\n",
      "[12,    12] loss: 0.395\n",
      "[12,    22] loss: 0.381\n",
      "[12,    32] loss: 0.390\n",
      "[12,    42] loss: 0.394\n",
      "[12,    52] loss: 0.389\n",
      "[12,    62] loss: 0.378\n",
      "[12,    72] loss: 0.382\n",
      "[12,    82] loss: 0.412\n",
      "[12,    92] loss: 0.386\n",
      "[12,   102] loss: 0.395\n",
      "[12,   112] loss: 0.396\n",
      "[12,   122] loss: 0.394\n",
      "[12,   132] loss: 0.361\n",
      "[12,   142] loss: 0.388\n",
      "[12,   152] loss: 0.370\n",
      "[12,   162] loss: 0.375\n",
      "[12,   172] loss: 0.380\n",
      "[12,   182] loss: 0.370\n",
      "[12,   192] loss: 0.406\n",
      "[12,   202] loss: 0.387\n",
      "[12,   212] loss: 0.369\n",
      "[12,   222] loss: 0.392\n",
      "[12,   232] loss: 0.381\n",
      "[12,   242] loss: 0.384\n",
      "[12,   252] loss: 0.382\n",
      "[12,   262] loss: 0.424\n",
      "[12,   272] loss: 0.391\n",
      "[12,   282] loss: 0.364\n",
      "[12,   292] loss: 0.374\n",
      "[12,   302] loss: 0.386\n",
      "[12,   312] loss: 0.379\n",
      "[12,   322] loss: 0.350\n",
      "[12,   332] loss: 0.393\n",
      "[12,   342] loss: 0.401\n",
      "[12,   352] loss: 0.380\n",
      "[12,   362] loss: 0.381\n",
      "[12,   372] loss: 0.372\n",
      "[12,   382] loss: 0.382\n",
      "[13,     2] loss: 0.071\n",
      "[13,    12] loss: 0.377\n",
      "[13,    22] loss: 0.398\n",
      "[13,    32] loss: 0.375\n",
      "[13,    42] loss: 0.373\n",
      "[13,    52] loss: 0.375\n",
      "[13,    62] loss: 0.386\n",
      "[13,    72] loss: 0.405\n",
      "[13,    82] loss: 0.384\n",
      "[13,    92] loss: 0.355\n",
      "[13,   102] loss: 0.390\n",
      "[13,   112] loss: 0.381\n",
      "[13,   122] loss: 0.368\n",
      "[13,   132] loss: 0.394\n",
      "[13,   142] loss: 0.383\n",
      "[13,   152] loss: 0.383\n",
      "[13,   162] loss: 0.388\n",
      "[13,   172] loss: 0.402\n",
      "[13,   182] loss: 0.376\n",
      "[13,   192] loss: 0.386\n",
      "[13,   202] loss: 0.353\n",
      "[13,   212] loss: 0.413\n",
      "[13,   222] loss: 0.407\n",
      "[13,   232] loss: 0.393\n",
      "[13,   242] loss: 0.393\n",
      "[13,   252] loss: 0.393\n",
      "[13,   262] loss: 0.386\n",
      "[13,   272] loss: 0.385\n",
      "[13,   282] loss: 0.391\n",
      "[13,   292] loss: 0.383\n",
      "[13,   302] loss: 0.405\n",
      "[13,   312] loss: 0.375\n",
      "[13,   322] loss: 0.396\n",
      "[13,   332] loss: 0.372\n",
      "[13,   342] loss: 0.413\n",
      "[13,   352] loss: 0.371\n",
      "[13,   362] loss: 0.396\n",
      "[13,   372] loss: 0.373\n",
      "[13,   382] loss: 0.361\n",
      "[14,     2] loss: 0.079\n",
      "[14,    12] loss: 0.389\n",
      "[14,    22] loss: 0.356\n",
      "[14,    32] loss: 0.366\n",
      "[14,    42] loss: 0.382\n",
      "[14,    52] loss: 0.393\n",
      "[14,    62] loss: 0.360\n",
      "[14,    72] loss: 0.386\n",
      "[14,    82] loss: 0.387\n",
      "[14,    92] loss: 0.383\n",
      "[14,   102] loss: 0.400\n",
      "[14,   112] loss: 0.403\n",
      "[14,   122] loss: 0.389\n",
      "[14,   132] loss: 0.395\n",
      "[14,   142] loss: 0.394\n",
      "[14,   152] loss: 0.393\n",
      "[14,   162] loss: 0.387\n",
      "[14,   172] loss: 0.379\n",
      "[14,   182] loss: 0.363\n",
      "[14,   192] loss: 0.380\n",
      "[14,   202] loss: 0.379\n",
      "[14,   212] loss: 0.391\n",
      "[14,   222] loss: 0.363\n",
      "[14,   232] loss: 0.365\n",
      "[14,   242] loss: 0.390\n",
      "[14,   252] loss: 0.371\n",
      "[14,   262] loss: 0.377\n",
      "[14,   272] loss: 0.403\n",
      "[14,   282] loss: 0.380\n",
      "[14,   292] loss: 0.407\n",
      "[14,   302] loss: 0.376\n",
      "[14,   312] loss: 0.376\n",
      "[14,   322] loss: 0.388\n",
      "[14,   332] loss: 0.406\n",
      "[14,   342] loss: 0.376\n",
      "[14,   352] loss: 0.367\n",
      "[14,   362] loss: 0.367\n",
      "[14,   372] loss: 0.387\n",
      "[14,   382] loss: 0.376\n",
      "[15,     2] loss: 0.073\n",
      "[15,    12] loss: 0.404\n",
      "[15,    22] loss: 0.383\n",
      "[15,    32] loss: 0.377\n",
      "[15,    42] loss: 0.375\n",
      "[15,    52] loss: 0.360\n",
      "[15,    62] loss: 0.354\n",
      "[15,    72] loss: 0.373\n",
      "[15,    82] loss: 0.388\n",
      "[15,    92] loss: 0.372\n",
      "[15,   102] loss: 0.367\n",
      "[15,   112] loss: 0.398\n",
      "[15,   122] loss: 0.392\n",
      "[15,   132] loss: 0.389\n",
      "[15,   142] loss: 0.390\n",
      "[15,   152] loss: 0.378\n",
      "[15,   162] loss: 0.387\n",
      "[15,   172] loss: 0.390\n",
      "[15,   182] loss: 0.365\n",
      "[15,   192] loss: 0.393\n",
      "[15,   202] loss: 0.362\n",
      "[15,   212] loss: 0.354\n",
      "[15,   222] loss: 0.371\n",
      "[15,   232] loss: 0.388\n",
      "[15,   242] loss: 0.375\n",
      "[15,   252] loss: 0.348\n",
      "[15,   262] loss: 0.394\n",
      "[15,   272] loss: 0.377\n",
      "[15,   282] loss: 0.367\n",
      "[15,   292] loss: 0.386\n",
      "[15,   302] loss: 0.385\n",
      "[15,   312] loss: 0.377\n",
      "[15,   322] loss: 0.391\n",
      "[15,   332] loss: 0.418\n",
      "[15,   342] loss: 0.388\n",
      "[15,   352] loss: 0.393\n",
      "[15,   362] loss: 0.404\n",
      "[15,   372] loss: 0.375\n",
      "[15,   382] loss: 0.395\n",
      "[16,     2] loss: 0.075\n",
      "[16,    12] loss: 0.394\n",
      "[16,    22] loss: 0.372\n",
      "[16,    32] loss: 0.381\n",
      "[16,    42] loss: 0.384\n",
      "[16,    52] loss: 0.390\n",
      "[16,    62] loss: 0.417\n",
      "[16,    72] loss: 0.379\n",
      "[16,    82] loss: 0.395\n",
      "[16,    92] loss: 0.381\n",
      "[16,   102] loss: 0.397\n",
      "[16,   112] loss: 0.367\n",
      "[16,   122] loss: 0.431\n",
      "[16,   132] loss: 0.392\n",
      "[16,   142] loss: 0.384\n",
      "[16,   152] loss: 0.365\n",
      "[16,   162] loss: 0.377\n",
      "[16,   172] loss: 0.369\n",
      "[16,   182] loss: 0.365\n",
      "[16,   192] loss: 0.397\n",
      "[16,   202] loss: 0.370\n",
      "[16,   212] loss: 0.371\n",
      "[16,   222] loss: 0.378\n",
      "[16,   232] loss: 0.395\n",
      "[16,   242] loss: 0.383\n",
      "[16,   252] loss: 0.363\n",
      "[16,   262] loss: 0.372\n",
      "[16,   272] loss: 0.362\n",
      "[16,   282] loss: 0.376\n",
      "[16,   292] loss: 0.385\n",
      "[16,   302] loss: 0.347\n",
      "[16,   312] loss: 0.390\n",
      "[16,   322] loss: 0.372\n",
      "[16,   332] loss: 0.393\n",
      "[16,   342] loss: 0.367\n",
      "[16,   352] loss: 0.405\n",
      "[16,   362] loss: 0.366\n",
      "[16,   372] loss: 0.394\n",
      "[16,   382] loss: 0.380\n",
      "[17,     2] loss: 0.078\n",
      "[17,    12] loss: 0.372\n",
      "[17,    22] loss: 0.381\n",
      "[17,    32] loss: 0.379\n",
      "[17,    42] loss: 0.388\n",
      "[17,    52] loss: 0.344\n",
      "[17,    62] loss: 0.382\n",
      "[17,    72] loss: 0.374\n",
      "[17,    82] loss: 0.377\n",
      "[17,    92] loss: 0.413\n",
      "[17,   102] loss: 0.358\n",
      "[17,   112] loss: 0.359\n",
      "[17,   122] loss: 0.374\n",
      "[17,   132] loss: 0.372\n",
      "[17,   142] loss: 0.354\n",
      "[17,   152] loss: 0.371\n",
      "[17,   162] loss: 0.376\n",
      "[17,   172] loss: 0.388\n",
      "[17,   182] loss: 0.400\n",
      "[17,   192] loss: 0.370\n",
      "[17,   202] loss: 0.375\n",
      "[17,   212] loss: 0.368\n",
      "[17,   222] loss: 0.379\n",
      "[17,   232] loss: 0.401\n",
      "[17,   242] loss: 0.371\n",
      "[17,   252] loss: 0.392\n",
      "[17,   262] loss: 0.388\n",
      "[17,   272] loss: 0.395\n",
      "[17,   282] loss: 0.380\n",
      "[17,   292] loss: 0.371\n",
      "[17,   302] loss: 0.376\n",
      "[17,   312] loss: 0.377\n",
      "[17,   322] loss: 0.392\n",
      "[17,   332] loss: 0.404\n",
      "[17,   342] loss: 0.375\n",
      "[17,   352] loss: 0.365\n",
      "[17,   362] loss: 0.382\n",
      "[17,   372] loss: 0.380\n",
      "[17,   382] loss: 0.393\n",
      "[18,     2] loss: 0.061\n",
      "[18,    12] loss: 0.400\n",
      "[18,    22] loss: 0.386\n",
      "[18,    32] loss: 0.374\n",
      "[18,    42] loss: 0.366\n",
      "[18,    52] loss: 0.381\n",
      "[18,    62] loss: 0.366\n",
      "[18,    72] loss: 0.394\n",
      "[18,    82] loss: 0.383\n",
      "[18,    92] loss: 0.371\n",
      "[18,   102] loss: 0.380\n",
      "[18,   112] loss: 0.387\n",
      "[18,   122] loss: 0.360\n",
      "[18,   132] loss: 0.381\n",
      "[18,   142] loss: 0.376\n",
      "[18,   152] loss: 0.362\n",
      "[18,   162] loss: 0.370\n",
      "[18,   172] loss: 0.374\n",
      "[18,   182] loss: 0.368\n",
      "[18,   192] loss: 0.351\n",
      "[18,   202] loss: 0.384\n",
      "[18,   212] loss: 0.354\n",
      "[18,   222] loss: 0.391\n",
      "[18,   232] loss: 0.370\n",
      "[18,   242] loss: 0.377\n",
      "[18,   252] loss: 0.371\n",
      "[18,   262] loss: 0.396\n",
      "[18,   272] loss: 0.365\n",
      "[18,   282] loss: 0.390\n",
      "[18,   292] loss: 0.371\n",
      "[18,   302] loss: 0.366\n",
      "[18,   312] loss: 0.362\n",
      "[18,   322] loss: 0.382\n",
      "[18,   332] loss: 0.370\n",
      "[18,   342] loss: 0.379\n",
      "[18,   352] loss: 0.371\n",
      "[18,   362] loss: 0.358\n",
      "[18,   372] loss: 0.389\n",
      "[18,   382] loss: 0.379\n",
      "[19,     2] loss: 0.079\n",
      "[19,    12] loss: 0.396\n",
      "[19,    22] loss: 0.373\n",
      "[19,    32] loss: 0.366\n",
      "[19,    42] loss: 0.359\n",
      "[19,    52] loss: 0.377\n",
      "[19,    62] loss: 0.397\n",
      "[19,    72] loss: 0.386\n",
      "[19,    82] loss: 0.361\n",
      "[19,    92] loss: 0.372\n",
      "[19,   102] loss: 0.371\n",
      "[19,   112] loss: 0.378\n",
      "[19,   122] loss: 0.358\n",
      "[19,   132] loss: 0.361\n",
      "[19,   142] loss: 0.362\n",
      "[19,   152] loss: 0.383\n",
      "[19,   162] loss: 0.380\n",
      "[19,   172] loss: 0.367\n",
      "[19,   182] loss: 0.374\n",
      "[19,   192] loss: 0.386\n",
      "[19,   202] loss: 0.363\n",
      "[19,   212] loss: 0.370\n",
      "[19,   222] loss: 0.378\n",
      "[19,   232] loss: 0.388\n",
      "[19,   242] loss: 0.384\n",
      "[19,   252] loss: 0.369\n",
      "[19,   262] loss: 0.355\n",
      "[19,   272] loss: 0.364\n",
      "[19,   282] loss: 0.373\n",
      "[19,   292] loss: 0.380\n",
      "[19,   302] loss: 0.383\n",
      "[19,   312] loss: 0.384\n",
      "[19,   322] loss: 0.409\n",
      "[19,   332] loss: 0.384\n",
      "[19,   342] loss: 0.367\n",
      "[19,   352] loss: 0.348\n",
      "[19,   362] loss: 0.360\n",
      "[19,   372] loss: 0.382\n",
      "[19,   382] loss: 0.365\n",
      "[20,     2] loss: 0.080\n",
      "[20,    12] loss: 0.386\n",
      "[20,    22] loss: 0.372\n",
      "[20,    32] loss: 0.380\n",
      "[20,    42] loss: 0.364\n",
      "[20,    52] loss: 0.383\n",
      "[20,    62] loss: 0.381\n",
      "[20,    72] loss: 0.385\n",
      "[20,    82] loss: 0.374\n",
      "[20,    92] loss: 0.365\n",
      "[20,   102] loss: 0.401\n",
      "[20,   112] loss: 0.407\n",
      "[20,   122] loss: 0.362\n",
      "[20,   132] loss: 0.352\n",
      "[20,   142] loss: 0.366\n",
      "[20,   152] loss: 0.371\n",
      "[20,   162] loss: 0.375\n",
      "[20,   172] loss: 0.353\n",
      "[20,   182] loss: 0.407\n",
      "[20,   192] loss: 0.359\n",
      "[20,   202] loss: 0.388\n",
      "[20,   212] loss: 0.364\n",
      "[20,   222] loss: 0.350\n",
      "[20,   232] loss: 0.384\n",
      "[20,   242] loss: 0.373\n",
      "[20,   252] loss: 0.352\n",
      "[20,   262] loss: 0.382\n",
      "[20,   272] loss: 0.375\n",
      "[20,   282] loss: 0.379\n",
      "[20,   292] loss: 0.353\n",
      "[20,   302] loss: 0.364\n",
      "[20,   312] loss: 0.370\n",
      "[20,   322] loss: 0.388\n",
      "[20,   332] loss: 0.363\n",
      "[20,   342] loss: 0.380\n",
      "[20,   352] loss: 0.363\n",
      "[20,   362] loss: 0.383\n",
      "[20,   372] loss: 0.350\n",
      "[20,   382] loss: 0.362\n",
      "[21,     2] loss: 0.072\n",
      "[21,    12] loss: 0.383\n",
      "[21,    22] loss: 0.351\n",
      "[21,    32] loss: 0.361\n",
      "[21,    42] loss: 0.383\n",
      "[21,    52] loss: 0.373\n",
      "[21,    62] loss: 0.368\n",
      "[21,    72] loss: 0.386\n",
      "[21,    82] loss: 0.382\n",
      "[21,    92] loss: 0.369\n",
      "[21,   102] loss: 0.380\n",
      "[21,   112] loss: 0.364\n",
      "[21,   122] loss: 0.386\n",
      "[21,   132] loss: 0.354\n",
      "[21,   142] loss: 0.398\n",
      "[21,   152] loss: 0.388\n",
      "[21,   162] loss: 0.386\n",
      "[21,   172] loss: 0.363\n",
      "[21,   182] loss: 0.351\n",
      "[21,   192] loss: 0.378\n",
      "[21,   202] loss: 0.364\n",
      "[21,   212] loss: 0.374\n",
      "[21,   222] loss: 0.368\n",
      "[21,   232] loss: 0.368\n",
      "[21,   242] loss: 0.368\n",
      "[21,   252] loss: 0.367\n",
      "[21,   262] loss: 0.366\n",
      "[21,   272] loss: 0.376\n",
      "[21,   282] loss: 0.386\n",
      "[21,   292] loss: 0.381\n",
      "[21,   302] loss: 0.373\n",
      "[21,   312] loss: 0.372\n",
      "[21,   322] loss: 0.359\n",
      "[21,   332] loss: 0.388\n",
      "[21,   342] loss: 0.377\n",
      "[21,   352] loss: 0.377\n",
      "[21,   362] loss: 0.398\n",
      "[21,   372] loss: 0.370\n",
      "[21,   382] loss: 0.402\n",
      "[22,     2] loss: 0.060\n",
      "[22,    12] loss: 0.346\n",
      "[22,    22] loss: 0.382\n",
      "[22,    32] loss: 0.369\n",
      "[22,    42] loss: 0.375\n",
      "[22,    52] loss: 0.378\n",
      "[22,    62] loss: 0.374\n",
      "[22,    72] loss: 0.386\n",
      "[22,    82] loss: 0.379\n",
      "[22,    92] loss: 0.396\n",
      "[22,   102] loss: 0.389\n",
      "[22,   112] loss: 0.364\n",
      "[22,   122] loss: 0.373\n",
      "[22,   132] loss: 0.353\n",
      "[22,   142] loss: 0.381\n",
      "[22,   152] loss: 0.386\n",
      "[22,   162] loss: 0.392\n",
      "[22,   172] loss: 0.366\n",
      "[22,   182] loss: 0.370\n",
      "[22,   192] loss: 0.362\n",
      "[22,   202] loss: 0.381\n",
      "[22,   212] loss: 0.375\n",
      "[22,   222] loss: 0.387\n",
      "[22,   232] loss: 0.382\n",
      "[22,   242] loss: 0.363\n",
      "[22,   252] loss: 0.388\n",
      "[22,   262] loss: 0.371\n",
      "[22,   272] loss: 0.377\n",
      "[22,   282] loss: 0.373\n",
      "[22,   292] loss: 0.363\n",
      "[22,   302] loss: 0.362\n",
      "[22,   312] loss: 0.371\n",
      "[22,   322] loss: 0.380\n",
      "[22,   332] loss: 0.352\n",
      "[22,   342] loss: 0.355\n",
      "[22,   352] loss: 0.376\n",
      "[22,   362] loss: 0.357\n",
      "[22,   372] loss: 0.384\n",
      "[22,   382] loss: 0.367\n",
      "[23,     2] loss: 0.073\n",
      "[23,    12] loss: 0.366\n",
      "[23,    22] loss: 0.373\n",
      "[23,    32] loss: 0.358\n",
      "[23,    42] loss: 0.361\n",
      "[23,    52] loss: 0.365\n",
      "[23,    62] loss: 0.361\n",
      "[23,    72] loss: 0.374\n",
      "[23,    82] loss: 0.387\n",
      "[23,    92] loss: 0.362\n",
      "[23,   102] loss: 0.371\n",
      "[23,   112] loss: 0.353\n",
      "[23,   122] loss: 0.364\n",
      "[23,   132] loss: 0.380\n",
      "[23,   142] loss: 0.365\n",
      "[23,   152] loss: 0.378\n",
      "[23,   162] loss: 0.379\n",
      "[23,   172] loss: 0.366\n",
      "[23,   182] loss: 0.374\n",
      "[23,   192] loss: 0.388\n",
      "[23,   202] loss: 0.358\n",
      "[23,   212] loss: 0.380\n",
      "[23,   222] loss: 0.366\n",
      "[23,   232] loss: 0.374\n",
      "[23,   242] loss: 0.386\n",
      "[23,   252] loss: 0.371\n",
      "[23,   262] loss: 0.371\n",
      "[23,   272] loss: 0.368\n",
      "[23,   282] loss: 0.353\n",
      "[23,   292] loss: 0.364\n",
      "[23,   302] loss: 0.371\n",
      "[23,   312] loss: 0.355\n",
      "[23,   322] loss: 0.372\n",
      "[23,   332] loss: 0.367\n",
      "[23,   342] loss: 0.376\n",
      "[23,   352] loss: 0.385\n",
      "[23,   362] loss: 0.370\n",
      "[23,   372] loss: 0.359\n",
      "[23,   382] loss: 0.378\n",
      "[24,     2] loss: 0.070\n",
      "[24,    12] loss: 0.367\n",
      "[24,    22] loss: 0.364\n",
      "[24,    32] loss: 0.373\n",
      "[24,    42] loss: 0.357\n",
      "[24,    52] loss: 0.348\n",
      "[24,    62] loss: 0.372\n",
      "[24,    72] loss: 0.365\n",
      "[24,    82] loss: 0.361\n",
      "[24,    92] loss: 0.364\n",
      "[24,   102] loss: 0.374\n",
      "[24,   112] loss: 0.343\n",
      "[24,   122] loss: 0.353\n",
      "[24,   132] loss: 0.378\n",
      "[24,   142] loss: 0.387\n",
      "[24,   152] loss: 0.391\n",
      "[24,   162] loss: 0.377\n",
      "[24,   172] loss: 0.380\n",
      "[24,   182] loss: 0.375\n",
      "[24,   192] loss: 0.359\n",
      "[24,   202] loss: 0.382\n",
      "[24,   212] loss: 0.381\n",
      "[24,   222] loss: 0.366\n",
      "[24,   232] loss: 0.376\n",
      "[24,   242] loss: 0.374\n",
      "[24,   252] loss: 0.378\n",
      "[24,   262] loss: 0.387\n",
      "[24,   272] loss: 0.370\n",
      "[24,   282] loss: 0.350\n",
      "[24,   292] loss: 0.369\n",
      "[24,   302] loss: 0.387\n",
      "[24,   312] loss: 0.376\n",
      "[24,   322] loss: 0.383\n",
      "[24,   332] loss: 0.365\n",
      "[24,   342] loss: 0.360\n",
      "[24,   352] loss: 0.377\n",
      "[24,   362] loss: 0.383\n",
      "[24,   372] loss: 0.396\n",
      "[24,   382] loss: 0.381\n",
      "[25,     2] loss: 0.065\n",
      "[25,    12] loss: 0.368\n",
      "[25,    22] loss: 0.366\n",
      "[25,    32] loss: 0.365\n",
      "[25,    42] loss: 0.379\n",
      "[25,    52] loss: 0.366\n",
      "[25,    62] loss: 0.388\n",
      "[25,    72] loss: 0.356\n",
      "[25,    82] loss: 0.357\n",
      "[25,    92] loss: 0.374\n",
      "[25,   102] loss: 0.373\n",
      "[25,   112] loss: 0.361\n",
      "[25,   122] loss: 0.373\n",
      "[25,   132] loss: 0.386\n",
      "[25,   142] loss: 0.348\n",
      "[25,   152] loss: 0.343\n",
      "[25,   162] loss: 0.369\n",
      "[25,   172] loss: 0.375\n",
      "[25,   182] loss: 0.394\n",
      "[25,   192] loss: 0.356\n",
      "[25,   202] loss: 0.359\n",
      "[25,   212] loss: 0.349\n",
      "[25,   222] loss: 0.374\n",
      "[25,   232] loss: 0.379\n",
      "[25,   242] loss: 0.372\n",
      "[25,   252] loss: 0.369\n",
      "[25,   262] loss: 0.401\n",
      "[25,   272] loss: 0.362\n",
      "[25,   282] loss: 0.382\n",
      "[25,   292] loss: 0.357\n",
      "[25,   302] loss: 0.364\n",
      "[25,   312] loss: 0.362\n",
      "[25,   322] loss: 0.386\n",
      "[25,   332] loss: 0.382\n",
      "[25,   342] loss: 0.391\n",
      "[25,   352] loss: 0.357\n",
      "[25,   362] loss: 0.383\n",
      "[25,   372] loss: 0.358\n",
      "[25,   382] loss: 0.369\n",
      "[26,     2] loss: 0.079\n",
      "[26,    12] loss: 0.384\n",
      "[26,    22] loss: 0.391\n",
      "[26,    32] loss: 0.362\n",
      "[26,    42] loss: 0.391\n",
      "[26,    52] loss: 0.370\n",
      "[26,    62] loss: 0.360\n",
      "[26,    72] loss: 0.367\n",
      "[26,    82] loss: 0.381\n",
      "[26,    92] loss: 0.369\n",
      "[26,   102] loss: 0.379\n",
      "[26,   112] loss: 0.374\n",
      "[26,   122] loss: 0.361\n",
      "[26,   132] loss: 0.377\n",
      "[26,   142] loss: 0.369\n",
      "[26,   152] loss: 0.376\n",
      "[26,   162] loss: 0.362\n",
      "[26,   172] loss: 0.352\n",
      "[26,   182] loss: 0.347\n",
      "[26,   192] loss: 0.374\n",
      "[26,   202] loss: 0.382\n",
      "[26,   212] loss: 0.361\n",
      "[26,   222] loss: 0.362\n",
      "[26,   232] loss: 0.385\n",
      "[26,   242] loss: 0.383\n",
      "[26,   252] loss: 0.368\n",
      "[26,   262] loss: 0.372\n",
      "[26,   272] loss: 0.359\n",
      "[26,   282] loss: 0.389\n",
      "[26,   292] loss: 0.377\n",
      "[26,   302] loss: 0.372\n",
      "[26,   312] loss: 0.346\n",
      "[26,   322] loss: 0.365\n",
      "[26,   332] loss: 0.371\n",
      "[26,   342] loss: 0.372\n",
      "[26,   352] loss: 0.356\n",
      "[26,   362] loss: 0.368\n",
      "[26,   372] loss: 0.357\n",
      "[26,   382] loss: 0.378\n",
      "[27,     2] loss: 0.066\n",
      "[27,    12] loss: 0.370\n",
      "[27,    22] loss: 0.358\n",
      "[27,    32] loss: 0.378\n",
      "[27,    42] loss: 0.373\n",
      "[27,    52] loss: 0.361\n",
      "[27,    62] loss: 0.347\n",
      "[27,    72] loss: 0.367\n",
      "[27,    82] loss: 0.370\n",
      "[27,    92] loss: 0.346\n",
      "[27,   102] loss: 0.361\n",
      "[27,   112] loss: 0.347\n",
      "[27,   122] loss: 0.365\n",
      "[27,   132] loss: 0.392\n",
      "[27,   142] loss: 0.383\n",
      "[27,   152] loss: 0.361\n",
      "[27,   162] loss: 0.379\n",
      "[27,   172] loss: 0.376\n",
      "[27,   182] loss: 0.364\n",
      "[27,   192] loss: 0.365\n",
      "[27,   202] loss: 0.381\n",
      "[27,   212] loss: 0.342\n",
      "[27,   222] loss: 0.389\n",
      "[27,   232] loss: 0.365\n",
      "[27,   242] loss: 0.357\n",
      "[27,   252] loss: 0.372\n",
      "[27,   262] loss: 0.361\n",
      "[27,   272] loss: 0.389\n",
      "[27,   282] loss: 0.382\n",
      "[27,   292] loss: 0.400\n",
      "[27,   302] loss: 0.390\n",
      "[27,   312] loss: 0.358\n",
      "[27,   322] loss: 0.386\n",
      "[27,   332] loss: 0.358\n",
      "[27,   342] loss: 0.383\n",
      "[27,   352] loss: 0.360\n",
      "[27,   362] loss: 0.374\n",
      "[27,   372] loss: 0.349\n",
      "[27,   382] loss: 0.386\n",
      "[28,     2] loss: 0.065\n",
      "[28,    12] loss: 0.347\n",
      "[28,    22] loss: 0.392\n",
      "[28,    32] loss: 0.358\n",
      "[28,    42] loss: 0.363\n",
      "[28,    52] loss: 0.382\n",
      "[28,    62] loss: 0.373\n",
      "[28,    72] loss: 0.372\n",
      "[28,    82] loss: 0.369\n",
      "[28,    92] loss: 0.363\n",
      "[28,   102] loss: 0.366\n",
      "[28,   112] loss: 0.373\n",
      "[28,   122] loss: 0.372\n",
      "[28,   132] loss: 0.374\n",
      "[28,   142] loss: 0.369\n",
      "[28,   152] loss: 0.366\n",
      "[28,   162] loss: 0.386\n",
      "[28,   172] loss: 0.370\n",
      "[28,   182] loss: 0.362\n",
      "[28,   192] loss: 0.344\n",
      "[28,   202] loss: 0.357\n",
      "[28,   212] loss: 0.342\n",
      "[28,   222] loss: 0.350\n",
      "[28,   232] loss: 0.377\n",
      "[28,   242] loss: 0.361\n",
      "[28,   252] loss: 0.346\n",
      "[28,   262] loss: 0.369\n",
      "[28,   272] loss: 0.369\n",
      "[28,   282] loss: 0.358\n",
      "[28,   292] loss: 0.353\n",
      "[28,   302] loss: 0.381\n",
      "[28,   312] loss: 0.394\n",
      "[28,   322] loss: 0.377\n",
      "[28,   332] loss: 0.389\n",
      "[28,   342] loss: 0.369\n",
      "[28,   352] loss: 0.361\n",
      "[28,   362] loss: 0.352\n",
      "[28,   372] loss: 0.382\n",
      "[28,   382] loss: 0.378\n",
      "[29,     2] loss: 0.067\n",
      "[29,    12] loss: 0.337\n",
      "[29,    22] loss: 0.371\n",
      "[29,    32] loss: 0.393\n",
      "[29,    42] loss: 0.367\n",
      "[29,    52] loss: 0.386\n",
      "[29,    62] loss: 0.365\n",
      "[29,    72] loss: 0.365\n",
      "[29,    82] loss: 0.366\n",
      "[29,    92] loss: 0.366\n",
      "[29,   102] loss: 0.359\n",
      "[29,   112] loss: 0.376\n",
      "[29,   122] loss: 0.340\n",
      "[29,   132] loss: 0.378\n",
      "[29,   142] loss: 0.372\n",
      "[29,   152] loss: 0.361\n",
      "[29,   162] loss: 0.372\n",
      "[29,   172] loss: 0.362\n",
      "[29,   182] loss: 0.379\n",
      "[29,   192] loss: 0.365\n",
      "[29,   202] loss: 0.341\n",
      "[29,   212] loss: 0.375\n",
      "[29,   222] loss: 0.368\n",
      "[29,   232] loss: 0.350\n",
      "[29,   242] loss: 0.355\n",
      "[29,   252] loss: 0.347\n",
      "[29,   262] loss: 0.377\n",
      "[29,   272] loss: 0.360\n",
      "[29,   282] loss: 0.370\n",
      "[29,   292] loss: 0.380\n",
      "[29,   302] loss: 0.362\n",
      "[29,   312] loss: 0.355\n",
      "[29,   322] loss: 0.370\n",
      "[29,   332] loss: 0.359\n",
      "[29,   342] loss: 0.390\n",
      "[29,   352] loss: 0.345\n",
      "[29,   362] loss: 0.377\n",
      "[29,   372] loss: 0.377\n",
      "[29,   382] loss: 0.382\n",
      "[30,     2] loss: 0.069\n",
      "[30,    12] loss: 0.367\n",
      "[30,    22] loss: 0.377\n",
      "[30,    32] loss: 0.368\n",
      "[30,    42] loss: 0.369\n",
      "[30,    52] loss: 0.359\n",
      "[30,    62] loss: 0.368\n",
      "[30,    72] loss: 0.339\n",
      "[30,    82] loss: 0.360\n",
      "[30,    92] loss: 0.369\n",
      "[30,   102] loss: 0.375\n",
      "[30,   112] loss: 0.341\n",
      "[30,   122] loss: 0.370\n",
      "[30,   132] loss: 0.383\n",
      "[30,   142] loss: 0.385\n",
      "[30,   152] loss: 0.381\n",
      "[30,   162] loss: 0.366\n",
      "[30,   172] loss: 0.377\n",
      "[30,   182] loss: 0.379\n",
      "[30,   192] loss: 0.375\n",
      "[30,   202] loss: 0.346\n",
      "[30,   212] loss: 0.368\n",
      "[30,   222] loss: 0.376\n",
      "[30,   232] loss: 0.379\n",
      "[30,   242] loss: 0.350\n",
      "[30,   252] loss: 0.362\n",
      "[30,   262] loss: 0.371\n",
      "[30,   272] loss: 0.361\n",
      "[30,   282] loss: 0.361\n",
      "[30,   292] loss: 0.362\n",
      "[30,   302] loss: 0.380\n",
      "[30,   312] loss: 0.366\n",
      "[30,   322] loss: 0.371\n",
      "[30,   332] loss: 0.388\n",
      "[30,   342] loss: 0.342\n",
      "[30,   352] loss: 0.384\n",
      "[30,   362] loss: 0.360\n",
      "[30,   372] loss: 0.360\n",
      "[30,   382] loss: 0.356\n",
      "[31,     2] loss: 0.078\n",
      "[31,    12] loss: 0.372\n",
      "[31,    22] loss: 0.371\n",
      "[31,    32] loss: 0.364\n",
      "[31,    42] loss: 0.358\n",
      "[31,    52] loss: 0.381\n",
      "[31,    62] loss: 0.369\n",
      "[31,    72] loss: 0.338\n",
      "[31,    82] loss: 0.356\n",
      "[31,    92] loss: 0.355\n",
      "[31,   102] loss: 0.361\n",
      "[31,   112] loss: 0.357\n",
      "[31,   122] loss: 0.356\n",
      "[31,   132] loss: 0.371\n",
      "[31,   142] loss: 0.351\n",
      "[31,   152] loss: 0.366\n",
      "[31,   162] loss: 0.345\n",
      "[31,   172] loss: 0.355\n",
      "[31,   182] loss: 0.357\n",
      "[31,   192] loss: 0.371\n",
      "[31,   202] loss: 0.361\n",
      "[31,   212] loss: 0.350\n",
      "[31,   222] loss: 0.378\n",
      "[31,   232] loss: 0.355\n",
      "[31,   242] loss: 0.364\n",
      "[31,   252] loss: 0.375\n",
      "[31,   262] loss: 0.379\n",
      "[31,   272] loss: 0.368\n",
      "[31,   282] loss: 0.370\n",
      "[31,   292] loss: 0.380\n",
      "[31,   302] loss: 0.358\n",
      "[31,   312] loss: 0.357\n",
      "[31,   322] loss: 0.346\n",
      "[31,   332] loss: 0.358\n",
      "[31,   342] loss: 0.355\n",
      "[31,   352] loss: 0.357\n",
      "[31,   362] loss: 0.372\n",
      "[31,   372] loss: 0.390\n",
      "[31,   382] loss: 0.367\n",
      "[32,     2] loss: 0.079\n",
      "[32,    12] loss: 0.370\n",
      "[32,    22] loss: 0.372\n",
      "[32,    32] loss: 0.375\n",
      "[32,    42] loss: 0.376\n",
      "[32,    52] loss: 0.363\n",
      "[32,    62] loss: 0.359\n",
      "[32,    72] loss: 0.369\n",
      "[32,    82] loss: 0.351\n",
      "[32,    92] loss: 0.369\n",
      "[32,   102] loss: 0.347\n",
      "[32,   112] loss: 0.351\n",
      "[32,   122] loss: 0.352\n",
      "[32,   132] loss: 0.356\n",
      "[32,   142] loss: 0.380\n",
      "[32,   152] loss: 0.368\n",
      "[32,   162] loss: 0.359\n",
      "[32,   172] loss: 0.371\n",
      "[32,   182] loss: 0.374\n",
      "[32,   192] loss: 0.345\n",
      "[32,   202] loss: 0.376\n",
      "[32,   212] loss: 0.366\n",
      "[32,   222] loss: 0.356\n",
      "[32,   232] loss: 0.359\n",
      "[32,   242] loss: 0.383\n",
      "[32,   252] loss: 0.345\n",
      "[32,   262] loss: 0.370\n",
      "[32,   272] loss: 0.363\n",
      "[32,   282] loss: 0.361\n",
      "[32,   292] loss: 0.378\n",
      "[32,   302] loss: 0.350\n",
      "[32,   312] loss: 0.362\n",
      "[32,   322] loss: 0.371\n",
      "[32,   332] loss: 0.363\n",
      "[32,   342] loss: 0.357\n",
      "[32,   352] loss: 0.357\n",
      "[32,   362] loss: 0.372\n",
      "[32,   372] loss: 0.379\n",
      "[32,   382] loss: 0.367\n",
      "[33,     2] loss: 0.069\n",
      "[33,    12] loss: 0.375\n",
      "[33,    22] loss: 0.359\n",
      "[33,    32] loss: 0.392\n",
      "[33,    42] loss: 0.367\n",
      "[33,    52] loss: 0.373\n",
      "[33,    62] loss: 0.350\n",
      "[33,    72] loss: 0.363\n",
      "[33,    82] loss: 0.380\n",
      "[33,    92] loss: 0.354\n",
      "[33,   102] loss: 0.355\n",
      "[33,   112] loss: 0.374\n",
      "[33,   122] loss: 0.368\n",
      "[33,   132] loss: 0.359\n",
      "[33,   142] loss: 0.383\n",
      "[33,   152] loss: 0.362\n",
      "[33,   162] loss: 0.346\n",
      "[33,   172] loss: 0.360\n",
      "[33,   182] loss: 0.361\n",
      "[33,   192] loss: 0.358\n",
      "[33,   202] loss: 0.381\n",
      "[33,   212] loss: 0.362\n",
      "[33,   222] loss: 0.348\n",
      "[33,   232] loss: 0.341\n",
      "[33,   242] loss: 0.379\n",
      "[33,   252] loss: 0.393\n",
      "[33,   262] loss: 0.352\n",
      "[33,   272] loss: 0.390\n",
      "[33,   282] loss: 0.375\n",
      "[33,   292] loss: 0.338\n",
      "[33,   302] loss: 0.378\n",
      "[33,   312] loss: 0.355\n",
      "[33,   322] loss: 0.360\n",
      "[33,   332] loss: 0.371\n",
      "[33,   342] loss: 0.385\n",
      "[33,   352] loss: 0.366\n",
      "[33,   362] loss: 0.344\n",
      "[33,   372] loss: 0.368\n",
      "[33,   382] loss: 0.352\n",
      "[34,     2] loss: 0.077\n",
      "[34,    12] loss: 0.366\n",
      "[34,    22] loss: 0.375\n",
      "[34,    32] loss: 0.376\n",
      "[34,    42] loss: 0.358\n",
      "[34,    52] loss: 0.341\n",
      "[34,    62] loss: 0.349\n",
      "[34,    72] loss: 0.351\n",
      "[34,    82] loss: 0.360\n",
      "[34,    92] loss: 0.356\n",
      "[34,   102] loss: 0.363\n",
      "[34,   112] loss: 0.374\n",
      "[34,   122] loss: 0.390\n",
      "[34,   132] loss: 0.365\n",
      "[34,   142] loss: 0.355\n",
      "[34,   152] loss: 0.357\n",
      "[34,   162] loss: 0.363\n",
      "[34,   172] loss: 0.373\n",
      "[34,   182] loss: 0.375\n",
      "[34,   192] loss: 0.364\n",
      "[34,   202] loss: 0.379\n",
      "[34,   212] loss: 0.384\n",
      "[34,   222] loss: 0.384\n",
      "[34,   232] loss: 0.365\n",
      "[34,   242] loss: 0.364\n",
      "[34,   252] loss: 0.369\n",
      "[34,   262] loss: 0.354\n",
      "[34,   272] loss: 0.374\n",
      "[34,   282] loss: 0.364\n",
      "[34,   292] loss: 0.363\n",
      "[34,   302] loss: 0.352\n",
      "[34,   312] loss: 0.351\n",
      "[34,   322] loss: 0.365\n",
      "[34,   332] loss: 0.382\n",
      "[34,   342] loss: 0.374\n",
      "[34,   352] loss: 0.357\n",
      "[34,   362] loss: 0.340\n",
      "[34,   372] loss: 0.364\n",
      "[34,   382] loss: 0.348\n",
      "[35,     2] loss: 0.075\n",
      "[35,    12] loss: 0.346\n",
      "[35,    22] loss: 0.350\n",
      "[35,    32] loss: 0.374\n",
      "[35,    42] loss: 0.342\n",
      "[35,    52] loss: 0.370\n",
      "[35,    62] loss: 0.349\n",
      "[35,    72] loss: 0.356\n",
      "[35,    82] loss: 0.365\n",
      "[35,    92] loss: 0.356\n",
      "[35,   102] loss: 0.344\n",
      "[35,   112] loss: 0.364\n",
      "[35,   122] loss: 0.376\n",
      "[35,   132] loss: 0.366\n",
      "[35,   142] loss: 0.341\n",
      "[35,   152] loss: 0.368\n",
      "[35,   162] loss: 0.369\n",
      "[35,   172] loss: 0.388\n",
      "[35,   182] loss: 0.359\n",
      "[35,   192] loss: 0.342\n",
      "[35,   202] loss: 0.375\n",
      "[35,   212] loss: 0.367\n",
      "[35,   222] loss: 0.374\n",
      "[35,   232] loss: 0.349\n",
      "[35,   242] loss: 0.372\n",
      "[35,   252] loss: 0.362\n",
      "[35,   262] loss: 0.359\n",
      "[35,   272] loss: 0.380\n",
      "[35,   282] loss: 0.356\n",
      "[35,   292] loss: 0.366\n",
      "[35,   302] loss: 0.367\n",
      "[35,   312] loss: 0.377\n",
      "[35,   322] loss: 0.364\n",
      "[35,   332] loss: 0.347\n",
      "[35,   342] loss: 0.367\n",
      "[35,   352] loss: 0.367\n",
      "[35,   362] loss: 0.366\n",
      "[35,   372] loss: 0.378\n",
      "[35,   382] loss: 0.375\n",
      "[36,     2] loss: 0.069\n",
      "[36,    12] loss: 0.383\n",
      "[36,    22] loss: 0.387\n",
      "[36,    32] loss: 0.370\n",
      "[36,    42] loss: 0.357\n",
      "[36,    52] loss: 0.359\n",
      "[36,    62] loss: 0.385\n",
      "[36,    72] loss: 0.355\n",
      "[36,    82] loss: 0.369\n",
      "[36,    92] loss: 0.360\n",
      "[36,   102] loss: 0.366\n",
      "[36,   112] loss: 0.358\n",
      "[36,   122] loss: 0.356\n",
      "[36,   132] loss: 0.356\n",
      "[36,   142] loss: 0.366\n",
      "[36,   152] loss: 0.364\n",
      "[36,   162] loss: 0.384\n",
      "[36,   172] loss: 0.347\n",
      "[36,   182] loss: 0.355\n",
      "[36,   192] loss: 0.370\n",
      "[36,   202] loss: 0.364\n",
      "[36,   212] loss: 0.367\n",
      "[36,   222] loss: 0.362\n",
      "[36,   232] loss: 0.350\n",
      "[36,   242] loss: 0.381\n",
      "[36,   252] loss: 0.385\n",
      "[36,   262] loss: 0.363\n",
      "[36,   272] loss: 0.373\n",
      "[36,   282] loss: 0.369\n",
      "[36,   292] loss: 0.377\n",
      "[36,   302] loss: 0.368\n",
      "[36,   312] loss: 0.367\n",
      "[36,   322] loss: 0.358\n",
      "[36,   332] loss: 0.363\n",
      "[36,   342] loss: 0.358\n",
      "[36,   352] loss: 0.356\n",
      "[36,   362] loss: 0.369\n",
      "[36,   372] loss: 0.354\n",
      "[36,   382] loss: 0.387\n",
      "[37,     2] loss: 0.070\n",
      "[37,    12] loss: 0.351\n",
      "[37,    22] loss: 0.373\n",
      "[37,    32] loss: 0.356\n",
      "[37,    42] loss: 0.354\n",
      "[37,    52] loss: 0.350\n",
      "[37,    62] loss: 0.373\n",
      "[37,    72] loss: 0.361\n",
      "[37,    82] loss: 0.380\n",
      "[37,    92] loss: 0.348\n",
      "[37,   102] loss: 0.371\n",
      "[37,   112] loss: 0.358\n",
      "[37,   122] loss: 0.362\n",
      "[37,   132] loss: 0.339\n",
      "[37,   142] loss: 0.357\n",
      "[37,   152] loss: 0.357\n",
      "[37,   162] loss: 0.347\n",
      "[37,   172] loss: 0.348\n",
      "[37,   182] loss: 0.373\n",
      "[37,   192] loss: 0.366\n",
      "[37,   202] loss: 0.364\n",
      "[37,   212] loss: 0.349\n",
      "[37,   222] loss: 0.380\n",
      "[37,   232] loss: 0.335\n",
      "[37,   242] loss: 0.370\n",
      "[37,   252] loss: 0.346\n",
      "[37,   262] loss: 0.382\n",
      "[37,   272] loss: 0.389\n",
      "[37,   282] loss: 0.370\n",
      "[37,   292] loss: 0.356\n",
      "[37,   302] loss: 0.360\n",
      "[37,   312] loss: 0.369\n",
      "[37,   322] loss: 0.378\n",
      "[37,   332] loss: 0.346\n",
      "[37,   342] loss: 0.347\n",
      "[37,   352] loss: 0.377\n",
      "[37,   362] loss: 0.349\n",
      "[37,   372] loss: 0.351\n",
      "[37,   382] loss: 0.363\n",
      "[38,     2] loss: 0.068\n",
      "[38,    12] loss: 0.375\n",
      "[38,    22] loss: 0.359\n",
      "[38,    32] loss: 0.360\n",
      "[38,    42] loss: 0.360\n",
      "[38,    52] loss: 0.377\n",
      "[38,    62] loss: 0.371\n",
      "[38,    72] loss: 0.388\n",
      "[38,    82] loss: 0.366\n",
      "[38,    92] loss: 0.374\n",
      "[38,   102] loss: 0.355\n",
      "[38,   112] loss: 0.369\n",
      "[38,   122] loss: 0.375\n",
      "[38,   132] loss: 0.347\n",
      "[38,   142] loss: 0.373\n",
      "[38,   152] loss: 0.356\n",
      "[38,   162] loss: 0.378\n",
      "[38,   172] loss: 0.353\n",
      "[38,   182] loss: 0.353\n",
      "[38,   192] loss: 0.374\n",
      "[38,   202] loss: 0.354\n",
      "[38,   212] loss: 0.353\n",
      "[38,   222] loss: 0.359\n",
      "[38,   232] loss: 0.367\n",
      "[38,   242] loss: 0.365\n",
      "[38,   252] loss: 0.366\n",
      "[38,   262] loss: 0.361\n",
      "[38,   272] loss: 0.365\n",
      "[38,   282] loss: 0.375\n",
      "[38,   292] loss: 0.368\n",
      "[38,   302] loss: 0.368\n",
      "[38,   312] loss: 0.359\n",
      "[38,   322] loss: 0.351\n",
      "[38,   332] loss: 0.358\n",
      "[38,   342] loss: 0.343\n",
      "[38,   352] loss: 0.349\n",
      "[38,   362] loss: 0.374\n",
      "[38,   372] loss: 0.368\n",
      "[38,   382] loss: 0.357\n",
      "[39,     2] loss: 0.072\n",
      "[39,    12] loss: 0.368\n",
      "[39,    22] loss: 0.361\n",
      "[39,    32] loss: 0.376\n",
      "[39,    42] loss: 0.347\n",
      "[39,    52] loss: 0.386\n",
      "[39,    62] loss: 0.352\n",
      "[39,    72] loss: 0.352\n",
      "[39,    82] loss: 0.374\n",
      "[39,    92] loss: 0.365\n",
      "[39,   102] loss: 0.351\n",
      "[39,   112] loss: 0.377\n",
      "[39,   122] loss: 0.370\n",
      "[39,   132] loss: 0.367\n",
      "[39,   142] loss: 0.354\n",
      "[39,   152] loss: 0.353\n",
      "[39,   162] loss: 0.355\n",
      "[39,   172] loss: 0.378\n",
      "[39,   182] loss: 0.358\n",
      "[39,   192] loss: 0.388\n",
      "[39,   202] loss: 0.332\n",
      "[39,   212] loss: 0.382\n",
      "[39,   222] loss: 0.354\n",
      "[39,   232] loss: 0.365\n",
      "[39,   242] loss: 0.371\n",
      "[39,   252] loss: 0.340\n",
      "[39,   262] loss: 0.345\n",
      "[39,   272] loss: 0.349\n",
      "[39,   282] loss: 0.341\n",
      "[39,   292] loss: 0.364\n",
      "[39,   302] loss: 0.337\n",
      "[39,   312] loss: 0.344\n",
      "[39,   322] loss: 0.356\n",
      "[39,   332] loss: 0.378\n",
      "[39,   342] loss: 0.372\n",
      "[39,   352] loss: 0.343\n",
      "[39,   362] loss: 0.364\n",
      "[39,   372] loss: 0.345\n",
      "[39,   382] loss: 0.364\n",
      "[40,     2] loss: 0.074\n",
      "[40,    12] loss: 0.350\n",
      "[40,    22] loss: 0.390\n",
      "[40,    32] loss: 0.360\n",
      "[40,    42] loss: 0.362\n",
      "[40,    52] loss: 0.380\n",
      "[40,    62] loss: 0.356\n",
      "[40,    72] loss: 0.356\n",
      "[40,    82] loss: 0.341\n",
      "[40,    92] loss: 0.366\n",
      "[40,   102] loss: 0.361\n",
      "[40,   112] loss: 0.404\n",
      "[40,   122] loss: 0.371\n",
      "[40,   132] loss: 0.365\n",
      "[40,   142] loss: 0.325\n",
      "[40,   152] loss: 0.337\n",
      "[40,   162] loss: 0.358\n",
      "[40,   172] loss: 0.352\n",
      "[40,   182] loss: 0.361\n",
      "[40,   192] loss: 0.348\n",
      "[40,   202] loss: 0.365\n",
      "[40,   212] loss: 0.349\n",
      "[40,   222] loss: 0.370\n",
      "[40,   232] loss: 0.358\n",
      "[40,   242] loss: 0.372\n",
      "[40,   252] loss: 0.362\n",
      "[40,   262] loss: 0.353\n",
      "[40,   272] loss: 0.356\n",
      "[40,   282] loss: 0.366\n",
      "[40,   292] loss: 0.369\n",
      "[40,   302] loss: 0.363\n",
      "[40,   312] loss: 0.338\n",
      "[40,   322] loss: 0.371\n",
      "[40,   332] loss: 0.372\n",
      "[40,   342] loss: 0.362\n",
      "[40,   352] loss: 0.372\n",
      "[40,   362] loss: 0.360\n",
      "[40,   372] loss: 0.356\n",
      "[40,   382] loss: 0.353\n",
      "[41,     2] loss: 0.064\n",
      "[41,    12] loss: 0.369\n",
      "[41,    22] loss: 0.362\n",
      "[41,    32] loss: 0.364\n",
      "[41,    42] loss: 0.354\n",
      "[41,    52] loss: 0.359\n",
      "[41,    62] loss: 0.370\n",
      "[41,    72] loss: 0.352\n",
      "[41,    82] loss: 0.365\n",
      "[41,    92] loss: 0.347\n",
      "[41,   102] loss: 0.352\n",
      "[41,   112] loss: 0.368\n",
      "[41,   122] loss: 0.365\n",
      "[41,   132] loss: 0.345\n",
      "[41,   142] loss: 0.373\n",
      "[41,   152] loss: 0.352\n",
      "[41,   162] loss: 0.366\n",
      "[41,   172] loss: 0.349\n",
      "[41,   182] loss: 0.360\n",
      "[41,   192] loss: 0.354\n",
      "[41,   202] loss: 0.369\n",
      "[41,   212] loss: 0.348\n",
      "[41,   222] loss: 0.342\n",
      "[41,   232] loss: 0.359\n",
      "[41,   242] loss: 0.351\n",
      "[41,   252] loss: 0.337\n",
      "[41,   262] loss: 0.346\n",
      "[41,   272] loss: 0.375\n",
      "[41,   282] loss: 0.360\n",
      "[41,   292] loss: 0.371\n",
      "[41,   302] loss: 0.385\n",
      "[41,   312] loss: 0.376\n",
      "[41,   322] loss: 0.370\n",
      "[41,   332] loss: 0.359\n",
      "[41,   342] loss: 0.331\n",
      "[41,   352] loss: 0.356\n",
      "[41,   362] loss: 0.366\n",
      "[41,   372] loss: 0.343\n",
      "[41,   382] loss: 0.350\n",
      "[42,     2] loss: 0.070\n",
      "[42,    12] loss: 0.356\n",
      "[42,    22] loss: 0.357\n",
      "[42,    32] loss: 0.354\n",
      "[42,    42] loss: 0.350\n",
      "[42,    52] loss: 0.382\n",
      "[42,    62] loss: 0.368\n",
      "[42,    72] loss: 0.338\n",
      "[42,    82] loss: 0.362\n",
      "[42,    92] loss: 0.362\n",
      "[42,   102] loss: 0.362\n",
      "[42,   112] loss: 0.373\n",
      "[42,   122] loss: 0.363\n",
      "[42,   132] loss: 0.383\n",
      "[42,   142] loss: 0.354\n",
      "[42,   152] loss: 0.369\n",
      "[42,   162] loss: 0.361\n",
      "[42,   172] loss: 0.345\n",
      "[42,   182] loss: 0.375\n",
      "[42,   192] loss: 0.368\n",
      "[42,   202] loss: 0.343\n",
      "[42,   212] loss: 0.369\n",
      "[42,   222] loss: 0.363\n",
      "[42,   232] loss: 0.357\n",
      "[42,   242] loss: 0.364\n",
      "[42,   252] loss: 0.348\n",
      "[42,   262] loss: 0.356\n",
      "[42,   272] loss: 0.371\n",
      "[42,   282] loss: 0.374\n",
      "[42,   292] loss: 0.333\n",
      "[42,   302] loss: 0.364\n",
      "[42,   312] loss: 0.363\n",
      "[42,   322] loss: 0.348\n",
      "[42,   332] loss: 0.357\n",
      "[42,   342] loss: 0.361\n",
      "[42,   352] loss: 0.356\n",
      "[42,   362] loss: 0.366\n",
      "[42,   372] loss: 0.372\n",
      "[42,   382] loss: 0.362\n",
      "[43,     2] loss: 0.079\n",
      "[43,    12] loss: 0.357\n",
      "[43,    22] loss: 0.362\n",
      "[43,    32] loss: 0.370\n",
      "[43,    42] loss: 0.349\n",
      "[43,    52] loss: 0.368\n",
      "[43,    62] loss: 0.375\n",
      "[43,    72] loss: 0.347\n",
      "[43,    82] loss: 0.350\n",
      "[43,    92] loss: 0.384\n",
      "[43,   102] loss: 0.361\n",
      "[43,   112] loss: 0.361\n",
      "[43,   122] loss: 0.363\n",
      "[43,   132] loss: 0.360\n",
      "[43,   142] loss: 0.356\n",
      "[43,   152] loss: 0.330\n",
      "[43,   162] loss: 0.344\n",
      "[43,   172] loss: 0.334\n",
      "[43,   182] loss: 0.337\n",
      "[43,   192] loss: 0.368\n",
      "[43,   202] loss: 0.356\n",
      "[43,   212] loss: 0.364\n",
      "[43,   222] loss: 0.351\n",
      "[43,   232] loss: 0.345\n",
      "[43,   242] loss: 0.366\n",
      "[43,   252] loss: 0.356\n",
      "[43,   262] loss: 0.342\n",
      "[43,   272] loss: 0.354\n",
      "[43,   282] loss: 0.350\n",
      "[43,   292] loss: 0.367\n",
      "[43,   302] loss: 0.352\n",
      "[43,   312] loss: 0.357\n",
      "[43,   322] loss: 0.360\n",
      "[43,   332] loss: 0.354\n",
      "[43,   342] loss: 0.365\n",
      "[43,   352] loss: 0.363\n",
      "[43,   362] loss: 0.374\n",
      "[43,   372] loss: 0.349\n",
      "[43,   382] loss: 0.350\n",
      "[44,     2] loss: 0.074\n",
      "[44,    12] loss: 0.372\n",
      "[44,    22] loss: 0.352\n",
      "[44,    32] loss: 0.374\n",
      "[44,    42] loss: 0.373\n",
      "[44,    52] loss: 0.342\n",
      "[44,    62] loss: 0.364\n",
      "[44,    72] loss: 0.366\n",
      "[44,    82] loss: 0.351\n",
      "[44,    92] loss: 0.336\n",
      "[44,   102] loss: 0.351\n",
      "[44,   112] loss: 0.371\n",
      "[44,   122] loss: 0.350\n",
      "[44,   132] loss: 0.379\n",
      "[44,   142] loss: 0.352\n",
      "[44,   152] loss: 0.362\n",
      "[44,   162] loss: 0.352\n",
      "[44,   172] loss: 0.362\n",
      "[44,   182] loss: 0.324\n",
      "[44,   192] loss: 0.356\n",
      "[44,   202] loss: 0.342\n",
      "[44,   212] loss: 0.355\n",
      "[44,   222] loss: 0.379\n",
      "[44,   232] loss: 0.372\n",
      "[44,   242] loss: 0.366\n",
      "[44,   252] loss: 0.360\n",
      "[44,   262] loss: 0.357\n",
      "[44,   272] loss: 0.348\n",
      "[44,   282] loss: 0.389\n",
      "[44,   292] loss: 0.364\n",
      "[44,   302] loss: 0.361\n",
      "[44,   312] loss: 0.351\n",
      "[44,   322] loss: 0.353\n",
      "[44,   332] loss: 0.367\n",
      "[44,   342] loss: 0.355\n",
      "[44,   352] loss: 0.358\n",
      "[44,   362] loss: 0.339\n",
      "[44,   372] loss: 0.370\n",
      "[44,   382] loss: 0.363\n",
      "[45,     2] loss: 0.078\n",
      "[45,    12] loss: 0.358\n",
      "[45,    22] loss: 0.361\n",
      "[45,    32] loss: 0.376\n",
      "[45,    42] loss: 0.356\n",
      "[45,    52] loss: 0.347\n",
      "[45,    62] loss: 0.340\n",
      "[45,    72] loss: 0.364\n",
      "[45,    82] loss: 0.372\n",
      "[45,    92] loss: 0.365\n",
      "[45,   102] loss: 0.386\n",
      "[45,   112] loss: 0.372\n",
      "[45,   122] loss: 0.389\n",
      "[45,   132] loss: 0.360\n",
      "[45,   142] loss: 0.378\n",
      "[45,   152] loss: 0.371\n",
      "[45,   162] loss: 0.360\n",
      "[45,   172] loss: 0.363\n",
      "[45,   182] loss: 0.349\n",
      "[45,   192] loss: 0.365\n",
      "[45,   202] loss: 0.356\n",
      "[45,   212] loss: 0.369\n",
      "[45,   222] loss: 0.349\n",
      "[45,   232] loss: 0.368\n",
      "[45,   242] loss: 0.372\n",
      "[45,   252] loss: 0.369\n",
      "[45,   262] loss: 0.366\n",
      "[45,   272] loss: 0.358\n",
      "[45,   282] loss: 0.375\n",
      "[45,   292] loss: 0.363\n",
      "[45,   302] loss: 0.356\n",
      "[45,   312] loss: 0.355\n",
      "[45,   322] loss: 0.344\n",
      "[45,   332] loss: 0.352\n",
      "[45,   342] loss: 0.365\n",
      "[45,   352] loss: 0.342\n",
      "[45,   362] loss: 0.369\n",
      "[45,   372] loss: 0.367\n",
      "[45,   382] loss: 0.368\n",
      "[46,     2] loss: 0.068\n",
      "[46,    12] loss: 0.344\n",
      "[46,    22] loss: 0.346\n",
      "[46,    32] loss: 0.369\n",
      "[46,    42] loss: 0.349\n",
      "[46,    52] loss: 0.350\n",
      "[46,    62] loss: 0.337\n",
      "[46,    72] loss: 0.377\n",
      "[46,    82] loss: 0.370\n",
      "[46,    92] loss: 0.369\n",
      "[46,   102] loss: 0.335\n",
      "[46,   112] loss: 0.337\n",
      "[46,   122] loss: 0.337\n",
      "[46,   132] loss: 0.339\n",
      "[46,   142] loss: 0.354\n",
      "[46,   152] loss: 0.328\n",
      "[46,   162] loss: 0.352\n",
      "[46,   172] loss: 0.347\n",
      "[46,   182] loss: 0.370\n",
      "[46,   192] loss: 0.346\n",
      "[46,   202] loss: 0.332\n",
      "[46,   212] loss: 0.352\n",
      "[46,   222] loss: 0.365\n",
      "[46,   232] loss: 0.345\n",
      "[46,   242] loss: 0.362\n",
      "[46,   252] loss: 0.351\n",
      "[46,   262] loss: 0.341\n",
      "[46,   272] loss: 0.379\n",
      "[46,   282] loss: 0.349\n",
      "[46,   292] loss: 0.358\n",
      "[46,   302] loss: 0.354\n",
      "[46,   312] loss: 0.366\n",
      "[46,   322] loss: 0.351\n",
      "[46,   332] loss: 0.361\n",
      "[46,   342] loss: 0.366\n",
      "[46,   352] loss: 0.340\n",
      "[46,   362] loss: 0.363\n",
      "[46,   372] loss: 0.364\n",
      "[46,   382] loss: 0.367\n",
      "[47,     2] loss: 0.073\n",
      "[47,    12] loss: 0.369\n",
      "[47,    22] loss: 0.384\n",
      "[47,    32] loss: 0.362\n",
      "[47,    42] loss: 0.355\n",
      "[47,    52] loss: 0.362\n",
      "[47,    62] loss: 0.349\n",
      "[47,    72] loss: 0.343\n",
      "[47,    82] loss: 0.362\n",
      "[47,    92] loss: 0.373\n",
      "[47,   102] loss: 0.346\n",
      "[47,   112] loss: 0.337\n",
      "[47,   122] loss: 0.352\n",
      "[47,   132] loss: 0.362\n",
      "[47,   142] loss: 0.371\n",
      "[47,   152] loss: 0.362\n",
      "[47,   162] loss: 0.372\n",
      "[47,   172] loss: 0.360\n",
      "[47,   182] loss: 0.369\n",
      "[47,   192] loss: 0.362\n",
      "[47,   202] loss: 0.353\n",
      "[47,   212] loss: 0.358\n",
      "[47,   222] loss: 0.362\n",
      "[47,   232] loss: 0.374\n",
      "[47,   242] loss: 0.334\n",
      "[47,   252] loss: 0.368\n",
      "[47,   262] loss: 0.370\n",
      "[47,   272] loss: 0.351\n",
      "[47,   282] loss: 0.354\n",
      "[47,   292] loss: 0.360\n",
      "[47,   302] loss: 0.352\n",
      "[47,   312] loss: 0.335\n",
      "[47,   322] loss: 0.358\n",
      "[47,   332] loss: 0.366\n",
      "[47,   342] loss: 0.375\n",
      "[47,   352] loss: 0.363\n",
      "[47,   362] loss: 0.354\n",
      "[47,   372] loss: 0.346\n",
      "[47,   382] loss: 0.344\n",
      "[48,     2] loss: 0.077\n",
      "[48,    12] loss: 0.368\n",
      "[48,    22] loss: 0.360\n",
      "[48,    32] loss: 0.350\n",
      "[48,    42] loss: 0.352\n",
      "[48,    52] loss: 0.367\n",
      "[48,    62] loss: 0.358\n",
      "[48,    72] loss: 0.363\n",
      "[48,    82] loss: 0.341\n",
      "[48,    92] loss: 0.347\n",
      "[48,   102] loss: 0.343\n",
      "[48,   112] loss: 0.366\n",
      "[48,   122] loss: 0.373\n",
      "[48,   132] loss: 0.344\n",
      "[48,   142] loss: 0.350\n",
      "[48,   152] loss: 0.349\n",
      "[48,   162] loss: 0.333\n",
      "[48,   172] loss: 0.360\n",
      "[48,   182] loss: 0.375\n",
      "[48,   192] loss: 0.363\n",
      "[48,   202] loss: 0.337\n",
      "[48,   212] loss: 0.352\n",
      "[48,   222] loss: 0.354\n",
      "[48,   232] loss: 0.336\n",
      "[48,   242] loss: 0.356\n",
      "[48,   252] loss: 0.347\n",
      "[48,   262] loss: 0.401\n",
      "[48,   272] loss: 0.358\n",
      "[48,   282] loss: 0.349\n",
      "[48,   292] loss: 0.349\n",
      "[48,   302] loss: 0.356\n",
      "[48,   312] loss: 0.355\n",
      "[48,   322] loss: 0.344\n",
      "[48,   332] loss: 0.361\n",
      "[48,   342] loss: 0.348\n",
      "[48,   352] loss: 0.360\n",
      "[48,   362] loss: 0.359\n",
      "[48,   372] loss: 0.370\n",
      "[48,   382] loss: 0.341\n",
      "[49,     2] loss: 0.063\n",
      "[49,    12] loss: 0.348\n",
      "[49,    22] loss: 0.363\n",
      "[49,    32] loss: 0.351\n",
      "[49,    42] loss: 0.359\n",
      "[49,    52] loss: 0.359\n",
      "[49,    62] loss: 0.357\n",
      "[49,    72] loss: 0.343\n",
      "[49,    82] loss: 0.369\n",
      "[49,    92] loss: 0.338\n",
      "[49,   102] loss: 0.362\n",
      "[49,   112] loss: 0.356\n",
      "[49,   122] loss: 0.358\n",
      "[49,   132] loss: 0.342\n",
      "[49,   142] loss: 0.353\n",
      "[49,   152] loss: 0.349\n",
      "[49,   162] loss: 0.351\n",
      "[49,   172] loss: 0.355\n",
      "[49,   182] loss: 0.340\n",
      "[49,   192] loss: 0.334\n",
      "[49,   202] loss: 0.363\n",
      "[49,   212] loss: 0.355\n",
      "[49,   222] loss: 0.364\n",
      "[49,   232] loss: 0.340\n",
      "[49,   242] loss: 0.346\n",
      "[49,   252] loss: 0.351\n",
      "[49,   262] loss: 0.364\n",
      "[49,   272] loss: 0.353\n",
      "[49,   282] loss: 0.374\n",
      "[49,   292] loss: 0.354\n",
      "[49,   302] loss: 0.335\n",
      "[49,   312] loss: 0.378\n",
      "[49,   322] loss: 0.361\n",
      "[49,   332] loss: 0.374\n",
      "[49,   342] loss: 0.361\n",
      "[49,   352] loss: 0.340\n",
      "[49,   362] loss: 0.359\n",
      "[49,   372] loss: 0.335\n",
      "[49,   382] loss: 0.375\n",
      "[50,     2] loss: 0.066\n",
      "[50,    12] loss: 0.366\n",
      "[50,    22] loss: 0.338\n",
      "[50,    32] loss: 0.339\n",
      "[50,    42] loss: 0.349\n",
      "[50,    52] loss: 0.348\n",
      "[50,    62] loss: 0.339\n",
      "[50,    72] loss: 0.378\n",
      "[50,    82] loss: 0.351\n",
      "[50,    92] loss: 0.355\n",
      "[50,   102] loss: 0.350\n",
      "[50,   112] loss: 0.360\n",
      "[50,   122] loss: 0.334\n",
      "[50,   132] loss: 0.353\n",
      "[50,   142] loss: 0.350\n",
      "[50,   152] loss: 0.354\n",
      "[50,   162] loss: 0.357\n",
      "[50,   172] loss: 0.342\n",
      "[50,   182] loss: 0.365\n",
      "[50,   192] loss: 0.329\n",
      "[50,   202] loss: 0.360\n",
      "[50,   212] loss: 0.347\n",
      "[50,   222] loss: 0.374\n",
      "[50,   232] loss: 0.355\n",
      "[50,   242] loss: 0.356\n",
      "[50,   252] loss: 0.346\n",
      "[50,   262] loss: 0.354\n",
      "[50,   272] loss: 0.351\n",
      "[50,   282] loss: 0.360\n",
      "[50,   292] loss: 0.351\n",
      "[50,   302] loss: 0.342\n",
      "[50,   312] loss: 0.379\n",
      "[50,   322] loss: 0.366\n",
      "[50,   332] loss: 0.350\n",
      "[50,   342] loss: 0.368\n",
      "[50,   352] loss: 0.361\n",
      "[50,   362] loss: 0.343\n",
      "[50,   372] loss: 0.346\n",
      "[50,   382] loss: 0.358\n",
      "[51,     2] loss: 0.081\n",
      "[51,    12] loss: 0.356\n",
      "[51,    22] loss: 0.362\n",
      "[51,    32] loss: 0.357\n",
      "[51,    42] loss: 0.346\n",
      "[51,    52] loss: 0.340\n",
      "[51,    62] loss: 0.350\n",
      "[51,    72] loss: 0.345\n",
      "[51,    82] loss: 0.357\n",
      "[51,    92] loss: 0.369\n",
      "[51,   102] loss: 0.382\n",
      "[51,   112] loss: 0.330\n",
      "[51,   122] loss: 0.361\n",
      "[51,   132] loss: 0.359\n",
      "[51,   142] loss: 0.368\n",
      "[51,   152] loss: 0.353\n",
      "[51,   162] loss: 0.360\n",
      "[51,   172] loss: 0.364\n",
      "[51,   182] loss: 0.338\n",
      "[51,   192] loss: 0.364\n",
      "[51,   202] loss: 0.346\n",
      "[51,   212] loss: 0.357\n",
      "[51,   222] loss: 0.368\n",
      "[51,   232] loss: 0.359\n",
      "[51,   242] loss: 0.316\n",
      "[51,   252] loss: 0.335\n",
      "[51,   262] loss: 0.345\n",
      "[51,   272] loss: 0.365\n",
      "[51,   282] loss: 0.359\n",
      "[51,   292] loss: 0.360\n",
      "[51,   302] loss: 0.331\n",
      "[51,   312] loss: 0.372\n",
      "[51,   322] loss: 0.360\n",
      "[51,   332] loss: 0.342\n",
      "[51,   342] loss: 0.359\n",
      "[51,   352] loss: 0.367\n",
      "[51,   362] loss: 0.364\n",
      "[51,   372] loss: 0.357\n",
      "[51,   382] loss: 0.349\n",
      "[52,     2] loss: 0.078\n",
      "[52,    12] loss: 0.333\n",
      "[52,    22] loss: 0.363\n",
      "[52,    32] loss: 0.364\n",
      "[52,    42] loss: 0.358\n",
      "[52,    52] loss: 0.353\n",
      "[52,    62] loss: 0.330\n",
      "[52,    72] loss: 0.363\n",
      "[52,    82] loss: 0.348\n",
      "[52,    92] loss: 0.339\n",
      "[52,   102] loss: 0.350\n",
      "[52,   112] loss: 0.361\n",
      "[52,   122] loss: 0.341\n",
      "[52,   132] loss: 0.347\n",
      "[52,   142] loss: 0.333\n",
      "[52,   152] loss: 0.350\n",
      "[52,   162] loss: 0.346\n",
      "[52,   172] loss: 0.347\n",
      "[52,   182] loss: 0.335\n",
      "[52,   192] loss: 0.365\n",
      "[52,   202] loss: 0.356\n",
      "[52,   212] loss: 0.355\n",
      "[52,   222] loss: 0.372\n",
      "[52,   232] loss: 0.355\n",
      "[52,   242] loss: 0.360\n",
      "[52,   252] loss: 0.328\n",
      "[52,   262] loss: 0.363\n",
      "[52,   272] loss: 0.371\n",
      "[52,   282] loss: 0.355\n",
      "[52,   292] loss: 0.355\n",
      "[52,   302] loss: 0.354\n",
      "[52,   312] loss: 0.351\n",
      "[52,   322] loss: 0.360\n",
      "[52,   332] loss: 0.336\n",
      "[52,   342] loss: 0.339\n",
      "[52,   352] loss: 0.358\n",
      "[52,   362] loss: 0.370\n",
      "[52,   372] loss: 0.362\n",
      "[52,   382] loss: 0.370\n",
      "[53,     2] loss: 0.073\n",
      "[53,    12] loss: 0.366\n",
      "[53,    22] loss: 0.348\n",
      "[53,    32] loss: 0.349\n",
      "[53,    42] loss: 0.366\n",
      "[53,    52] loss: 0.367\n",
      "[53,    62] loss: 0.345\n",
      "[53,    72] loss: 0.356\n",
      "[53,    82] loss: 0.358\n",
      "[53,    92] loss: 0.350\n",
      "[53,   102] loss: 0.353\n",
      "[53,   112] loss: 0.372\n",
      "[53,   122] loss: 0.333\n",
      "[53,   132] loss: 0.379\n",
      "[53,   142] loss: 0.357\n",
      "[53,   152] loss: 0.340\n",
      "[53,   162] loss: 0.381\n",
      "[53,   172] loss: 0.368\n",
      "[53,   182] loss: 0.350\n",
      "[53,   192] loss: 0.357\n",
      "[53,   202] loss: 0.368\n",
      "[53,   212] loss: 0.340\n",
      "[53,   222] loss: 0.365\n",
      "[53,   232] loss: 0.357\n",
      "[53,   242] loss: 0.348\n",
      "[53,   252] loss: 0.353\n",
      "[53,   262] loss: 0.336\n",
      "[53,   272] loss: 0.368\n",
      "[53,   282] loss: 0.386\n",
      "[53,   292] loss: 0.372\n",
      "[53,   302] loss: 0.339\n",
      "[53,   312] loss: 0.353\n",
      "[53,   322] loss: 0.334\n",
      "[53,   332] loss: 0.314\n",
      "[53,   342] loss: 0.351\n",
      "[53,   352] loss: 0.361\n",
      "[53,   362] loss: 0.347\n",
      "[53,   372] loss: 0.377\n",
      "[53,   382] loss: 0.355\n",
      "[54,     2] loss: 0.064\n",
      "[54,    12] loss: 0.344\n",
      "[54,    22] loss: 0.337\n",
      "[54,    32] loss: 0.366\n",
      "[54,    42] loss: 0.364\n",
      "[54,    52] loss: 0.344\n",
      "[54,    62] loss: 0.362\n",
      "[54,    72] loss: 0.363\n",
      "[54,    82] loss: 0.352\n",
      "[54,    92] loss: 0.367\n",
      "[54,   102] loss: 0.352\n",
      "[54,   112] loss: 0.359\n",
      "[54,   122] loss: 0.383\n",
      "[54,   132] loss: 0.374\n",
      "[54,   142] loss: 0.352\n",
      "[54,   152] loss: 0.349\n",
      "[54,   162] loss: 0.363\n",
      "[54,   172] loss: 0.368\n",
      "[54,   182] loss: 0.351\n",
      "[54,   192] loss: 0.356\n",
      "[54,   202] loss: 0.341\n",
      "[54,   212] loss: 0.362\n",
      "[54,   222] loss: 0.342\n",
      "[54,   232] loss: 0.366\n",
      "[54,   242] loss: 0.345\n",
      "[54,   252] loss: 0.346\n",
      "[54,   262] loss: 0.347\n",
      "[54,   272] loss: 0.320\n",
      "[54,   282] loss: 0.350\n",
      "[54,   292] loss: 0.367\n",
      "[54,   302] loss: 0.353\n",
      "[54,   312] loss: 0.359\n",
      "[54,   322] loss: 0.366\n",
      "[54,   332] loss: 0.348\n",
      "[54,   342] loss: 0.352\n",
      "[54,   352] loss: 0.356\n",
      "[54,   362] loss: 0.341\n",
      "[54,   372] loss: 0.357\n",
      "[54,   382] loss: 0.361\n",
      "[55,     2] loss: 0.066\n",
      "[55,    12] loss: 0.360\n",
      "[55,    22] loss: 0.353\n",
      "[55,    32] loss: 0.324\n",
      "[55,    42] loss: 0.350\n",
      "[55,    52] loss: 0.338\n",
      "[55,    62] loss: 0.359\n",
      "[55,    72] loss: 0.346\n",
      "[55,    82] loss: 0.343\n",
      "[55,    92] loss: 0.363\n",
      "[55,   102] loss: 0.359\n",
      "[55,   112] loss: 0.340\n",
      "[55,   122] loss: 0.342\n",
      "[55,   132] loss: 0.358\n",
      "[55,   142] loss: 0.346\n",
      "[55,   152] loss: 0.349\n",
      "[55,   162] loss: 0.339\n",
      "[55,   172] loss: 0.339\n",
      "[55,   182] loss: 0.352\n",
      "[55,   192] loss: 0.341\n",
      "[55,   202] loss: 0.365\n",
      "[55,   212] loss: 0.338\n",
      "[55,   222] loss: 0.346\n",
      "[55,   232] loss: 0.370\n",
      "[55,   242] loss: 0.348\n",
      "[55,   252] loss: 0.366\n",
      "[55,   262] loss: 0.358\n",
      "[55,   272] loss: 0.350\n",
      "[55,   282] loss: 0.334\n",
      "[55,   292] loss: 0.340\n",
      "[55,   302] loss: 0.363\n",
      "[55,   312] loss: 0.336\n",
      "[55,   322] loss: 0.352\n",
      "[55,   332] loss: 0.339\n",
      "[55,   342] loss: 0.344\n",
      "[55,   352] loss: 0.326\n",
      "[55,   362] loss: 0.369\n",
      "[55,   372] loss: 0.351\n",
      "[55,   382] loss: 0.358\n",
      "[56,     2] loss: 0.070\n",
      "[56,    12] loss: 0.361\n",
      "[56,    22] loss: 0.357\n",
      "[56,    32] loss: 0.329\n",
      "[56,    42] loss: 0.364\n",
      "[56,    52] loss: 0.352\n",
      "[56,    62] loss: 0.379\n",
      "[56,    72] loss: 0.376\n",
      "[56,    82] loss: 0.352\n",
      "[56,    92] loss: 0.371\n",
      "[56,   102] loss: 0.361\n",
      "[56,   112] loss: 0.358\n",
      "[56,   122] loss: 0.359\n",
      "[56,   132] loss: 0.358\n",
      "[56,   142] loss: 0.349\n",
      "[56,   152] loss: 0.330\n",
      "[56,   162] loss: 0.356\n",
      "[56,   172] loss: 0.334\n",
      "[56,   182] loss: 0.370\n",
      "[56,   192] loss: 0.353\n",
      "[56,   202] loss: 0.340\n",
      "[56,   212] loss: 0.344\n",
      "[56,   222] loss: 0.376\n",
      "[56,   232] loss: 0.346\n",
      "[56,   242] loss: 0.358\n",
      "[56,   252] loss: 0.356\n",
      "[56,   262] loss: 0.351\n",
      "[56,   272] loss: 0.351\n",
      "[56,   282] loss: 0.363\n",
      "[56,   292] loss: 0.343\n",
      "[56,   302] loss: 0.347\n",
      "[56,   312] loss: 0.347\n",
      "[56,   322] loss: 0.353\n",
      "[56,   332] loss: 0.335\n",
      "[56,   342] loss: 0.379\n",
      "[56,   352] loss: 0.348\n",
      "[56,   362] loss: 0.355\n",
      "[56,   372] loss: 0.354\n",
      "[56,   382] loss: 0.355\n",
      "[57,     2] loss: 0.071\n",
      "[57,    12] loss: 0.357\n",
      "[57,    22] loss: 0.344\n",
      "[57,    32] loss: 0.350\n",
      "[57,    42] loss: 0.364\n",
      "[57,    52] loss: 0.343\n",
      "[57,    62] loss: 0.370\n",
      "[57,    72] loss: 0.340\n",
      "[57,    82] loss: 0.377\n",
      "[57,    92] loss: 0.359\n",
      "[57,   102] loss: 0.342\n",
      "[57,   112] loss: 0.353\n",
      "[57,   122] loss: 0.345\n",
      "[57,   132] loss: 0.355\n",
      "[57,   142] loss: 0.332\n",
      "[57,   152] loss: 0.365\n",
      "[57,   162] loss: 0.347\n",
      "[57,   172] loss: 0.344\n",
      "[57,   182] loss: 0.362\n",
      "[57,   192] loss: 0.336\n",
      "[57,   202] loss: 0.343\n",
      "[57,   212] loss: 0.352\n",
      "[57,   222] loss: 0.361\n",
      "[57,   232] loss: 0.362\n",
      "[57,   242] loss: 0.337\n",
      "[57,   252] loss: 0.336\n",
      "[57,   262] loss: 0.349\n",
      "[57,   272] loss: 0.352\n",
      "[57,   282] loss: 0.338\n",
      "[57,   292] loss: 0.350\n",
      "[57,   302] loss: 0.343\n",
      "[57,   312] loss: 0.336\n",
      "[57,   322] loss: 0.333\n",
      "[57,   332] loss: 0.352\n",
      "[57,   342] loss: 0.346\n",
      "[57,   352] loss: 0.359\n",
      "[57,   362] loss: 0.357\n",
      "[57,   372] loss: 0.355\n",
      "[57,   382] loss: 0.354\n",
      "[58,     2] loss: 0.065\n",
      "[58,    12] loss: 0.347\n",
      "[58,    22] loss: 0.340\n",
      "[58,    32] loss: 0.369\n",
      "[58,    42] loss: 0.350\n",
      "[58,    52] loss: 0.348\n",
      "[58,    62] loss: 0.362\n",
      "[58,    72] loss: 0.339\n",
      "[58,    82] loss: 0.349\n",
      "[58,    92] loss: 0.354\n",
      "[58,   102] loss: 0.342\n",
      "[58,   112] loss: 0.360\n",
      "[58,   122] loss: 0.347\n",
      "[58,   132] loss: 0.348\n",
      "[58,   142] loss: 0.343\n",
      "[58,   152] loss: 0.344\n",
      "[58,   162] loss: 0.374\n",
      "[58,   172] loss: 0.359\n",
      "[58,   182] loss: 0.352\n",
      "[58,   192] loss: 0.345\n",
      "[58,   202] loss: 0.362\n",
      "[58,   212] loss: 0.323\n",
      "[58,   222] loss: 0.330\n",
      "[58,   232] loss: 0.351\n",
      "[58,   242] loss: 0.338\n",
      "[58,   252] loss: 0.344\n",
      "[58,   262] loss: 0.339\n",
      "[58,   272] loss: 0.338\n",
      "[58,   282] loss: 0.371\n",
      "[58,   292] loss: 0.338\n",
      "[58,   302] loss: 0.348\n",
      "[58,   312] loss: 0.337\n",
      "[58,   322] loss: 0.337\n",
      "[58,   332] loss: 0.354\n",
      "[58,   342] loss: 0.365\n",
      "[58,   352] loss: 0.359\n",
      "[58,   362] loss: 0.351\n",
      "[58,   372] loss: 0.350\n",
      "[58,   382] loss: 0.363\n",
      "[59,     2] loss: 0.072\n",
      "[59,    12] loss: 0.360\n",
      "[59,    22] loss: 0.347\n",
      "[59,    32] loss: 0.354\n",
      "[59,    42] loss: 0.342\n",
      "[59,    52] loss: 0.353\n",
      "[59,    62] loss: 0.351\n",
      "[59,    72] loss: 0.326\n",
      "[59,    82] loss: 0.360\n",
      "[59,    92] loss: 0.353\n",
      "[59,   102] loss: 0.328\n",
      "[59,   112] loss: 0.357\n",
      "[59,   122] loss: 0.348\n",
      "[59,   132] loss: 0.352\n",
      "[59,   142] loss: 0.381\n",
      "[59,   152] loss: 0.365\n",
      "[59,   162] loss: 0.341\n",
      "[59,   172] loss: 0.365\n",
      "[59,   182] loss: 0.342\n",
      "[59,   192] loss: 0.362\n",
      "[59,   202] loss: 0.343\n",
      "[59,   212] loss: 0.339\n",
      "[59,   222] loss: 0.348\n",
      "[59,   232] loss: 0.341\n",
      "[59,   242] loss: 0.347\n",
      "[59,   252] loss: 0.370\n",
      "[59,   262] loss: 0.366\n",
      "[59,   272] loss: 0.357\n",
      "[59,   282] loss: 0.344\n",
      "[59,   292] loss: 0.356\n",
      "[59,   302] loss: 0.346\n",
      "[59,   312] loss: 0.346\n",
      "[59,   322] loss: 0.323\n",
      "[59,   332] loss: 0.364\n",
      "[59,   342] loss: 0.340\n",
      "[59,   352] loss: 0.344\n",
      "[59,   362] loss: 0.341\n",
      "[59,   372] loss: 0.365\n",
      "[59,   382] loss: 0.336\n",
      "[60,     2] loss: 0.062\n",
      "[60,    12] loss: 0.344\n",
      "[60,    22] loss: 0.347\n",
      "[60,    32] loss: 0.350\n",
      "[60,    42] loss: 0.345\n",
      "[60,    52] loss: 0.323\n",
      "[60,    62] loss: 0.331\n",
      "[60,    72] loss: 0.362\n",
      "[60,    82] loss: 0.349\n",
      "[60,    92] loss: 0.321\n",
      "[60,   102] loss: 0.353\n",
      "[60,   112] loss: 0.339\n",
      "[60,   122] loss: 0.351\n",
      "[60,   132] loss: 0.344\n",
      "[60,   142] loss: 0.350\n",
      "[60,   152] loss: 0.345\n",
      "[60,   162] loss: 0.331\n",
      "[60,   172] loss: 0.344\n",
      "[60,   182] loss: 0.354\n",
      "[60,   192] loss: 0.351\n",
      "[60,   202] loss: 0.334\n",
      "[60,   212] loss: 0.349\n",
      "[60,   222] loss: 0.364\n",
      "[60,   232] loss: 0.346\n",
      "[60,   242] loss: 0.340\n",
      "[60,   252] loss: 0.343\n",
      "[60,   262] loss: 0.340\n",
      "[60,   272] loss: 0.367\n",
      "[60,   282] loss: 0.329\n",
      "[60,   292] loss: 0.360\n",
      "[60,   302] loss: 0.345\n",
      "[60,   312] loss: 0.342\n",
      "[60,   322] loss: 0.347\n",
      "[60,   332] loss: 0.347\n",
      "[60,   342] loss: 0.346\n",
      "[60,   352] loss: 0.346\n",
      "[60,   362] loss: 0.344\n",
      "[60,   372] loss: 0.345\n",
      "[60,   382] loss: 0.351\n",
      "[61,     2] loss: 0.079\n",
      "[61,    12] loss: 0.336\n",
      "[61,    22] loss: 0.362\n",
      "[61,    32] loss: 0.359\n",
      "[61,    42] loss: 0.350\n",
      "[61,    52] loss: 0.339\n",
      "[61,    62] loss: 0.338\n",
      "[61,    72] loss: 0.345\n",
      "[61,    82] loss: 0.368\n",
      "[61,    92] loss: 0.373\n",
      "[61,   102] loss: 0.336\n",
      "[61,   112] loss: 0.363\n",
      "[61,   122] loss: 0.332\n",
      "[61,   132] loss: 0.365\n",
      "[61,   142] loss: 0.370\n",
      "[61,   152] loss: 0.349\n",
      "[61,   162] loss: 0.331\n",
      "[61,   172] loss: 0.329\n",
      "[61,   182] loss: 0.341\n",
      "[61,   192] loss: 0.327\n",
      "[61,   202] loss: 0.334\n",
      "[61,   212] loss: 0.336\n",
      "[61,   222] loss: 0.344\n",
      "[61,   232] loss: 0.337\n",
      "[61,   242] loss: 0.345\n",
      "[61,   252] loss: 0.332\n",
      "[61,   262] loss: 0.361\n",
      "[61,   272] loss: 0.342\n",
      "[61,   282] loss: 0.342\n",
      "[61,   292] loss: 0.364\n",
      "[61,   302] loss: 0.314\n",
      "[61,   312] loss: 0.352\n",
      "[61,   322] loss: 0.348\n",
      "[61,   332] loss: 0.330\n",
      "[61,   342] loss: 0.348\n",
      "[61,   352] loss: 0.337\n",
      "[61,   362] loss: 0.353\n",
      "[61,   372] loss: 0.353\n",
      "[61,   382] loss: 0.336\n",
      "[62,     2] loss: 0.068\n",
      "[62,    12] loss: 0.345\n",
      "[62,    22] loss: 0.339\n",
      "[62,    32] loss: 0.338\n",
      "[62,    42] loss: 0.362\n",
      "[62,    52] loss: 0.329\n",
      "[62,    62] loss: 0.352\n",
      "[62,    72] loss: 0.366\n",
      "[62,    82] loss: 0.340\n",
      "[62,    92] loss: 0.332\n",
      "[62,   102] loss: 0.340\n",
      "[62,   112] loss: 0.344\n",
      "[62,   122] loss: 0.339\n",
      "[62,   132] loss: 0.357\n",
      "[62,   142] loss: 0.363\n",
      "[62,   152] loss: 0.353\n",
      "[62,   162] loss: 0.341\n",
      "[62,   172] loss: 0.346\n",
      "[62,   182] loss: 0.336\n",
      "[62,   192] loss: 0.384\n",
      "[62,   202] loss: 0.355\n",
      "[62,   212] loss: 0.338\n",
      "[62,   222] loss: 0.342\n",
      "[62,   232] loss: 0.334\n",
      "[62,   242] loss: 0.373\n",
      "[62,   252] loss: 0.336\n",
      "[62,   262] loss: 0.353\n",
      "[62,   272] loss: 0.338\n",
      "[62,   282] loss: 0.336\n",
      "[62,   292] loss: 0.359\n",
      "[62,   302] loss: 0.349\n",
      "[62,   312] loss: 0.352\n",
      "[62,   322] loss: 0.348\n",
      "[62,   332] loss: 0.342\n",
      "[62,   342] loss: 0.351\n",
      "[62,   352] loss: 0.360\n",
      "[62,   362] loss: 0.347\n",
      "[62,   372] loss: 0.328\n",
      "[62,   382] loss: 0.353\n",
      "[63,     2] loss: 0.072\n",
      "[63,    12] loss: 0.349\n",
      "[63,    22] loss: 0.334\n",
      "[63,    32] loss: 0.360\n",
      "[63,    42] loss: 0.337\n",
      "[63,    52] loss: 0.352\n",
      "[63,    62] loss: 0.366\n",
      "[63,    72] loss: 0.342\n",
      "[63,    82] loss: 0.340\n",
      "[63,    92] loss: 0.358\n",
      "[63,   102] loss: 0.331\n",
      "[63,   112] loss: 0.354\n",
      "[63,   122] loss: 0.348\n",
      "[63,   132] loss: 0.355\n",
      "[63,   142] loss: 0.364\n",
      "[63,   152] loss: 0.343\n",
      "[63,   162] loss: 0.340\n",
      "[63,   172] loss: 0.334\n",
      "[63,   182] loss: 0.338\n",
      "[63,   192] loss: 0.327\n",
      "[63,   202] loss: 0.357\n",
      "[63,   212] loss: 0.350\n",
      "[63,   222] loss: 0.336\n",
      "[63,   232] loss: 0.338\n",
      "[63,   242] loss: 0.360\n",
      "[63,   252] loss: 0.332\n",
      "[63,   262] loss: 0.355\n",
      "[63,   272] loss: 0.330\n",
      "[63,   282] loss: 0.333\n",
      "[63,   292] loss: 0.344\n",
      "[63,   302] loss: 0.313\n",
      "[63,   312] loss: 0.346\n",
      "[63,   322] loss: 0.339\n",
      "[63,   332] loss: 0.361\n",
      "[63,   342] loss: 0.356\n",
      "[63,   352] loss: 0.364\n",
      "[63,   362] loss: 0.318\n",
      "[63,   372] loss: 0.348\n",
      "[63,   382] loss: 0.346\n",
      "[64,     2] loss: 0.067\n",
      "[64,    12] loss: 0.331\n",
      "[64,    22] loss: 0.342\n",
      "[64,    32] loss: 0.345\n",
      "[64,    42] loss: 0.350\n",
      "[64,    52] loss: 0.334\n",
      "[64,    62] loss: 0.335\n",
      "[64,    72] loss: 0.345\n",
      "[64,    82] loss: 0.340\n",
      "[64,    92] loss: 0.344\n",
      "[64,   102] loss: 0.346\n",
      "[64,   112] loss: 0.322\n",
      "[64,   122] loss: 0.344\n",
      "[64,   132] loss: 0.351\n",
      "[64,   142] loss: 0.366\n",
      "[64,   152] loss: 0.331\n",
      "[64,   162] loss: 0.352\n",
      "[64,   172] loss: 0.340\n",
      "[64,   182] loss: 0.353\n",
      "[64,   192] loss: 0.332\n",
      "[64,   202] loss: 0.377\n",
      "[64,   212] loss: 0.364\n",
      "[64,   222] loss: 0.354\n",
      "[64,   232] loss: 0.345\n",
      "[64,   242] loss: 0.345\n",
      "[64,   252] loss: 0.354\n",
      "[64,   262] loss: 0.356\n",
      "[64,   272] loss: 0.353\n",
      "[64,   282] loss: 0.343\n",
      "[64,   292] loss: 0.369\n",
      "[64,   302] loss: 0.352\n",
      "[64,   312] loss: 0.335\n",
      "[64,   322] loss: 0.354\n",
      "[64,   332] loss: 0.332\n",
      "[64,   342] loss: 0.349\n",
      "[64,   352] loss: 0.364\n",
      "[64,   362] loss: 0.348\n",
      "[64,   372] loss: 0.349\n",
      "[64,   382] loss: 0.334\n",
      "[65,     2] loss: 0.072\n",
      "[65,    12] loss: 0.326\n",
      "[65,    22] loss: 0.330\n",
      "[65,    32] loss: 0.359\n",
      "[65,    42] loss: 0.339\n",
      "[65,    52] loss: 0.337\n",
      "[65,    62] loss: 0.328\n",
      "[65,    72] loss: 0.343\n",
      "[65,    82] loss: 0.355\n",
      "[65,    92] loss: 0.339\n",
      "[65,   102] loss: 0.365\n",
      "[65,   112] loss: 0.344\n",
      "[65,   122] loss: 0.355\n",
      "[65,   132] loss: 0.336\n",
      "[65,   142] loss: 0.379\n",
      "[65,   152] loss: 0.353\n",
      "[65,   162] loss: 0.354\n",
      "[65,   172] loss: 0.332\n",
      "[65,   182] loss: 0.341\n",
      "[65,   192] loss: 0.340\n",
      "[65,   202] loss: 0.344\n",
      "[65,   212] loss: 0.355\n",
      "[65,   222] loss: 0.332\n",
      "[65,   232] loss: 0.354\n",
      "[65,   242] loss: 0.335\n",
      "[65,   252] loss: 0.361\n",
      "[65,   262] loss: 0.348\n",
      "[65,   272] loss: 0.355\n",
      "[65,   282] loss: 0.360\n",
      "[65,   292] loss: 0.347\n",
      "[65,   302] loss: 0.330\n",
      "[65,   312] loss: 0.330\n",
      "[65,   322] loss: 0.335\n",
      "[65,   332] loss: 0.358\n",
      "[65,   342] loss: 0.358\n",
      "[65,   352] loss: 0.363\n",
      "[65,   362] loss: 0.330\n",
      "[65,   372] loss: 0.341\n",
      "[65,   382] loss: 0.335\n",
      "[66,     2] loss: 0.069\n",
      "[66,    12] loss: 0.327\n",
      "[66,    22] loss: 0.350\n",
      "[66,    32] loss: 0.355\n",
      "[66,    42] loss: 0.354\n",
      "[66,    52] loss: 0.337\n",
      "[66,    62] loss: 0.367\n",
      "[66,    72] loss: 0.339\n",
      "[66,    82] loss: 0.352\n",
      "[66,    92] loss: 0.327\n",
      "[66,   102] loss: 0.333\n",
      "[66,   112] loss: 0.363\n",
      "[66,   122] loss: 0.330\n",
      "[66,   132] loss: 0.322\n",
      "[66,   142] loss: 0.325\n",
      "[66,   152] loss: 0.346\n",
      "[66,   162] loss: 0.353\n",
      "[66,   172] loss: 0.356\n",
      "[66,   182] loss: 0.353\n",
      "[66,   192] loss: 0.354\n",
      "[66,   202] loss: 0.338\n",
      "[66,   212] loss: 0.356\n",
      "[66,   222] loss: 0.340\n",
      "[66,   232] loss: 0.348\n",
      "[66,   242] loss: 0.329\n",
      "[66,   252] loss: 0.337\n",
      "[66,   262] loss: 0.339\n",
      "[66,   272] loss: 0.351\n",
      "[66,   282] loss: 0.325\n",
      "[66,   292] loss: 0.318\n",
      "[66,   302] loss: 0.336\n",
      "[66,   312] loss: 0.343\n",
      "[66,   322] loss: 0.328\n",
      "[66,   332] loss: 0.358\n",
      "[66,   342] loss: 0.376\n",
      "[66,   352] loss: 0.338\n",
      "[66,   362] loss: 0.356\n",
      "[66,   372] loss: 0.348\n",
      "[66,   382] loss: 0.343\n",
      "[67,     2] loss: 0.065\n",
      "[67,    12] loss: 0.347\n",
      "[67,    22] loss: 0.359\n",
      "[67,    32] loss: 0.332\n",
      "[67,    42] loss: 0.335\n",
      "[67,    52] loss: 0.342\n",
      "[67,    62] loss: 0.331\n",
      "[67,    72] loss: 0.323\n",
      "[67,    82] loss: 0.335\n",
      "[67,    92] loss: 0.330\n",
      "[67,   102] loss: 0.341\n",
      "[67,   112] loss: 0.345\n",
      "[67,   122] loss: 0.341\n",
      "[67,   132] loss: 0.351\n",
      "[67,   142] loss: 0.340\n",
      "[67,   152] loss: 0.378\n",
      "[67,   162] loss: 0.361\n",
      "[67,   172] loss: 0.350\n",
      "[67,   182] loss: 0.332\n",
      "[67,   192] loss: 0.346\n",
      "[67,   202] loss: 0.356\n",
      "[67,   212] loss: 0.356\n",
      "[67,   222] loss: 0.351\n",
      "[67,   232] loss: 0.338\n",
      "[67,   242] loss: 0.369\n",
      "[67,   252] loss: 0.356\n",
      "[67,   262] loss: 0.343\n",
      "[67,   272] loss: 0.355\n",
      "[67,   282] loss: 0.349\n",
      "[67,   292] loss: 0.340\n",
      "[67,   302] loss: 0.331\n",
      "[67,   312] loss: 0.381\n",
      "[67,   322] loss: 0.361\n",
      "[67,   332] loss: 0.358\n",
      "[67,   342] loss: 0.350\n",
      "[67,   352] loss: 0.360\n",
      "[67,   362] loss: 0.359\n",
      "[67,   372] loss: 0.344\n",
      "[67,   382] loss: 0.354\n",
      "[68,     2] loss: 0.072\n",
      "[68,    12] loss: 0.346\n",
      "[68,    22] loss: 0.353\n",
      "[68,    32] loss: 0.334\n",
      "[68,    42] loss: 0.341\n",
      "[68,    52] loss: 0.343\n",
      "[68,    62] loss: 0.338\n",
      "[68,    72] loss: 0.338\n",
      "[68,    82] loss: 0.347\n",
      "[68,    92] loss: 0.356\n",
      "[68,   102] loss: 0.344\n",
      "[68,   112] loss: 0.339\n",
      "[68,   122] loss: 0.356\n",
      "[68,   132] loss: 0.351\n",
      "[68,   142] loss: 0.364\n",
      "[68,   152] loss: 0.328\n",
      "[68,   162] loss: 0.342\n",
      "[68,   172] loss: 0.345\n",
      "[68,   182] loss: 0.339\n",
      "[68,   192] loss: 0.340\n",
      "[68,   202] loss: 0.365\n",
      "[68,   212] loss: 0.338\n",
      "[68,   222] loss: 0.327\n",
      "[68,   232] loss: 0.346\n",
      "[68,   242] loss: 0.360\n",
      "[68,   252] loss: 0.336\n",
      "[68,   262] loss: 0.349\n",
      "[68,   272] loss: 0.360\n",
      "[68,   282] loss: 0.332\n",
      "[68,   292] loss: 0.317\n",
      "[68,   302] loss: 0.343\n",
      "[68,   312] loss: 0.348\n",
      "[68,   322] loss: 0.370\n",
      "[68,   332] loss: 0.354\n",
      "[68,   342] loss: 0.342\n",
      "[68,   352] loss: 0.329\n",
      "[68,   362] loss: 0.359\n",
      "[68,   372] loss: 0.341\n",
      "[68,   382] loss: 0.337\n",
      "[69,     2] loss: 0.078\n",
      "[69,    12] loss: 0.368\n",
      "[69,    22] loss: 0.329\n",
      "[69,    32] loss: 0.353\n",
      "[69,    42] loss: 0.337\n",
      "[69,    52] loss: 0.369\n",
      "[69,    62] loss: 0.351\n",
      "[69,    72] loss: 0.325\n",
      "[69,    82] loss: 0.340\n",
      "[69,    92] loss: 0.358\n",
      "[69,   102] loss: 0.341\n",
      "[69,   112] loss: 0.330\n",
      "[69,   122] loss: 0.340\n",
      "[69,   132] loss: 0.339\n",
      "[69,   142] loss: 0.357\n",
      "[69,   152] loss: 0.325\n",
      "[69,   162] loss: 0.346\n",
      "[69,   172] loss: 0.355\n",
      "[69,   182] loss: 0.332\n",
      "[69,   192] loss: 0.339\n",
      "[69,   202] loss: 0.343\n",
      "[69,   212] loss: 0.336\n",
      "[69,   222] loss: 0.354\n",
      "[69,   232] loss: 0.332\n",
      "[69,   242] loss: 0.336\n",
      "[69,   252] loss: 0.343\n",
      "[69,   262] loss: 0.330\n",
      "[69,   272] loss: 0.342\n",
      "[69,   282] loss: 0.328\n",
      "[69,   292] loss: 0.365\n",
      "[69,   302] loss: 0.361\n",
      "[69,   312] loss: 0.358\n",
      "[69,   322] loss: 0.336\n",
      "[69,   332] loss: 0.326\n",
      "[69,   342] loss: 0.325\n",
      "[69,   352] loss: 0.329\n",
      "[69,   362] loss: 0.333\n",
      "[69,   372] loss: 0.356\n",
      "[69,   382] loss: 0.363\n",
      "[70,     2] loss: 0.069\n",
      "[70,    12] loss: 0.337\n",
      "[70,    22] loss: 0.348\n",
      "[70,    32] loss: 0.340\n",
      "[70,    42] loss: 0.353\n",
      "[70,    52] loss: 0.344\n",
      "[70,    62] loss: 0.338\n",
      "[70,    72] loss: 0.344\n",
      "[70,    82] loss: 0.354\n",
      "[70,    92] loss: 0.356\n",
      "[70,   102] loss: 0.357\n",
      "[70,   112] loss: 0.338\n",
      "[70,   122] loss: 0.355\n",
      "[70,   132] loss: 0.347\n",
      "[70,   142] loss: 0.337\n",
      "[70,   152] loss: 0.349\n",
      "[70,   162] loss: 0.360\n",
      "[70,   172] loss: 0.342\n",
      "[70,   182] loss: 0.354\n",
      "[70,   192] loss: 0.341\n",
      "[70,   202] loss: 0.350\n",
      "[70,   212] loss: 0.348\n",
      "[70,   222] loss: 0.351\n",
      "[70,   232] loss: 0.336\n",
      "[70,   242] loss: 0.337\n",
      "[70,   252] loss: 0.343\n",
      "[70,   262] loss: 0.344\n",
      "[70,   272] loss: 0.340\n",
      "[70,   282] loss: 0.339\n",
      "[70,   292] loss: 0.352\n",
      "[70,   302] loss: 0.346\n",
      "[70,   312] loss: 0.360\n",
      "[70,   322] loss: 0.367\n",
      "[70,   332] loss: 0.331\n",
      "[70,   342] loss: 0.337\n",
      "[70,   352] loss: 0.335\n",
      "[70,   362] loss: 0.335\n",
      "[70,   372] loss: 0.339\n",
      "[70,   382] loss: 0.350\n",
      "[71,     2] loss: 0.071\n",
      "[71,    12] loss: 0.335\n",
      "[71,    22] loss: 0.324\n",
      "[71,    32] loss: 0.339\n",
      "[71,    42] loss: 0.356\n",
      "[71,    52] loss: 0.350\n",
      "[71,    62] loss: 0.348\n",
      "[71,    72] loss: 0.359\n",
      "[71,    82] loss: 0.335\n",
      "[71,    92] loss: 0.350\n",
      "[71,   102] loss: 0.365\n",
      "[71,   112] loss: 0.368\n",
      "[71,   122] loss: 0.352\n",
      "[71,   132] loss: 0.351\n",
      "[71,   142] loss: 0.321\n",
      "[71,   152] loss: 0.358\n",
      "[71,   162] loss: 0.347\n",
      "[71,   172] loss: 0.350\n",
      "[71,   182] loss: 0.335\n",
      "[71,   192] loss: 0.373\n",
      "[71,   202] loss: 0.366\n",
      "[71,   212] loss: 0.345\n",
      "[71,   222] loss: 0.334\n",
      "[71,   232] loss: 0.358\n",
      "[71,   242] loss: 0.342\n",
      "[71,   252] loss: 0.330\n",
      "[71,   262] loss: 0.343\n",
      "[71,   272] loss: 0.343\n",
      "[71,   282] loss: 0.353\n",
      "[71,   292] loss: 0.358\n",
      "[71,   302] loss: 0.332\n",
      "[71,   312] loss: 0.351\n",
      "[71,   322] loss: 0.325\n",
      "[71,   332] loss: 0.362\n",
      "[71,   342] loss: 0.347\n",
      "[71,   352] loss: 0.364\n",
      "[71,   362] loss: 0.351\n",
      "[71,   372] loss: 0.356\n",
      "[71,   382] loss: 0.321\n",
      "[72,     2] loss: 0.078\n",
      "[72,    12] loss: 0.338\n",
      "[72,    22] loss: 0.340\n",
      "[72,    32] loss: 0.358\n",
      "[72,    42] loss: 0.330\n",
      "[72,    52] loss: 0.326\n",
      "[72,    62] loss: 0.351\n",
      "[72,    72] loss: 0.351\n",
      "[72,    82] loss: 0.345\n",
      "[72,    92] loss: 0.316\n",
      "[72,   102] loss: 0.330\n",
      "[72,   112] loss: 0.346\n",
      "[72,   122] loss: 0.339\n",
      "[72,   132] loss: 0.364\n",
      "[72,   142] loss: 0.364\n",
      "[72,   152] loss: 0.346\n",
      "[72,   162] loss: 0.336\n",
      "[72,   172] loss: 0.330\n",
      "[72,   182] loss: 0.322\n",
      "[72,   192] loss: 0.348\n",
      "[72,   202] loss: 0.326\n",
      "[72,   212] loss: 0.346\n",
      "[72,   222] loss: 0.349\n",
      "[72,   232] loss: 0.339\n",
      "[72,   242] loss: 0.350\n",
      "[72,   252] loss: 0.343\n",
      "[72,   262] loss: 0.339\n",
      "[72,   272] loss: 0.325\n",
      "[72,   282] loss: 0.319\n",
      "[72,   292] loss: 0.350\n",
      "[72,   302] loss: 0.352\n",
      "[72,   312] loss: 0.346\n",
      "[72,   322] loss: 0.340\n",
      "[72,   332] loss: 0.332\n",
      "[72,   342] loss: 0.354\n",
      "[72,   352] loss: 0.350\n",
      "[72,   362] loss: 0.340\n",
      "[72,   372] loss: 0.342\n",
      "[72,   382] loss: 0.335\n",
      "[73,     2] loss: 0.065\n",
      "[73,    12] loss: 0.331\n",
      "[73,    22] loss: 0.364\n",
      "[73,    32] loss: 0.363\n",
      "[73,    42] loss: 0.360\n",
      "[73,    52] loss: 0.323\n",
      "[73,    62] loss: 0.354\n",
      "[73,    72] loss: 0.349\n",
      "[73,    82] loss: 0.328\n",
      "[73,    92] loss: 0.351\n",
      "[73,   102] loss: 0.357\n",
      "[73,   112] loss: 0.334\n",
      "[73,   122] loss: 0.345\n",
      "[73,   132] loss: 0.331\n",
      "[73,   142] loss: 0.351\n",
      "[73,   152] loss: 0.355\n",
      "[73,   162] loss: 0.330\n",
      "[73,   172] loss: 0.364\n",
      "[73,   182] loss: 0.363\n",
      "[73,   192] loss: 0.341\n",
      "[73,   202] loss: 0.358\n",
      "[73,   212] loss: 0.343\n",
      "[73,   222] loss: 0.312\n",
      "[73,   232] loss: 0.326\n",
      "[73,   242] loss: 0.332\n",
      "[73,   252] loss: 0.351\n",
      "[73,   262] loss: 0.350\n",
      "[73,   272] loss: 0.334\n",
      "[73,   282] loss: 0.356\n",
      "[73,   292] loss: 0.320\n",
      "[73,   302] loss: 0.353\n",
      "[73,   312] loss: 0.348\n",
      "[73,   322] loss: 0.356\n",
      "[73,   332] loss: 0.341\n",
      "[73,   342] loss: 0.340\n",
      "[73,   352] loss: 0.333\n",
      "[73,   362] loss: 0.347\n",
      "[73,   372] loss: 0.325\n",
      "[73,   382] loss: 0.342\n",
      "[74,     2] loss: 0.068\n",
      "[74,    12] loss: 0.338\n",
      "[74,    22] loss: 0.347\n",
      "[74,    32] loss: 0.338\n",
      "[74,    42] loss: 0.353\n",
      "[74,    52] loss: 0.333\n",
      "[74,    62] loss: 0.329\n",
      "[74,    72] loss: 0.333\n",
      "[74,    82] loss: 0.346\n",
      "[74,    92] loss: 0.333\n",
      "[74,   102] loss: 0.339\n",
      "[74,   112] loss: 0.340\n",
      "[74,   122] loss: 0.348\n",
      "[74,   132] loss: 0.369\n",
      "[74,   142] loss: 0.346\n",
      "[74,   152] loss: 0.342\n",
      "[74,   162] loss: 0.357\n",
      "[74,   172] loss: 0.357\n",
      "[74,   182] loss: 0.338\n",
      "[74,   192] loss: 0.331\n",
      "[74,   202] loss: 0.347\n",
      "[74,   212] loss: 0.331\n",
      "[74,   222] loss: 0.332\n",
      "[74,   232] loss: 0.336\n",
      "[74,   242] loss: 0.340\n",
      "[74,   252] loss: 0.314\n",
      "[74,   262] loss: 0.352\n",
      "[74,   272] loss: 0.322\n",
      "[74,   282] loss: 0.340\n",
      "[74,   292] loss: 0.336\n",
      "[74,   302] loss: 0.355\n",
      "[74,   312] loss: 0.346\n",
      "[74,   322] loss: 0.342\n",
      "[74,   332] loss: 0.352\n",
      "[74,   342] loss: 0.324\n",
      "[74,   352] loss: 0.336\n",
      "[74,   362] loss: 0.317\n",
      "[74,   372] loss: 0.326\n",
      "[74,   382] loss: 0.326\n",
      "[75,     2] loss: 0.073\n",
      "[75,    12] loss: 0.387\n",
      "[75,    22] loss: 0.380\n",
      "[75,    32] loss: 0.377\n",
      "[75,    42] loss: 0.349\n",
      "[75,    52] loss: 0.350\n",
      "[75,    62] loss: 0.335\n",
      "[75,    72] loss: 0.342\n",
      "[75,    82] loss: 0.328\n",
      "[75,    92] loss: 0.339\n",
      "[75,   102] loss: 0.381\n",
      "[75,   112] loss: 0.344\n",
      "[75,   122] loss: 0.343\n",
      "[75,   132] loss: 0.331\n",
      "[75,   142] loss: 0.343\n",
      "[75,   152] loss: 0.349\n",
      "[75,   162] loss: 0.338\n",
      "[75,   172] loss: 0.353\n",
      "[75,   182] loss: 0.367\n",
      "[75,   192] loss: 0.323\n",
      "[75,   202] loss: 0.346\n",
      "[75,   212] loss: 0.345\n",
      "[75,   222] loss: 0.338\n",
      "[75,   232] loss: 0.323\n",
      "[75,   242] loss: 0.358\n",
      "[75,   252] loss: 0.372\n",
      "[75,   262] loss: 0.337\n",
      "[75,   272] loss: 0.330\n",
      "[75,   282] loss: 0.312\n",
      "[75,   292] loss: 0.327\n",
      "[75,   302] loss: 0.341\n",
      "[75,   312] loss: 0.330\n",
      "[75,   322] loss: 0.314\n",
      "[75,   332] loss: 0.333\n",
      "[75,   342] loss: 0.349\n",
      "[75,   352] loss: 0.320\n",
      "[75,   362] loss: 0.339\n",
      "[75,   372] loss: 0.344\n",
      "[75,   382] loss: 0.340\n",
      "Finished Training\n",
      "time: 32.81730890274048\n",
      "gpu memory: 0.3375244140625\n",
      "gpu memory: 0.3375244140625\n"
     ]
    },
    {
     "data": {
      "text/plain": "(array([0.97754514, 0.98064893, 0.52000976, ..., 0.50331306, 0.97287995,\n        0.98204786], dtype=float32),\n tensor([0.0932, 0.0918, 0.0659,  ..., 0.0637, 0.0780, 0.0682]),\n 33.02954339981079,\n 0.3375244140625)"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_and_measure_cor_with_change(activation='relu',epoch_num=75,lr=0.001,batch_size=128,hiden_layers=2,genes=1000,cells=5000):\n",
    "    n=genes\n",
    "    p=cells\n",
    "    adata = sc.datasets.blobs(n_variables=n,n_centers=4,cluster_std=1,n_observations=p)\n",
    "    adata.obs['change_weight']= np.zeros(adata.n_obs)\n",
    "    sc.pp.pca(adata)\n",
    "    sc.pp.neighbors(adata)\n",
    "    adata = create_intermediate_state(adata,'blobs',['0','1'])\n",
    "    adata = create_intermediate_state(adata,'blobs',['2','3'])\n",
    "    sc.pp.pca(adata)\n",
    "    sc.pp.neighbors(adata)\n",
    "    sc.tl.umap(adata)\n",
    "    labeles = adata.obs['blobs']\n",
    "    df , were_changed = modify_labels(labeles , probability=0.00)\n",
    "    y_train = adata.obs['blobs']\n",
    "    y_train_indices = y_train.unique()\n",
    "    class_sample_count = np.array(\n",
    "        [sum(y_train == t) for t in y_train_indices])\n",
    "    weight = 1. / class_sample_count\n",
    "    samples_weight= np.zeros(adata.n_obs)\n",
    "    for i in range(adata.n_obs):\n",
    "        for j, t in enumerate(y_train_indices):\n",
    "            if adata.obs['blobs'].iloc[i]==t:\n",
    "                samples_weight[i]=weight[j]\n",
    "    samples_weight = torch.from_numpy(samples_weight)\n",
    "\n",
    "\n",
    "\n",
    "    t = time.time()\n",
    "\n",
    "    one_hot_label , inverted_label = one_hot_encode(df['label'])\n",
    "    net = Net(adata.X.shape[1],output_size=4,activation=activation,hidden_layers=hiden_layers)\n",
    "    net.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
    "    x_data = np.array(adata.X)\n",
    "    sampler = WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'), len(samples_weight))\n",
    "    tensor_x = torch.Tensor(x_data).to(device) # transform to torch tensor\n",
    "    # tensor_y_noisy = torch.Tensor(one_hot_modified_label).to(device)\n",
    "    tensor_y_true = torch.Tensor(one_hot_label).to(device)\n",
    "    my_dataset = TensorDataset(tensor_x,tensor_y_true) # create your datset\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(my_dataset, batch_size=batch_size,\n",
    "                                              sampler=sampler, num_workers=0)\n",
    "\n",
    "    prob_loss_list = []\n",
    "    for epoch in range(epoch_num):  # loop over the dataset multiple times\n",
    "        prob_all=[]\n",
    "\n",
    "        outputs_all = net(tensor_x)\n",
    "        tensor_y_true_temp = torch.Tensor(one_hot_label).to(device)\n",
    "        prob_all = probability_for_confidence(outputs_all, tensor_y_true)\n",
    "\n",
    "        prob_loss_list.append(prob_all.cpu().detach().numpy())\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if i % 10 == 1:    # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 10:.3f}')\n",
    "                running_loss = 0.0\n",
    "            del inputs, labels, outputs, loss\n",
    "            # gc.collect()\n",
    "            # torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "\n",
    "    all_conf , all_var = probability_list_to_confidence_and_var(prob_loss_list, n_obs= adata.n_obs, epoch_num=epoch_num)\n",
    "    adata.obs[\"conf\"] = all_conf.detach().numpy()\n",
    "    # if adata_conf_ref is not None:\n",
    "    #     print(\"ws\")\n",
    "    #     res = stats.wasserstein_distance(adata.obs['conf'], adata_conf_ref)\n",
    "    #     print(res,\"wasserstein_distance\")\n",
    "    # else:\n",
    "    #     res = stats.spearmanr(adata.obs['conf'], adata.obs['change_weight'])\n",
    "    #     print(res,\"spearmanr correlation\")\n",
    "    time_elapsed = time.time() - t\n",
    "    print('time:', time.time()-t)\n",
    "    memory = torch.cuda.memory_allocated()\n",
    "    # #convert to gb\n",
    "    memory_allocated_gb = memory / (1024 ** 3)\n",
    "    print(\"gpu memory:\", memory_allocated_gb)\n",
    "        # Cleanup to free GPU memory\n",
    "    del net, tensor_x, tensor_y_true, my_dataset, trainloader\n",
    "    # del net\n",
    "    # torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"gpu memory:\", torch.cuda.memory_allocated()/ (1024 ** 3))\n",
    "    return all_conf.detach().numpy(), all_var,time.time()-t,memory_allocated_gb\n",
    "train_and_measure_cor_with_change(genes=1000,cells=50000)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-07T11:59:58.895233322Z",
     "start_time": "2024-07-07T11:57:08.062227943Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated())\n",
    "torch.cuda.memory_allocated()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-07T11:59:58.898512688Z",
     "start_time": "2024-07-07T11:59:58.896383131Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-07T11:59:58.905117717Z",
     "start_time": "2024-07-07T11:59:58.899645665Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "#ALSO ADDED THE NUMBET OF GENENS NOT CELL FROM 1000 TO 10000"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-07T11:59:58.909645128Z",
     "start_time": "2024-07-07T11:59:58.905655757Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell number 1000\n",
      "0\n",
      "['0' '3' '0' '1' '3' '3' '1' '3' '1' '1' '3' '0' '1' '2' '0' '0' '3' '2'\n",
      " '2' '1' '3' '2' '3' '1' '2' '0' '2' '1' '1' '0' '1' '0' '0' '0' '2' '1'\n",
      " '3' '1' '3' '1' '1' '1' '0' '0' '0' '0' '2' '2' '0' '1' '3' '1' '3' '2'\n",
      " '3' '0' '0' '1' '2' '3' '3' '0' '0' '3' '3' '1' '2' '1' '3' '0' '1' '0'\n",
      " '2' '3' '3' '3' '1' '2' '2' '3' '2' '0' '1' '3' '0' '3' '3' '1' '3' '1'\n",
      " '2' '3' '0' '0' '2' '2' '1' '3' '1' '0' '0' '2' '0' '0' '1' '2' '3' '3'\n",
      " '2' '2' '3' '1' '3' '2' '1' '1' '1' '0' '3' '1' '1' '1' '0' '0' '2' '1'\n",
      " '1' '0' '0' '3' '1' '3' '0' '3' '0' '2' '0' '2' '0' '3' '1' '3' '0' '1'\n",
      " '1' '1' '1' '0' '0' '2' '0' '2' '0' '0' '2' '1' '2' '3' '0' '1' '0' '3'\n",
      " '0' '3' '0' '3' '1' '2' '3' '2' '1' '3' '0' '2' '3' '0' '0' '2' '3' '0'\n",
      " '0' '0' '0' '3' '1' '0' '1' '0' '3' '1' '3' '1' '2' '3' '3' '1' '2' '2'\n",
      " '2' '2' '1' '2' '1' '1' '3' '3' '0' '1' '0' '1' '2' '2' '2' '2' '3' '1'\n",
      " '0' '2' '3' '3' '0' '1' '2' '3' '3' '3' '2' '0' '3' '3' '2' '2' '3' '2'\n",
      " '2' '3' '3' '0' '2' '1' '3' '3' '1' '0' '0' '0' '1' '1' '1' '3' '2' '2'\n",
      " '2' '1' '3' '0' '1' '1' '2' '1' '0' '0' '1' '1' '1' '2' '1' '3' '1' '3'\n",
      " '0' '0' '1' '1' '0' '2' '3' '2' '2' '1' '0' '1' '3' '3' '1' '1' '3' '2'\n",
      " '1' '0' '3' '2' '2' '0' '2' '0' '1' '2' '3' '2' '2' '1' '1' '2' '1' '3'\n",
      " '1' '0' '0' '2' '3' '1' '3' '3' '2' '0' '1' '3' '3' '2' '3' '2' '3' '0'\n",
      " '2' '2' '0' '3' '1' '3' '0' '0' '1' '1' '2' '2' '0' '2' '1' '1' '3' '2'\n",
      " '2' '3' '1' '0' '2' '0' '0' '0' '2' '1' '3' '1' '2' '3' '0' '2' '1' '2'\n",
      " '2' '2' '2' '2' '0' '0' '3' '3' '0' '2' '1' '3' '0' '3' '1' '2' '0' '0'\n",
      " '1' '1' '1' '3' '1' '2' '1' '1' '3' '2' '2' '0' '1' '3' '0' '1' '0' '3'\n",
      " '3' '2' '0' '3' '0' '0' '1' '1' '0' '2' '0' '3' '3' '1' '3' '2' '0' '2'\n",
      " '2' '3' '1' '2' '0' '3' '1' '1' '0' '0' '0' '3' '1' '1' '2' '2' '3' '1'\n",
      " '1' '0' '0' '2' '1' '2' '3' '1' '3' '1' '0' '1' '2' '3' '0' '1' '2' '3'\n",
      " '2' '1' '3' '3' '2' '2' '2' '3' '2' '2' '2' '0' '1' '1' '2' '1' '2' '1'\n",
      " '2' '1' '2' '2' '0' '3' '2' '1' '3' '1' '3' '3' '2' '2' '3' '1' '1' '1'\n",
      " '0' '1' '0' '1' '2' '2' '3' '1' '0' '3' '0' '2' '1' '3' '0' '0' '2' '2'\n",
      " '3' '2' '3' '3' '2' '3' '0' '1' '2' '3' '2' '3' '3' '1' '0' '3' '2' '1'\n",
      " '3' '2' '1' '1' '0' '3' '0' '3' '2' '3' '0' '2' '2' '0' '3' '1' '0' '1'\n",
      " '2' '1' '2' '1' '2' '1' '2' '0' '0' '2' '3' '0' '1' '2' '2' '2' '0' '1'\n",
      " '3' '2' '3' '2' '1' '3' '0' '2' '3' '0' '0' '0' '2' '2' '2' '1' '3' '3'\n",
      " '0' '2' '3' '0' '0' '1' '0' '3' '0' '3' '0' '2' '1' '0' '3' '0' '3' '2'\n",
      " '0' '3' '1' '3' '2' '1' '2' '2' '2' '3' '0' '0' '0' '3' '3' '3' '1' '0'\n",
      " '1' '2' '1' '0' '1' '3' '3' '0' '0' '0' '0' '0' '1' '0' '1' '1' '3' '2'\n",
      " '1' '3' '2' '2' '0' '1' '3' '2' '1' '2' '0' '0' '3' '0' '0' '0' '1' '3'\n",
      " '2' '0' '3' '1' '0' '0' '3' '1' '2' '1' '0' '1' '3' '0' '3' '0' '2' '2'\n",
      " '0' '1' '1' '2' '3' '3' '2' '2' '1' '1' '1' '0' '1' '0' '2' '3' '1' '3'\n",
      " '1' '1' '1' '2' '3' '3' '0' '2' '0' '1' '2' '1' '2' '0' '2' '0' '1' '2'\n",
      " '1' '3' '0' '1' '3' '1' '3' '1' '3' '3' '2' '2' '0' '3' '3' '1' '2' '2'\n",
      " '1' '1' '0' '0' '1' '2' '1' '3' '0' '0' '1' '0' '1' '0' '0' '2' '1' '2'\n",
      " '1' '2' '3' '0' '2' '0' '0' '3' '0' '2' '3' '1' '3' '0' '1' '0' '2' '1'\n",
      " '2' '2' '3' '0' '3' '0' '1' '2' '0' '1' '3' '2' '3' '2' '0' '0' '3' '1'\n",
      " '0' '3' '1' '0' '1' '1' '2' '0' '3' '0' '2' '1' '3' '2' '0' '0' '3' '0'\n",
      " '1' '3' '2' '3' '2' '3' '3' '0' '1' '1' '3' '0' '1' '1' '0' '0' '1' '2'\n",
      " '3' '1' '1' '3' '0' '0' '3' '1' '1' '1' '2' '1' '1' '0' '3' '3' '3' '2'\n",
      " '1' '3' '3' '3' '0' '2' '3' '3' '1' '2' '0' '1' '3' '3' '0' '2' '0' '3'\n",
      " '1' '0' '3' '2' '2' '1' '3' '2' '1' '2' '2' '2' '1' '0' '0' '3' '0' '0'\n",
      " '2' '3' '1' '1' '0' '3' '3' '2' '1' '0' '0' '2' '1' '3' '2' '0' '0' '3'\n",
      " '0' '3' '1' '1' '1' '0' '3' '0' '0' '2' '3' '1' '2' '1' '3' '2' '1' '3'\n",
      " '1' '3' '2' '0' '0' '3' '0' '0' '2' '0' '2' '1' '0' '2' '2' '3' '2' '1'\n",
      " '1' '2' '1' '3' '2' '1' '2' '2' '0' '1' '1' '2' '3' '1' '0' '2' '3' '2'\n",
      " '1' '0' '0' '3' '2' '2' '2' '2' '3' '2' '2' '0' '2' '3' '3' '1' '3' '1'\n",
      " '3' '2' '2' '0' '0' '3' '3' '2' '3' '2' '0' '3' '3' '2' '1' '0' '1' '0'\n",
      " '3' '2' '3' '2' '2' '3' '2' '3' '3' '0' '2' '3' '0' '2' '0' '0' '1' '2'\n",
      " '3' '2' '3' '3' '2' '0' '0' '0' '3' '0']\n",
      "[0 3 0 1 3 3 1 3 1 1 3 0 1 2 0 0 3 2 2 1 3 2 3 1 2 0 2 1 1 0 1 0 0 0 2 1 3\n",
      " 1 3 1 1 1 0 0 0 0 2 2 0 1 3 1 3 2 3 0 0 1 2 3 3 0 0 3 3 1 2 1 3 0 1 0 2 3\n",
      " 3 3 1 2 2 3 2 0 1 3 0 3 3 1 3 1 2 3 0 0 2 2 1 3 1 0 0 2 0 0 1 2 3 3 2 2 3\n",
      " 1 3 2 1 1 1 0 3 1 1 1 0 0 2 1 1 0 0 3 1 3 0 3 0 2 0 2 0 3 1 3 0 1 1 1 1 0\n",
      " 0 2 0 2 0 0 2 1 2 3 0 1 0 3 0 3 0 3 1 2 3 2 1 3 0 2 3 0 0 2 3 0 0 0 0 3 1\n",
      " 0 1 0 3 1 3 1 2 3 3 1 2 2 2 2 1 2 1 1 3 3 0 1 0 1 2 2 2 2 3 1 0 2 3 3 0 1\n",
      " 2 3 3 3 2 0 3 3 2 2 3 2 2 3 3 0 2 1 3 3 1 0 0 0 1 1 1 3 2 2 2 1 3 0 1 1 2\n",
      " 1 0 0 1 1 1 2 1 3 1 3 0 0 1 1 0 2 3 2 2 1 0 1 3 3 1 1 3 2 1 0 3 2 2 0 2 0\n",
      " 1 2 3 2 2 1 1 2 1 3 1 0 0 2 3 1 3 3 2 0 1 3 3 2 3 2 3 0 2 2 0 3 1 3 0 0 1\n",
      " 1 2 2 0 2 1 1 3 2 2 3 1 0 2 0 0 0 2 1 3 1 2 3 0 2 1 2 2 2 2 2 0 0 3 3 0 2\n",
      " 1 3 0 3 1 2 0 0 1 1 1 3 1 2 1 1 3 2 2 0 1 3 0 1 0 3 3 2 0 3 0 0 1 1 0 2 0\n",
      " 3 3 1 3 2 0 2 2 3 1 2 0 3 1 1 0 0 0 3 1 1 2 2 3 1 1 0 0 2 1 2 3 1 3 1 0 1\n",
      " 2 3 0 1 2 3 2 1 3 3 2 2 2 3 2 2 2 0 1 1 2 1 2 1 2 1 2 2 0 3 2 1 3 1 3 3 2\n",
      " 2 3 1 1 1 0 1 0 1 2 2 3 1 0 3 0 2 1 3 0 0 2 2 3 2 3 3 2 3 0 1 2 3 2 3 3 1\n",
      " 0 3 2 1 3 2 1 1 0 3 0 3 2 3 0 2 2 0 3 1 0 1 2 1 2 1 2 1 2 0 0 2 3 0 1 2 2\n",
      " 2 0 1 3 2 3 2 1 3 0 2 3 0 0 0 2 2 2 1 3 3 0 2 3 0 0 1 0 3 0 3 0 2 1 0 3 0\n",
      " 3 2 0 3 1 3 2 1 2 2 2 3 0 0 0 3 3 3 1 0 1 2 1 0 1 3 3 0 0 0 0 0 1 0 1 1 3\n",
      " 2 1 3 2 2 0 1 3 2 1 2 0 0 3 0 0 0 1 3 2 0 3 1 0 0 3 1 2 1 0 1 3 0 3 0 2 2\n",
      " 0 1 1 2 3 3 2 2 1 1 1 0 1 0 2 3 1 3 1 1 1 2 3 3 0 2 0 1 2 1 2 0 2 0 1 2 1\n",
      " 3 0 1 3 1 3 1 3 3 2 2 0 3 3 1 2 2 1 1 0 0 1 2 1 3 0 0 1 0 1 0 0 2 1 2 1 2\n",
      " 3 0 2 0 0 3 0 2 3 1 3 0 1 0 2 1 2 2 3 0 3 0 1 2 0 1 3 2 3 2 0 0 3 1 0 3 1\n",
      " 0 1 1 2 0 3 0 2 1 3 2 0 0 3 0 1 3 2 3 2 3 3 0 1 1 3 0 1 1 0 0 1 2 3 1 1 3\n",
      " 0 0 3 1 1 1 2 1 1 0 3 3 3 2 1 3 3 3 0 2 3 3 1 2 0 1 3 3 0 2 0 3 1 0 3 2 2\n",
      " 1 3 2 1 2 2 2 1 0 0 3 0 0 2 3 1 1 0 3 3 2 1 0 0 2 1 3 2 0 0 3 0 3 1 1 1 0\n",
      " 3 0 0 2 3 1 2 1 3 2 1 3 1 3 2 0 0 3 0 0 2 0 2 1 0 2 2 3 2 1 1 2 1 3 2 1 2\n",
      " 2 0 1 1 2 3 1 0 2 3 2 1 0 0 3 2 2 2 2 3 2 2 0 2 3 3 1 3 1 3 2 2 0 0 3 3 2\n",
      " 3 2 0 3 3 2 1 0 1 0 3 2 3 2 2 3 2 3 3 0 2 3 0 2 0 0 1 2 3 2 3 3 2 0 0 0 3\n",
      " 0]\n",
      "[1,     2] loss: 0.261\n",
      "[2,     2] loss: 0.121\n",
      "[3,     2] loss: 0.105\n",
      "[4,     2] loss: 0.105\n",
      "[5,     2] loss: 0.096\n",
      "[6,     2] loss: 0.093\n",
      "[7,     2] loss: 0.087\n",
      "[8,     2] loss: 0.086\n",
      "[9,     2] loss: 0.097\n",
      "[10,     2] loss: 0.087\n",
      "[11,     2] loss: 0.094\n",
      "[12,     2] loss: 0.085\n",
      "[13,     2] loss: 0.085\n",
      "[14,     2] loss: 0.092\n",
      "[15,     2] loss: 0.087\n",
      "[16,     2] loss: 0.091\n",
      "[17,     2] loss: 0.077\n",
      "[18,     2] loss: 0.089\n",
      "[19,     2] loss: 0.076\n",
      "[20,     2] loss: 0.079\n",
      "[21,     2] loss: 0.075\n",
      "[22,     2] loss: 0.072\n",
      "[23,     2] loss: 0.095\n",
      "[24,     2] loss: 0.077\n",
      "[25,     2] loss: 0.105\n",
      "[26,     2] loss: 0.079\n",
      "[27,     2] loss: 0.086\n",
      "[28,     2] loss: 0.099\n",
      "[29,     2] loss: 0.078\n",
      "[30,     2] loss: 0.088\n",
      "[31,     2] loss: 0.085\n",
      "[32,     2] loss: 0.084\n",
      "[33,     2] loss: 0.090\n",
      "[34,     2] loss: 0.073\n",
      "[35,     2] loss: 0.082\n",
      "[36,     2] loss: 0.081\n",
      "[37,     2] loss: 0.092\n",
      "[38,     2] loss: 0.082\n",
      "[39,     2] loss: 0.079\n",
      "[40,     2] loss: 0.083\n",
      "[41,     2] loss: 0.091\n",
      "[42,     2] loss: 0.091\n",
      "[43,     2] loss: 0.082\n",
      "[44,     2] loss: 0.073\n",
      "[45,     2] loss: 0.076\n",
      "[46,     2] loss: 0.078\n",
      "[47,     2] loss: 0.069\n",
      "[48,     2] loss: 0.080\n",
      "[49,     2] loss: 0.071\n",
      "[50,     2] loss: 0.072\n",
      "[51,     2] loss: 0.081\n",
      "[52,     2] loss: 0.076\n",
      "[53,     2] loss: 0.076\n",
      "[54,     2] loss: 0.078\n",
      "[55,     2] loss: 0.077\n",
      "[56,     2] loss: 0.076\n",
      "[57,     2] loss: 0.083\n",
      "[58,     2] loss: 0.076\n",
      "[59,     2] loss: 0.071\n",
      "[60,     2] loss: 0.081\n",
      "[61,     2] loss: 0.073\n",
      "[62,     2] loss: 0.074\n",
      "[63,     2] loss: 0.073\n",
      "[64,     2] loss: 0.081\n",
      "[65,     2] loss: 0.074\n",
      "[66,     2] loss: 0.075\n",
      "[67,     2] loss: 0.084\n",
      "[68,     2] loss: 0.063\n",
      "[69,     2] loss: 0.080\n",
      "[70,     2] loss: 0.068\n",
      "[71,     2] loss: 0.073\n",
      "[72,     2] loss: 0.077\n",
      "[73,     2] loss: 0.078\n",
      "[74,     2] loss: 0.085\n",
      "[75,     2] loss: 0.067\n",
      "Finished Training\n",
      "time: 0.7296886444091797\n",
      "gpu memory: 0.014451026916503906\n",
      "gpu memory: 0.014451026916503906\n",
      "cell number 5000\n",
      "0\n",
      "['2' '1' '0' ... '2' '2' '0']\n",
      "[2 1 0 ... 2 2 0]\n",
      "[1,     2] loss: 0.260\n",
      "[1,    12] loss: 0.695\n",
      "[1,    22] loss: 0.509\n",
      "[1,    32] loss: 0.483\n",
      "[2,     2] loss: 0.093\n",
      "[2,    12] loss: 0.441\n",
      "[2,    22] loss: 0.443\n",
      "[2,    32] loss: 0.445\n",
      "[3,     2] loss: 0.089\n",
      "[3,    12] loss: 0.426\n",
      "[3,    22] loss: 0.439\n",
      "[3,    32] loss: 0.462\n",
      "[4,     2] loss: 0.090\n",
      "[4,    12] loss: 0.456\n",
      "[4,    22] loss: 0.444\n",
      "[4,    32] loss: 0.443\n",
      "[5,     2] loss: 0.088\n",
      "[5,    12] loss: 0.440\n",
      "[5,    22] loss: 0.438\n",
      "[5,    32] loss: 0.458\n",
      "[6,     2] loss: 0.089\n",
      "[6,    12] loss: 0.432\n",
      "[6,    22] loss: 0.472\n",
      "[6,    32] loss: 0.425\n",
      "[7,     2] loss: 0.084\n",
      "[7,    12] loss: 0.444\n",
      "[7,    22] loss: 0.446\n",
      "[7,    32] loss: 0.435\n",
      "[8,     2] loss: 0.090\n",
      "[8,    12] loss: 0.395\n",
      "[8,    22] loss: 0.410\n",
      "[8,    32] loss: 0.448\n",
      "[9,     2] loss: 0.091\n",
      "[9,    12] loss: 0.425\n",
      "[9,    22] loss: 0.417\n",
      "[9,    32] loss: 0.424\n",
      "[10,     2] loss: 0.081\n",
      "[10,    12] loss: 0.422\n",
      "[10,    22] loss: 0.404\n",
      "[10,    32] loss: 0.424\n",
      "[11,     2] loss: 0.084\n",
      "[11,    12] loss: 0.414\n",
      "[11,    22] loss: 0.427\n",
      "[11,    32] loss: 0.433\n",
      "[12,     2] loss: 0.080\n",
      "[12,    12] loss: 0.423\n",
      "[12,    22] loss: 0.396\n",
      "[12,    32] loss: 0.400\n",
      "[13,     2] loss: 0.080\n",
      "[13,    12] loss: 0.406\n",
      "[13,    22] loss: 0.416\n",
      "[13,    32] loss: 0.432\n",
      "[14,     2] loss: 0.087\n",
      "[14,    12] loss: 0.430\n",
      "[14,    22] loss: 0.424\n",
      "[14,    32] loss: 0.412\n",
      "[15,     2] loss: 0.079\n",
      "[15,    12] loss: 0.437\n",
      "[15,    22] loss: 0.410\n",
      "[15,    32] loss: 0.392\n",
      "[16,     2] loss: 0.073\n",
      "[16,    12] loss: 0.399\n",
      "[16,    22] loss: 0.422\n",
      "[16,    32] loss: 0.384\n",
      "[17,     2] loss: 0.078\n",
      "[17,    12] loss: 0.391\n",
      "[17,    22] loss: 0.409\n",
      "[17,    32] loss: 0.381\n",
      "[18,     2] loss: 0.093\n",
      "[18,    12] loss: 0.470\n",
      "[18,    22] loss: 0.441\n",
      "[18,    32] loss: 0.404\n",
      "[19,     2] loss: 0.077\n",
      "[19,    12] loss: 0.397\n",
      "[19,    22] loss: 0.399\n",
      "[19,    32] loss: 0.423\n",
      "[20,     2] loss: 0.092\n",
      "[20,    12] loss: 0.389\n",
      "[20,    22] loss: 0.396\n",
      "[20,    32] loss: 0.400\n",
      "[21,     2] loss: 0.078\n",
      "[21,    12] loss: 0.430\n",
      "[21,    22] loss: 0.394\n",
      "[21,    32] loss: 0.398\n",
      "[22,     2] loss: 0.088\n",
      "[22,    12] loss: 0.419\n",
      "[22,    22] loss: 0.439\n",
      "[22,    32] loss: 0.412\n",
      "[23,     2] loss: 0.071\n",
      "[23,    12] loss: 0.412\n",
      "[23,    22] loss: 0.388\n",
      "[23,    32] loss: 0.396\n",
      "[24,     2] loss: 0.081\n",
      "[24,    12] loss: 0.379\n",
      "[24,    22] loss: 0.420\n",
      "[24,    32] loss: 0.408\n",
      "[25,     2] loss: 0.080\n",
      "[25,    12] loss: 0.385\n",
      "[25,    22] loss: 0.363\n",
      "[25,    32] loss: 0.377\n",
      "[26,     2] loss: 0.086\n",
      "[26,    12] loss: 0.401\n",
      "[26,    22] loss: 0.410\n",
      "[26,    32] loss: 0.397\n",
      "[27,     2] loss: 0.075\n",
      "[27,    12] loss: 0.405\n",
      "[27,    22] loss: 0.400\n",
      "[27,    32] loss: 0.397\n",
      "[28,     2] loss: 0.076\n",
      "[28,    12] loss: 0.380\n",
      "[28,    22] loss: 0.411\n",
      "[28,    32] loss: 0.391\n",
      "[29,     2] loss: 0.082\n",
      "[29,    12] loss: 0.394\n",
      "[29,    22] loss: 0.406\n",
      "[29,    32] loss: 0.398\n",
      "[30,     2] loss: 0.075\n",
      "[30,    12] loss: 0.399\n",
      "[30,    22] loss: 0.404\n",
      "[30,    32] loss: 0.401\n",
      "[31,     2] loss: 0.084\n",
      "[31,    12] loss: 0.406\n",
      "[31,    22] loss: 0.397\n",
      "[31,    32] loss: 0.400\n",
      "[32,     2] loss: 0.071\n",
      "[32,    12] loss: 0.405\n",
      "[32,    22] loss: 0.375\n",
      "[32,    32] loss: 0.381\n",
      "[33,     2] loss: 0.082\n",
      "[33,    12] loss: 0.415\n",
      "[33,    22] loss: 0.383\n",
      "[33,    32] loss: 0.400\n",
      "[34,     2] loss: 0.076\n",
      "[34,    12] loss: 0.395\n",
      "[34,    22] loss: 0.409\n",
      "[34,    32] loss: 0.377\n",
      "[35,     2] loss: 0.083\n",
      "[35,    12] loss: 0.381\n",
      "[35,    22] loss: 0.410\n",
      "[35,    32] loss: 0.383\n",
      "[36,     2] loss: 0.083\n",
      "[36,    12] loss: 0.413\n",
      "[36,    22] loss: 0.383\n",
      "[36,    32] loss: 0.367\n",
      "[37,     2] loss: 0.072\n",
      "[37,    12] loss: 0.416\n",
      "[37,    22] loss: 0.386\n",
      "[37,    32] loss: 0.403\n",
      "[38,     2] loss: 0.072\n",
      "[38,    12] loss: 0.384\n",
      "[38,    22] loss: 0.377\n",
      "[38,    32] loss: 0.375\n",
      "[39,     2] loss: 0.082\n",
      "[39,    12] loss: 0.396\n",
      "[39,    22] loss: 0.387\n",
      "[39,    32] loss: 0.386\n",
      "[40,     2] loss: 0.071\n",
      "[40,    12] loss: 0.379\n",
      "[40,    22] loss: 0.382\n",
      "[40,    32] loss: 0.381\n",
      "[41,     2] loss: 0.077\n",
      "[41,    12] loss: 0.379\n",
      "[41,    22] loss: 0.380\n",
      "[41,    32] loss: 0.384\n",
      "[42,     2] loss: 0.076\n",
      "[42,    12] loss: 0.387\n",
      "[42,    22] loss: 0.392\n",
      "[42,    32] loss: 0.370\n",
      "[43,     2] loss: 0.078\n",
      "[43,    12] loss: 0.372\n",
      "[43,    22] loss: 0.364\n",
      "[43,    32] loss: 0.389\n",
      "[44,     2] loss: 0.067\n",
      "[44,    12] loss: 0.375\n",
      "[44,    22] loss: 0.348\n",
      "[44,    32] loss: 0.376\n",
      "[45,     2] loss: 0.064\n",
      "[45,    12] loss: 0.400\n",
      "[45,    22] loss: 0.373\n",
      "[45,    32] loss: 0.368\n",
      "[46,     2] loss: 0.093\n",
      "[46,    12] loss: 0.354\n",
      "[46,    22] loss: 0.357\n",
      "[46,    32] loss: 0.358\n",
      "[47,     2] loss: 0.073\n",
      "[47,    12] loss: 0.387\n",
      "[47,    22] loss: 0.369\n",
      "[47,    32] loss: 0.367\n",
      "[48,     2] loss: 0.071\n",
      "[48,    12] loss: 0.365\n",
      "[48,    22] loss: 0.353\n",
      "[48,    32] loss: 0.365\n",
      "[49,     2] loss: 0.087\n",
      "[49,    12] loss: 0.374\n",
      "[49,    22] loss: 0.379\n",
      "[49,    32] loss: 0.388\n",
      "[50,     2] loss: 0.083\n",
      "[50,    12] loss: 0.387\n",
      "[50,    22] loss: 0.374\n",
      "[50,    32] loss: 0.379\n",
      "[51,     2] loss: 0.077\n",
      "[51,    12] loss: 0.375\n",
      "[51,    22] loss: 0.363\n",
      "[51,    32] loss: 0.344\n",
      "[52,     2] loss: 0.067\n",
      "[52,    12] loss: 0.372\n",
      "[52,    22] loss: 0.375\n",
      "[52,    32] loss: 0.353\n",
      "[53,     2] loss: 0.082\n",
      "[53,    12] loss: 0.374\n",
      "[53,    22] loss: 0.356\n",
      "[53,    32] loss: 0.348\n",
      "[54,     2] loss: 0.071\n",
      "[54,    12] loss: 0.375\n",
      "[54,    22] loss: 0.386\n",
      "[54,    32] loss: 0.336\n",
      "[55,     2] loss: 0.079\n",
      "[55,    12] loss: 0.368\n",
      "[55,    22] loss: 0.363\n",
      "[55,    32] loss: 0.353\n",
      "[56,     2] loss: 0.068\n",
      "[56,    12] loss: 0.352\n",
      "[56,    22] loss: 0.360\n",
      "[56,    32] loss: 0.361\n",
      "[57,     2] loss: 0.080\n",
      "[57,    12] loss: 0.397\n",
      "[57,    22] loss: 0.347\n",
      "[57,    32] loss: 0.354\n",
      "[58,     2] loss: 0.059\n",
      "[58,    12] loss: 0.321\n",
      "[58,    22] loss: 0.331\n",
      "[58,    32] loss: 0.351\n",
      "[59,     2] loss: 0.060\n",
      "[59,    12] loss: 0.367\n",
      "[59,    22] loss: 0.359\n",
      "[59,    32] loss: 0.345\n",
      "[60,     2] loss: 0.079\n",
      "[60,    12] loss: 0.369\n",
      "[60,    22] loss: 0.348\n",
      "[60,    32] loss: 0.359\n",
      "[61,     2] loss: 0.062\n",
      "[61,    12] loss: 0.367\n",
      "[61,    22] loss: 0.384\n",
      "[61,    32] loss: 0.351\n",
      "[62,     2] loss: 0.085\n",
      "[62,    12] loss: 0.350\n",
      "[62,    22] loss: 0.334\n",
      "[62,    32] loss: 0.337\n",
      "[63,     2] loss: 0.077\n",
      "[63,    12] loss: 0.329\n",
      "[63,    22] loss: 0.356\n",
      "[63,    32] loss: 0.317\n",
      "[64,     2] loss: 0.072\n",
      "[64,    12] loss: 0.374\n",
      "[64,    22] loss: 0.364\n",
      "[64,    32] loss: 0.325\n",
      "[65,     2] loss: 0.059\n",
      "[65,    12] loss: 0.357\n",
      "[65,    22] loss: 0.378\n",
      "[65,    32] loss: 0.362\n",
      "[66,     2] loss: 0.075\n",
      "[66,    12] loss: 0.329\n",
      "[66,    22] loss: 0.360\n",
      "[66,    32] loss: 0.306\n",
      "[67,     2] loss: 0.065\n",
      "[67,    12] loss: 0.327\n",
      "[67,    22] loss: 0.318\n",
      "[67,    32] loss: 0.341\n",
      "[68,     2] loss: 0.082\n",
      "[68,    12] loss: 0.326\n",
      "[68,    22] loss: 0.336\n",
      "[68,    32] loss: 0.330\n",
      "[69,     2] loss: 0.061\n",
      "[69,    12] loss: 0.344\n",
      "[69,    22] loss: 0.347\n",
      "[69,    32] loss: 0.355\n",
      "[70,     2] loss: 0.080\n",
      "[70,    12] loss: 0.395\n",
      "[70,    22] loss: 0.356\n",
      "[70,    32] loss: 0.346\n",
      "[71,     2] loss: 0.072\n",
      "[71,    12] loss: 0.374\n",
      "[71,    22] loss: 0.351\n",
      "[71,    32] loss: 0.377\n",
      "[72,     2] loss: 0.080\n",
      "[72,    12] loss: 0.328\n",
      "[72,    22] loss: 0.330\n",
      "[72,    32] loss: 0.328\n",
      "[73,     2] loss: 0.063\n",
      "[73,    12] loss: 0.334\n",
      "[73,    22] loss: 0.330\n",
      "[73,    32] loss: 0.336\n",
      "[74,     2] loss: 0.074\n",
      "[74,    12] loss: 0.353\n",
      "[74,    22] loss: 0.345\n",
      "[74,    32] loss: 0.347\n",
      "[75,     2] loss: 0.071\n",
      "[75,    12] loss: 0.321\n",
      "[75,    22] loss: 0.336\n",
      "[75,    32] loss: 0.317\n",
      "Finished Training\n",
      "time: 3.3919997215270996\n",
      "gpu memory: 0.043161869049072266\n",
      "gpu memory: 0.043161869049072266\n",
      "cell number 10000\n",
      "0\n",
      "['2' '2' '1' ... '1' '3' '0']\n",
      "[2 2 1 ... 1 3 0]\n",
      "[1,     2] loss: 0.296\n",
      "[1,    12] loss: 0.763\n",
      "[1,    22] loss: 0.516\n",
      "[1,    32] loss: 0.504\n",
      "[1,    42] loss: 0.482\n",
      "[1,    52] loss: 0.493\n",
      "[1,    62] loss: 0.471\n",
      "[1,    72] loss: 0.462\n",
      "[2,     2] loss: 0.087\n",
      "[2,    12] loss: 0.474\n",
      "[2,    22] loss: 0.467\n",
      "[2,    32] loss: 0.471\n",
      "[2,    42] loss: 0.451\n",
      "[2,    52] loss: 0.462\n",
      "[2,    62] loss: 0.455\n",
      "[2,    72] loss: 0.442\n",
      "[3,     2] loss: 0.092\n",
      "[3,    12] loss: 0.445\n",
      "[3,    22] loss: 0.457\n",
      "[3,    32] loss: 0.434\n",
      "[3,    42] loss: 0.451\n",
      "[3,    52] loss: 0.444\n",
      "[3,    62] loss: 0.424\n",
      "[3,    72] loss: 0.415\n",
      "[4,     2] loss: 0.081\n",
      "[4,    12] loss: 0.446\n",
      "[4,    22] loss: 0.452\n",
      "[4,    32] loss: 0.432\n",
      "[4,    42] loss: 0.436\n",
      "[4,    52] loss: 0.433\n",
      "[4,    62] loss: 0.425\n",
      "[4,    72] loss: 0.428\n",
      "[5,     2] loss: 0.088\n",
      "[5,    12] loss: 0.434\n",
      "[5,    22] loss: 0.401\n",
      "[5,    32] loss: 0.441\n",
      "[5,    42] loss: 0.407\n",
      "[5,    52] loss: 0.438\n",
      "[5,    62] loss: 0.435\n",
      "[5,    72] loss: 0.437\n",
      "[6,     2] loss: 0.088\n",
      "[6,    12] loss: 0.454\n",
      "[6,    22] loss: 0.420\n",
      "[6,    32] loss: 0.417\n",
      "[6,    42] loss: 0.434\n",
      "[6,    52] loss: 0.410\n",
      "[6,    62] loss: 0.424\n",
      "[6,    72] loss: 0.439\n",
      "[7,     2] loss: 0.088\n",
      "[7,    12] loss: 0.443\n",
      "[7,    22] loss: 0.446\n",
      "[7,    32] loss: 0.426\n",
      "[7,    42] loss: 0.412\n",
      "[7,    52] loss: 0.420\n",
      "[7,    62] loss: 0.430\n",
      "[7,    72] loss: 0.406\n",
      "[8,     2] loss: 0.086\n",
      "[8,    12] loss: 0.434\n",
      "[8,    22] loss: 0.425\n",
      "[8,    32] loss: 0.430\n",
      "[8,    42] loss: 0.435\n",
      "[8,    52] loss: 0.401\n",
      "[8,    62] loss: 0.412\n",
      "[8,    72] loss: 0.446\n",
      "[9,     2] loss: 0.082\n",
      "[9,    12] loss: 0.440\n",
      "[9,    22] loss: 0.429\n",
      "[9,    32] loss: 0.439\n",
      "[9,    42] loss: 0.412\n",
      "[9,    52] loss: 0.396\n",
      "[9,    62] loss: 0.425\n",
      "[9,    72] loss: 0.429\n",
      "[10,     2] loss: 0.089\n",
      "[10,    12] loss: 0.416\n",
      "[10,    22] loss: 0.414\n",
      "[10,    32] loss: 0.409\n",
      "[10,    42] loss: 0.423\n",
      "[10,    52] loss: 0.424\n",
      "[10,    62] loss: 0.422\n",
      "[10,    72] loss: 0.390\n",
      "[11,     2] loss: 0.082\n",
      "[11,    12] loss: 0.400\n",
      "[11,    22] loss: 0.400\n",
      "[11,    32] loss: 0.384\n",
      "[11,    42] loss: 0.414\n",
      "[11,    52] loss: 0.417\n",
      "[11,    62] loss: 0.421\n",
      "[11,    72] loss: 0.420\n",
      "[12,     2] loss: 0.089\n",
      "[12,    12] loss: 0.407\n",
      "[12,    22] loss: 0.407\n",
      "[12,    32] loss: 0.422\n",
      "[12,    42] loss: 0.432\n",
      "[12,    52] loss: 0.407\n",
      "[12,    62] loss: 0.422\n",
      "[12,    72] loss: 0.446\n",
      "[13,     2] loss: 0.080\n",
      "[13,    12] loss: 0.417\n",
      "[13,    22] loss: 0.393\n",
      "[13,    32] loss: 0.384\n",
      "[13,    42] loss: 0.447\n",
      "[13,    52] loss: 0.416\n",
      "[13,    62] loss: 0.398\n",
      "[13,    72] loss: 0.409\n",
      "[14,     2] loss: 0.073\n",
      "[14,    12] loss: 0.399\n",
      "[14,    22] loss: 0.437\n",
      "[14,    32] loss: 0.405\n",
      "[14,    42] loss: 0.422\n",
      "[14,    52] loss: 0.409\n",
      "[14,    62] loss: 0.390\n",
      "[14,    72] loss: 0.391\n",
      "[15,     2] loss: 0.087\n",
      "[15,    12] loss: 0.401\n",
      "[15,    22] loss: 0.412\n",
      "[15,    32] loss: 0.421\n",
      "[15,    42] loss: 0.390\n",
      "[15,    52] loss: 0.425\n",
      "[15,    62] loss: 0.428\n",
      "[15,    72] loss: 0.396\n",
      "[16,     2] loss: 0.077\n",
      "[16,    12] loss: 0.419\n",
      "[16,    22] loss: 0.427\n",
      "[16,    32] loss: 0.417\n",
      "[16,    42] loss: 0.415\n",
      "[16,    52] loss: 0.400\n",
      "[16,    62] loss: 0.410\n",
      "[16,    72] loss: 0.398\n",
      "[17,     2] loss: 0.071\n",
      "[17,    12] loss: 0.397\n",
      "[17,    22] loss: 0.403\n",
      "[17,    32] loss: 0.416\n",
      "[17,    42] loss: 0.425\n",
      "[17,    52] loss: 0.429\n",
      "[17,    62] loss: 0.390\n",
      "[17,    72] loss: 0.395\n",
      "[18,     2] loss: 0.074\n",
      "[18,    12] loss: 0.406\n",
      "[18,    22] loss: 0.389\n",
      "[18,    32] loss: 0.414\n",
      "[18,    42] loss: 0.404\n",
      "[18,    52] loss: 0.410\n",
      "[18,    62] loss: 0.422\n",
      "[18,    72] loss: 0.401\n",
      "[19,     2] loss: 0.087\n",
      "[19,    12] loss: 0.395\n",
      "[19,    22] loss: 0.434\n",
      "[19,    32] loss: 0.425\n",
      "[19,    42] loss: 0.393\n",
      "[19,    52] loss: 0.389\n",
      "[19,    62] loss: 0.411\n",
      "[19,    72] loss: 0.419\n",
      "[20,     2] loss: 0.073\n",
      "[20,    12] loss: 0.424\n",
      "[20,    22] loss: 0.432\n",
      "[20,    32] loss: 0.406\n",
      "[20,    42] loss: 0.397\n",
      "[20,    52] loss: 0.377\n",
      "[20,    62] loss: 0.406\n",
      "[20,    72] loss: 0.392\n",
      "[21,     2] loss: 0.076\n",
      "[21,    12] loss: 0.394\n",
      "[21,    22] loss: 0.395\n",
      "[21,    32] loss: 0.402\n",
      "[21,    42] loss: 0.358\n",
      "[21,    52] loss: 0.413\n",
      "[21,    62] loss: 0.391\n",
      "[21,    72] loss: 0.403\n",
      "[22,     2] loss: 0.095\n",
      "[22,    12] loss: 0.414\n",
      "[22,    22] loss: 0.379\n",
      "[22,    32] loss: 0.395\n",
      "[22,    42] loss: 0.385\n",
      "[22,    52] loss: 0.405\n",
      "[22,    62] loss: 0.410\n",
      "[22,    72] loss: 0.395\n",
      "[23,     2] loss: 0.080\n",
      "[23,    12] loss: 0.402\n",
      "[23,    22] loss: 0.406\n",
      "[23,    32] loss: 0.391\n",
      "[23,    42] loss: 0.399\n",
      "[23,    52] loss: 0.379\n",
      "[23,    62] loss: 0.373\n",
      "[23,    72] loss: 0.380\n",
      "[24,     2] loss: 0.088\n",
      "[24,    12] loss: 0.396\n",
      "[24,    22] loss: 0.399\n",
      "[24,    32] loss: 0.409\n",
      "[24,    42] loss: 0.378\n",
      "[24,    52] loss: 0.436\n",
      "[24,    62] loss: 0.377\n",
      "[24,    72] loss: 0.405\n",
      "[25,     2] loss: 0.080\n",
      "[25,    12] loss: 0.410\n",
      "[25,    22] loss: 0.391\n",
      "[25,    32] loss: 0.379\n",
      "[25,    42] loss: 0.406\n",
      "[25,    52] loss: 0.410\n",
      "[25,    62] loss: 0.387\n",
      "[25,    72] loss: 0.390\n",
      "[26,     2] loss: 0.077\n",
      "[26,    12] loss: 0.381\n",
      "[26,    22] loss: 0.402\n",
      "[26,    32] loss: 0.379\n",
      "[26,    42] loss: 0.411\n",
      "[26,    52] loss: 0.407\n",
      "[26,    62] loss: 0.366\n",
      "[26,    72] loss: 0.381\n",
      "[27,     2] loss: 0.073\n",
      "[27,    12] loss: 0.378\n",
      "[27,    22] loss: 0.420\n",
      "[27,    32] loss: 0.399\n",
      "[27,    42] loss: 0.382\n",
      "[27,    52] loss: 0.381\n",
      "[27,    62] loss: 0.407\n",
      "[27,    72] loss: 0.407\n",
      "[28,     2] loss: 0.074\n",
      "[28,    12] loss: 0.389\n",
      "[28,    22] loss: 0.402\n",
      "[28,    32] loss: 0.389\n",
      "[28,    42] loss: 0.401\n",
      "[28,    52] loss: 0.406\n",
      "[28,    62] loss: 0.392\n",
      "[28,    72] loss: 0.373\n",
      "[29,     2] loss: 0.072\n",
      "[29,    12] loss: 0.374\n",
      "[29,    22] loss: 0.385\n",
      "[29,    32] loss: 0.377\n",
      "[29,    42] loss: 0.410\n",
      "[29,    52] loss: 0.388\n",
      "[29,    62] loss: 0.390\n",
      "[29,    72] loss: 0.387\n",
      "[30,     2] loss: 0.071\n",
      "[30,    12] loss: 0.371\n",
      "[30,    22] loss: 0.402\n",
      "[30,    32] loss: 0.370\n",
      "[30,    42] loss: 0.353\n",
      "[30,    52] loss: 0.379\n",
      "[30,    62] loss: 0.388\n",
      "[30,    72] loss: 0.377\n",
      "[31,     2] loss: 0.086\n",
      "[31,    12] loss: 0.386\n",
      "[31,    22] loss: 0.387\n",
      "[31,    32] loss: 0.385\n",
      "[31,    42] loss: 0.368\n",
      "[31,    52] loss: 0.384\n",
      "[31,    62] loss: 0.353\n",
      "[31,    72] loss: 0.386\n",
      "[32,     2] loss: 0.080\n",
      "[32,    12] loss: 0.390\n",
      "[32,    22] loss: 0.382\n",
      "[32,    32] loss: 0.387\n",
      "[32,    42] loss: 0.375\n",
      "[32,    52] loss: 0.401\n",
      "[32,    62] loss: 0.365\n",
      "[32,    72] loss: 0.380\n",
      "[33,     2] loss: 0.084\n",
      "[33,    12] loss: 0.410\n",
      "[33,    22] loss: 0.402\n",
      "[33,    32] loss: 0.402\n",
      "[33,    42] loss: 0.387\n",
      "[33,    52] loss: 0.378\n",
      "[33,    62] loss: 0.398\n",
      "[33,    72] loss: 0.386\n",
      "[34,     2] loss: 0.080\n",
      "[34,    12] loss: 0.382\n",
      "[34,    22] loss: 0.357\n",
      "[34,    32] loss: 0.398\n",
      "[34,    42] loss: 0.382\n",
      "[34,    52] loss: 0.415\n",
      "[34,    62] loss: 0.381\n",
      "[34,    72] loss: 0.347\n",
      "[35,     2] loss: 0.082\n",
      "[35,    12] loss: 0.375\n",
      "[35,    22] loss: 0.371\n",
      "[35,    32] loss: 0.379\n",
      "[35,    42] loss: 0.388\n",
      "[35,    52] loss: 0.361\n",
      "[35,    62] loss: 0.389\n",
      "[35,    72] loss: 0.376\n",
      "[36,     2] loss: 0.074\n",
      "[36,    12] loss: 0.360\n",
      "[36,    22] loss: 0.372\n",
      "[36,    32] loss: 0.379\n",
      "[36,    42] loss: 0.352\n",
      "[36,    52] loss: 0.354\n",
      "[36,    62] loss: 0.414\n",
      "[36,    72] loss: 0.363\n",
      "[37,     2] loss: 0.076\n",
      "[37,    12] loss: 0.399\n",
      "[37,    22] loss: 0.375\n",
      "[37,    32] loss: 0.378\n",
      "[37,    42] loss: 0.388\n",
      "[37,    52] loss: 0.370\n",
      "[37,    62] loss: 0.376\n",
      "[37,    72] loss: 0.381\n",
      "[38,     2] loss: 0.069\n",
      "[38,    12] loss: 0.378\n",
      "[38,    22] loss: 0.357\n",
      "[38,    32] loss: 0.354\n",
      "[38,    42] loss: 0.394\n",
      "[38,    52] loss: 0.368\n",
      "[38,    62] loss: 0.362\n",
      "[38,    72] loss: 0.378\n",
      "[39,     2] loss: 0.063\n",
      "[39,    12] loss: 0.385\n",
      "[39,    22] loss: 0.367\n",
      "[39,    32] loss: 0.388\n",
      "[39,    42] loss: 0.361\n",
      "[39,    52] loss: 0.394\n",
      "[39,    62] loss: 0.375\n",
      "[39,    72] loss: 0.366\n",
      "[40,     2] loss: 0.077\n",
      "[40,    12] loss: 0.394\n",
      "[40,    22] loss: 0.376\n",
      "[40,    32] loss: 0.366\n",
      "[40,    42] loss: 0.351\n",
      "[40,    52] loss: 0.353\n",
      "[40,    62] loss: 0.388\n",
      "[40,    72] loss: 0.385\n",
      "[41,     2] loss: 0.074\n",
      "[41,    12] loss: 0.380\n",
      "[41,    22] loss: 0.366\n",
      "[41,    32] loss: 0.373\n",
      "[41,    42] loss: 0.393\n",
      "[41,    52] loss: 0.342\n",
      "[41,    62] loss: 0.358\n",
      "[41,    72] loss: 0.363\n",
      "[42,     2] loss: 0.065\n",
      "[42,    12] loss: 0.381\n",
      "[42,    22] loss: 0.383\n",
      "[42,    32] loss: 0.367\n",
      "[42,    42] loss: 0.357\n",
      "[42,    52] loss: 0.361\n",
      "[42,    62] loss: 0.376\n",
      "[42,    72] loss: 0.347\n",
      "[43,     2] loss: 0.074\n",
      "[43,    12] loss: 0.361\n",
      "[43,    22] loss: 0.355\n",
      "[43,    32] loss: 0.347\n",
      "[43,    42] loss: 0.357\n",
      "[43,    52] loss: 0.358\n",
      "[43,    62] loss: 0.365\n",
      "[43,    72] loss: 0.377\n",
      "[44,     2] loss: 0.079\n",
      "[44,    12] loss: 0.351\n",
      "[44,    22] loss: 0.363\n",
      "[44,    32] loss: 0.355\n",
      "[44,    42] loss: 0.355\n",
      "[44,    52] loss: 0.365\n",
      "[44,    62] loss: 0.379\n",
      "[44,    72] loss: 0.360\n",
      "[45,     2] loss: 0.078\n",
      "[45,    12] loss: 0.387\n",
      "[45,    22] loss: 0.361\n",
      "[45,    32] loss: 0.354\n",
      "[45,    42] loss: 0.366\n",
      "[45,    52] loss: 0.368\n",
      "[45,    62] loss: 0.351\n",
      "[45,    72] loss: 0.339\n",
      "[46,     2] loss: 0.088\n",
      "[46,    12] loss: 0.412\n",
      "[46,    22] loss: 0.362\n",
      "[46,    32] loss: 0.353\n",
      "[46,    42] loss: 0.345\n",
      "[46,    52] loss: 0.353\n",
      "[46,    62] loss: 0.359\n",
      "[46,    72] loss: 0.375\n",
      "[47,     2] loss: 0.070\n",
      "[47,    12] loss: 0.354\n",
      "[47,    22] loss: 0.353\n",
      "[47,    32] loss: 0.366\n",
      "[47,    42] loss: 0.351\n",
      "[47,    52] loss: 0.358\n",
      "[47,    62] loss: 0.367\n",
      "[47,    72] loss: 0.377\n",
      "[48,     2] loss: 0.075\n",
      "[48,    12] loss: 0.364\n",
      "[48,    22] loss: 0.341\n",
      "[48,    32] loss: 0.371\n",
      "[48,    42] loss: 0.340\n",
      "[48,    52] loss: 0.354\n",
      "[48,    62] loss: 0.361\n",
      "[48,    72] loss: 0.353\n",
      "[49,     2] loss: 0.071\n",
      "[49,    12] loss: 0.385\n",
      "[49,    22] loss: 0.367\n",
      "[49,    32] loss: 0.351\n",
      "[49,    42] loss: 0.386\n",
      "[49,    52] loss: 0.364\n",
      "[49,    62] loss: 0.366\n",
      "[49,    72] loss: 0.341\n",
      "[50,     2] loss: 0.082\n",
      "[50,    12] loss: 0.356\n",
      "[50,    22] loss: 0.366\n",
      "[50,    32] loss: 0.373\n",
      "[50,    42] loss: 0.355\n",
      "[50,    52] loss: 0.357\n",
      "[50,    62] loss: 0.332\n",
      "[50,    72] loss: 0.344\n",
      "[51,     2] loss: 0.079\n",
      "[51,    12] loss: 0.366\n",
      "[51,    22] loss: 0.360\n",
      "[51,    32] loss: 0.355\n",
      "[51,    42] loss: 0.345\n",
      "[51,    52] loss: 0.351\n",
      "[51,    62] loss: 0.334\n",
      "[51,    72] loss: 0.337\n",
      "[52,     2] loss: 0.062\n",
      "[52,    12] loss: 0.353\n",
      "[52,    22] loss: 0.372\n",
      "[52,    32] loss: 0.382\n",
      "[52,    42] loss: 0.368\n",
      "[52,    52] loss: 0.361\n",
      "[52,    62] loss: 0.370\n",
      "[52,    72] loss: 0.347\n",
      "[53,     2] loss: 0.070\n",
      "[53,    12] loss: 0.366\n",
      "[53,    22] loss: 0.350\n",
      "[53,    32] loss: 0.335\n",
      "[53,    42] loss: 0.355\n",
      "[53,    52] loss: 0.357\n",
      "[53,    62] loss: 0.353\n",
      "[53,    72] loss: 0.344\n",
      "[54,     2] loss: 0.071\n",
      "[54,    12] loss: 0.348\n",
      "[54,    22] loss: 0.359\n",
      "[54,    32] loss: 0.343\n",
      "[54,    42] loss: 0.358\n",
      "[54,    52] loss: 0.353\n",
      "[54,    62] loss: 0.335\n",
      "[54,    72] loss: 0.368\n",
      "[55,     2] loss: 0.075\n",
      "[55,    12] loss: 0.366\n",
      "[55,    22] loss: 0.355\n",
      "[55,    32] loss: 0.330\n",
      "[55,    42] loss: 0.360\n",
      "[55,    52] loss: 0.343\n",
      "[55,    62] loss: 0.347\n",
      "[55,    72] loss: 0.335\n",
      "[56,     2] loss: 0.077\n",
      "[56,    12] loss: 0.376\n",
      "[56,    22] loss: 0.324\n",
      "[56,    32] loss: 0.348\n",
      "[56,    42] loss: 0.355\n",
      "[56,    52] loss: 0.351\n",
      "[56,    62] loss: 0.361\n",
      "[56,    72] loss: 0.357\n",
      "[57,     2] loss: 0.070\n",
      "[57,    12] loss: 0.356\n",
      "[57,    22] loss: 0.351\n",
      "[57,    32] loss: 0.365\n",
      "[57,    42] loss: 0.355\n",
      "[57,    52] loss: 0.351\n",
      "[57,    62] loss: 0.334\n",
      "[57,    72] loss: 0.349\n",
      "[58,     2] loss: 0.076\n",
      "[58,    12] loss: 0.362\n",
      "[58,    22] loss: 0.391\n",
      "[58,    32] loss: 0.366\n",
      "[58,    42] loss: 0.351\n",
      "[58,    52] loss: 0.336\n",
      "[58,    62] loss: 0.331\n",
      "[58,    72] loss: 0.348\n",
      "[59,     2] loss: 0.063\n",
      "[59,    12] loss: 0.360\n",
      "[59,    22] loss: 0.327\n",
      "[59,    32] loss: 0.365\n",
      "[59,    42] loss: 0.331\n",
      "[59,    52] loss: 0.347\n",
      "[59,    62] loss: 0.344\n",
      "[59,    72] loss: 0.340\n",
      "[60,     2] loss: 0.071\n",
      "[60,    12] loss: 0.344\n",
      "[60,    22] loss: 0.344\n",
      "[60,    32] loss: 0.335\n",
      "[60,    42] loss: 0.350\n",
      "[60,    52] loss: 0.354\n",
      "[60,    62] loss: 0.357\n",
      "[60,    72] loss: 0.346\n",
      "[61,     2] loss: 0.077\n",
      "[61,    12] loss: 0.351\n",
      "[61,    22] loss: 0.351\n",
      "[61,    32] loss: 0.347\n",
      "[61,    42] loss: 0.332\n",
      "[61,    52] loss: 0.340\n",
      "[61,    62] loss: 0.324\n",
      "[61,    72] loss: 0.327\n",
      "[62,     2] loss: 0.057\n",
      "[62,    12] loss: 0.341\n",
      "[62,    22] loss: 0.331\n",
      "[62,    32] loss: 0.343\n",
      "[62,    42] loss: 0.334\n",
      "[62,    52] loss: 0.336\n",
      "[62,    62] loss: 0.346\n",
      "[62,    72] loss: 0.322\n",
      "[63,     2] loss: 0.069\n",
      "[63,    12] loss: 0.364\n",
      "[63,    22] loss: 0.377\n",
      "[63,    32] loss: 0.361\n",
      "[63,    42] loss: 0.335\n",
      "[63,    52] loss: 0.359\n",
      "[63,    62] loss: 0.362\n",
      "[63,    72] loss: 0.335\n",
      "[64,     2] loss: 0.076\n",
      "[64,    12] loss: 0.348\n",
      "[64,    22] loss: 0.331\n",
      "[64,    32] loss: 0.336\n",
      "[64,    42] loss: 0.348\n",
      "[64,    52] loss: 0.351\n",
      "[64,    62] loss: 0.339\n",
      "[64,    72] loss: 0.340\n",
      "[65,     2] loss: 0.072\n",
      "[65,    12] loss: 0.337\n",
      "[65,    22] loss: 0.313\n",
      "[65,    32] loss: 0.347\n",
      "[65,    42] loss: 0.342\n",
      "[65,    52] loss: 0.323\n",
      "[65,    62] loss: 0.345\n",
      "[65,    72] loss: 0.313\n",
      "[66,     2] loss: 0.062\n",
      "[66,    12] loss: 0.352\n",
      "[66,    22] loss: 0.352\n",
      "[66,    32] loss: 0.335\n",
      "[66,    42] loss: 0.344\n",
      "[66,    52] loss: 0.332\n",
      "[66,    62] loss: 0.333\n",
      "[66,    72] loss: 0.308\n",
      "[67,     2] loss: 0.068\n",
      "[67,    12] loss: 0.333\n",
      "[67,    22] loss: 0.361\n",
      "[67,    32] loss: 0.335\n",
      "[67,    42] loss: 0.343\n",
      "[67,    52] loss: 0.333\n",
      "[67,    62] loss: 0.330\n",
      "[67,    72] loss: 0.311\n",
      "[68,     2] loss: 0.078\n",
      "[68,    12] loss: 0.372\n",
      "[68,    22] loss: 0.373\n",
      "[68,    32] loss: 0.349\n",
      "[68,    42] loss: 0.356\n",
      "[68,    52] loss: 0.353\n",
      "[68,    62] loss: 0.329\n",
      "[68,    72] loss: 0.327\n",
      "[69,     2] loss: 0.081\n",
      "[69,    12] loss: 0.347\n",
      "[69,    22] loss: 0.369\n",
      "[69,    32] loss: 0.345\n",
      "[69,    42] loss: 0.336\n",
      "[69,    52] loss: 0.342\n",
      "[69,    62] loss: 0.328\n",
      "[69,    72] loss: 0.361\n",
      "[70,     2] loss: 0.062\n",
      "[70,    12] loss: 0.336\n",
      "[70,    22] loss: 0.338\n",
      "[70,    32] loss: 0.350\n",
      "[70,    42] loss: 0.334\n",
      "[70,    52] loss: 0.338\n",
      "[70,    62] loss: 0.321\n",
      "[70,    72] loss: 0.323\n",
      "[71,     2] loss: 0.080\n",
      "[71,    12] loss: 0.309\n",
      "[71,    22] loss: 0.337\n",
      "[71,    32] loss: 0.328\n",
      "[71,    42] loss: 0.338\n",
      "[71,    52] loss: 0.348\n",
      "[71,    62] loss: 0.321\n",
      "[71,    72] loss: 0.370\n",
      "[72,     2] loss: 0.070\n",
      "[72,    12] loss: 0.425\n",
      "[72,    22] loss: 0.368\n",
      "[72,    32] loss: 0.339\n",
      "[72,    42] loss: 0.341\n",
      "[72,    52] loss: 0.326\n",
      "[72,    62] loss: 0.339\n",
      "[72,    72] loss: 0.323\n",
      "[73,     2] loss: 0.074\n",
      "[73,    12] loss: 0.315\n",
      "[73,    22] loss: 0.334\n",
      "[73,    32] loss: 0.325\n",
      "[73,    42] loss: 0.309\n",
      "[73,    52] loss: 0.321\n",
      "[73,    62] loss: 0.321\n",
      "[73,    72] loss: 0.326\n",
      "[74,     2] loss: 0.067\n",
      "[74,    12] loss: 0.323\n",
      "[74,    22] loss: 0.334\n",
      "[74,    32] loss: 0.334\n",
      "[74,    42] loss: 0.324\n",
      "[74,    52] loss: 0.328\n",
      "[74,    62] loss: 0.340\n",
      "[74,    72] loss: 0.349\n",
      "[75,     2] loss: 0.067\n",
      "[75,    12] loss: 0.333\n",
      "[75,    22] loss: 0.331\n",
      "[75,    32] loss: 0.337\n",
      "[75,    42] loss: 0.326\n",
      "[75,    52] loss: 0.319\n",
      "[75,    62] loss: 0.320\n",
      "[75,    72] loss: 0.311\n",
      "Finished Training\n",
      "time: 7.165190935134888\n",
      "gpu memory: 0.07517290115356445\n",
      "gpu memory: 0.07517290115356445\n",
      "cell number 20000\n",
      "0\n",
      "['1' '0' '2' ... '0' '0' '3']\n",
      "[1 0 2 ... 0 0 3]\n",
      "[1,     2] loss: 0.299\n",
      "[1,    12] loss: 0.699\n",
      "[1,    22] loss: 0.518\n",
      "[1,    32] loss: 0.481\n",
      "[1,    42] loss: 0.472\n",
      "[1,    52] loss: 0.494\n",
      "[1,    62] loss: 0.470\n",
      "[1,    72] loss: 0.477\n",
      "[1,    82] loss: 0.458\n",
      "[1,    92] loss: 0.434\n",
      "[1,   102] loss: 0.485\n",
      "[1,   112] loss: 0.452\n",
      "[1,   122] loss: 0.477\n",
      "[1,   132] loss: 0.457\n",
      "[1,   142] loss: 0.440\n",
      "[1,   152] loss: 0.452\n",
      "[2,     2] loss: 0.083\n",
      "[2,    12] loss: 0.419\n",
      "[2,    22] loss: 0.433\n",
      "[2,    32] loss: 0.474\n",
      "[2,    42] loss: 0.432\n",
      "[2,    52] loss: 0.424\n",
      "[2,    62] loss: 0.438\n",
      "[2,    72] loss: 0.451\n",
      "[2,    82] loss: 0.435\n",
      "[2,    92] loss: 0.435\n",
      "[2,   102] loss: 0.438\n",
      "[2,   112] loss: 0.425\n",
      "[2,   122] loss: 0.432\n",
      "[2,   132] loss: 0.434\n",
      "[2,   142] loss: 0.420\n",
      "[2,   152] loss: 0.445\n",
      "[3,     2] loss: 0.083\n",
      "[3,    12] loss: 0.411\n",
      "[3,    22] loss: 0.424\n",
      "[3,    32] loss: 0.437\n",
      "[3,    42] loss: 0.412\n",
      "[3,    52] loss: 0.425\n",
      "[3,    62] loss: 0.430\n",
      "[3,    72] loss: 0.413\n",
      "[3,    82] loss: 0.437\n",
      "[3,    92] loss: 0.428\n",
      "[3,   102] loss: 0.435\n",
      "[3,   112] loss: 0.421\n",
      "[3,   122] loss: 0.435\n",
      "[3,   132] loss: 0.425\n",
      "[3,   142] loss: 0.424\n",
      "[3,   152] loss: 0.447\n",
      "[4,     2] loss: 0.085\n",
      "[4,    12] loss: 0.412\n",
      "[4,    22] loss: 0.437\n",
      "[4,    32] loss: 0.420\n",
      "[4,    42] loss: 0.416\n",
      "[4,    52] loss: 0.453\n",
      "[4,    62] loss: 0.448\n",
      "[4,    72] loss: 0.411\n",
      "[4,    82] loss: 0.419\n",
      "[4,    92] loss: 0.414\n",
      "[4,   102] loss: 0.429\n",
      "[4,   112] loss: 0.437\n",
      "[4,   122] loss: 0.427\n",
      "[4,   132] loss: 0.426\n",
      "[4,   142] loss: 0.413\n",
      "[4,   152] loss: 0.426\n",
      "[5,     2] loss: 0.083\n",
      "[5,    12] loss: 0.400\n",
      "[5,    22] loss: 0.399\n",
      "[5,    32] loss: 0.400\n",
      "[5,    42] loss: 0.429\n",
      "[5,    52] loss: 0.428\n",
      "[5,    62] loss: 0.407\n",
      "[5,    72] loss: 0.431\n",
      "[5,    82] loss: 0.400\n",
      "[5,    92] loss: 0.422\n",
      "[5,   102] loss: 0.411\n",
      "[5,   112] loss: 0.410\n",
      "[5,   122] loss: 0.414\n",
      "[5,   132] loss: 0.434\n",
      "[5,   142] loss: 0.415\n",
      "[5,   152] loss: 0.404\n",
      "[6,     2] loss: 0.086\n",
      "[6,    12] loss: 0.413\n",
      "[6,    22] loss: 0.423\n",
      "[6,    32] loss: 0.438\n",
      "[6,    42] loss: 0.404\n",
      "[6,    52] loss: 0.413\n",
      "[6,    62] loss: 0.453\n",
      "[6,    72] loss: 0.426\n",
      "[6,    82] loss: 0.436\n",
      "[6,    92] loss: 0.425\n",
      "[6,   102] loss: 0.411\n",
      "[6,   112] loss: 0.420\n",
      "[6,   122] loss: 0.400\n",
      "[6,   132] loss: 0.409\n",
      "[6,   142] loss: 0.412\n",
      "[6,   152] loss: 0.408\n",
      "[7,     2] loss: 0.084\n",
      "[7,    12] loss: 0.408\n",
      "[7,    22] loss: 0.425\n",
      "[7,    32] loss: 0.446\n",
      "[7,    42] loss: 0.412\n",
      "[7,    52] loss: 0.414\n",
      "[7,    62] loss: 0.414\n",
      "[7,    72] loss: 0.391\n",
      "[7,    82] loss: 0.394\n",
      "[7,    92] loss: 0.410\n",
      "[7,   102] loss: 0.419\n",
      "[7,   112] loss: 0.417\n",
      "[7,   122] loss: 0.425\n",
      "[7,   132] loss: 0.430\n",
      "[7,   142] loss: 0.411\n",
      "[7,   152] loss: 0.425\n",
      "[8,     2] loss: 0.080\n",
      "[8,    12] loss: 0.435\n",
      "[8,    22] loss: 0.447\n",
      "[8,    32] loss: 0.422\n",
      "[8,    42] loss: 0.419\n",
      "[8,    52] loss: 0.401\n",
      "[8,    62] loss: 0.434\n",
      "[8,    72] loss: 0.409\n",
      "[8,    82] loss: 0.437\n",
      "[8,    92] loss: 0.406\n",
      "[8,   102] loss: 0.398\n",
      "[8,   112] loss: 0.392\n",
      "[8,   122] loss: 0.413\n",
      "[8,   132] loss: 0.407\n",
      "[8,   142] loss: 0.417\n",
      "[8,   152] loss: 0.406\n",
      "[9,     2] loss: 0.086\n",
      "[9,    12] loss: 0.421\n",
      "[9,    22] loss: 0.401\n",
      "[9,    32] loss: 0.419\n",
      "[9,    42] loss: 0.428\n",
      "[9,    52] loss: 0.402\n",
      "[9,    62] loss: 0.390\n",
      "[9,    72] loss: 0.407\n",
      "[9,    82] loss: 0.412\n",
      "[9,    92] loss: 0.389\n",
      "[9,   102] loss: 0.425\n",
      "[9,   112] loss: 0.396\n",
      "[9,   122] loss: 0.393\n",
      "[9,   132] loss: 0.404\n",
      "[9,   142] loss: 0.392\n",
      "[9,   152] loss: 0.415\n",
      "[10,     2] loss: 0.076\n",
      "[10,    12] loss: 0.402\n",
      "[10,    22] loss: 0.399\n",
      "[10,    32] loss: 0.432\n",
      "[10,    42] loss: 0.388\n",
      "[10,    52] loss: 0.408\n",
      "[10,    62] loss: 0.405\n",
      "[10,    72] loss: 0.414\n",
      "[10,    82] loss: 0.398\n",
      "[10,    92] loss: 0.402\n",
      "[10,   102] loss: 0.420\n",
      "[10,   112] loss: 0.396\n",
      "[10,   122] loss: 0.407\n",
      "[10,   132] loss: 0.417\n",
      "[10,   142] loss: 0.402\n",
      "[10,   152] loss: 0.415\n",
      "[11,     2] loss: 0.086\n",
      "[11,    12] loss: 0.429\n",
      "[11,    22] loss: 0.430\n",
      "[11,    32] loss: 0.433\n",
      "[11,    42] loss: 0.399\n",
      "[11,    52] loss: 0.426\n",
      "[11,    62] loss: 0.400\n",
      "[11,    72] loss: 0.415\n",
      "[11,    82] loss: 0.393\n",
      "[11,    92] loss: 0.384\n",
      "[11,   102] loss: 0.400\n",
      "[11,   112] loss: 0.415\n",
      "[11,   122] loss: 0.386\n",
      "[11,   132] loss: 0.409\n",
      "[11,   142] loss: 0.416\n",
      "[11,   152] loss: 0.420\n",
      "[12,     2] loss: 0.091\n",
      "[12,    12] loss: 0.406\n",
      "[12,    22] loss: 0.404\n",
      "[12,    32] loss: 0.385\n",
      "[12,    42] loss: 0.389\n",
      "[12,    52] loss: 0.415\n",
      "[12,    62] loss: 0.387\n",
      "[12,    72] loss: 0.401\n",
      "[12,    82] loss: 0.392\n",
      "[12,    92] loss: 0.403\n",
      "[12,   102] loss: 0.401\n",
      "[12,   112] loss: 0.409\n",
      "[12,   122] loss: 0.394\n",
      "[12,   132] loss: 0.402\n",
      "[12,   142] loss: 0.400\n",
      "[12,   152] loss: 0.396\n",
      "[13,     2] loss: 0.067\n",
      "[13,    12] loss: 0.417\n",
      "[13,    22] loss: 0.386\n",
      "[13,    32] loss: 0.375\n",
      "[13,    42] loss: 0.395\n",
      "[13,    52] loss: 0.415\n",
      "[13,    62] loss: 0.398\n",
      "[13,    72] loss: 0.386\n",
      "[13,    82] loss: 0.408\n",
      "[13,    92] loss: 0.401\n",
      "[13,   102] loss: 0.421\n",
      "[13,   112] loss: 0.395\n",
      "[13,   122] loss: 0.378\n",
      "[13,   132] loss: 0.395\n",
      "[13,   142] loss: 0.365\n",
      "[13,   152] loss: 0.390\n",
      "[14,     2] loss: 0.083\n",
      "[14,    12] loss: 0.394\n",
      "[14,    22] loss: 0.372\n",
      "[14,    32] loss: 0.393\n",
      "[14,    42] loss: 0.416\n",
      "[14,    52] loss: 0.378\n",
      "[14,    62] loss: 0.424\n",
      "[14,    72] loss: 0.418\n",
      "[14,    82] loss: 0.380\n",
      "[14,    92] loss: 0.388\n",
      "[14,   102] loss: 0.391\n",
      "[14,   112] loss: 0.424\n",
      "[14,   122] loss: 0.376\n",
      "[14,   132] loss: 0.403\n",
      "[14,   142] loss: 0.385\n",
      "[14,   152] loss: 0.382\n",
      "[15,     2] loss: 0.079\n",
      "[15,    12] loss: 0.411\n",
      "[15,    22] loss: 0.362\n",
      "[15,    32] loss: 0.394\n",
      "[15,    42] loss: 0.374\n",
      "[15,    52] loss: 0.414\n",
      "[15,    62] loss: 0.388\n",
      "[15,    72] loss: 0.403\n",
      "[15,    82] loss: 0.386\n",
      "[15,    92] loss: 0.406\n",
      "[15,   102] loss: 0.388\n",
      "[15,   112] loss: 0.423\n",
      "[15,   122] loss: 0.386\n",
      "[15,   132] loss: 0.398\n",
      "[15,   142] loss: 0.391\n",
      "[15,   152] loss: 0.406\n",
      "[16,     2] loss: 0.074\n",
      "[16,    12] loss: 0.389\n",
      "[16,    22] loss: 0.399\n",
      "[16,    32] loss: 0.400\n",
      "[16,    42] loss: 0.387\n",
      "[16,    52] loss: 0.413\n",
      "[16,    62] loss: 0.411\n",
      "[16,    72] loss: 0.389\n",
      "[16,    82] loss: 0.397\n",
      "[16,    92] loss: 0.383\n",
      "[16,   102] loss: 0.393\n",
      "[16,   112] loss: 0.389\n",
      "[16,   122] loss: 0.412\n",
      "[16,   132] loss: 0.396\n",
      "[16,   142] loss: 0.372\n",
      "[16,   152] loss: 0.401\n",
      "[17,     2] loss: 0.075\n",
      "[17,    12] loss: 0.399\n",
      "[17,    22] loss: 0.405\n",
      "[17,    32] loss: 0.395\n",
      "[17,    42] loss: 0.384\n",
      "[17,    52] loss: 0.375\n",
      "[17,    62] loss: 0.391\n",
      "[17,    72] loss: 0.409\n",
      "[17,    82] loss: 0.381\n",
      "[17,    92] loss: 0.380\n",
      "[17,   102] loss: 0.381\n",
      "[17,   112] loss: 0.389\n",
      "[17,   122] loss: 0.392\n",
      "[17,   132] loss: 0.376\n",
      "[17,   142] loss: 0.385\n",
      "[17,   152] loss: 0.404\n",
      "[18,     2] loss: 0.077\n",
      "[18,    12] loss: 0.414\n",
      "[18,    22] loss: 0.361\n",
      "[18,    32] loss: 0.392\n",
      "[18,    42] loss: 0.414\n",
      "[18,    52] loss: 0.375\n",
      "[18,    62] loss: 0.396\n",
      "[18,    72] loss: 0.391\n",
      "[18,    82] loss: 0.413\n",
      "[18,    92] loss: 0.417\n",
      "[18,   102] loss: 0.399\n",
      "[18,   112] loss: 0.376\n",
      "[18,   122] loss: 0.402\n",
      "[18,   132] loss: 0.395\n",
      "[18,   142] loss: 0.411\n",
      "[18,   152] loss: 0.387\n",
      "[19,     2] loss: 0.081\n",
      "[19,    12] loss: 0.405\n",
      "[19,    22] loss: 0.407\n",
      "[19,    32] loss: 0.411\n",
      "[19,    42] loss: 0.415\n",
      "[19,    52] loss: 0.376\n",
      "[19,    62] loss: 0.393\n",
      "[19,    72] loss: 0.379\n",
      "[19,    82] loss: 0.382\n",
      "[19,    92] loss: 0.393\n",
      "[19,   102] loss: 0.388\n",
      "[19,   112] loss: 0.380\n",
      "[19,   122] loss: 0.382\n",
      "[19,   132] loss: 0.387\n",
      "[19,   142] loss: 0.374\n",
      "[19,   152] loss: 0.387\n",
      "[20,     2] loss: 0.082\n",
      "[20,    12] loss: 0.389\n",
      "[20,    22] loss: 0.390\n",
      "[20,    32] loss: 0.396\n",
      "[20,    42] loss: 0.419\n",
      "[20,    52] loss: 0.400\n",
      "[20,    62] loss: 0.372\n",
      "[20,    72] loss: 0.393\n",
      "[20,    82] loss: 0.408\n",
      "[20,    92] loss: 0.383\n",
      "[20,   102] loss: 0.395\n",
      "[20,   112] loss: 0.416\n",
      "[20,   122] loss: 0.386\n",
      "[20,   132] loss: 0.395\n",
      "[20,   142] loss: 0.393\n",
      "[20,   152] loss: 0.378\n",
      "[21,     2] loss: 0.079\n",
      "[21,    12] loss: 0.364\n",
      "[21,    22] loss: 0.378\n",
      "[21,    32] loss: 0.400\n",
      "[21,    42] loss: 0.381\n",
      "[21,    52] loss: 0.385\n",
      "[21,    62] loss: 0.369\n",
      "[21,    72] loss: 0.372\n",
      "[21,    82] loss: 0.379\n",
      "[21,    92] loss: 0.371\n",
      "[21,   102] loss: 0.373\n",
      "[21,   112] loss: 0.397\n",
      "[21,   122] loss: 0.388\n",
      "[21,   132] loss: 0.402\n",
      "[21,   142] loss: 0.413\n",
      "[21,   152] loss: 0.387\n",
      "[22,     2] loss: 0.083\n",
      "[22,    12] loss: 0.382\n",
      "[22,    22] loss: 0.389\n",
      "[22,    32] loss: 0.374\n",
      "[22,    42] loss: 0.367\n",
      "[22,    52] loss: 0.388\n",
      "[22,    62] loss: 0.373\n",
      "[22,    72] loss: 0.382\n",
      "[22,    82] loss: 0.388\n",
      "[22,    92] loss: 0.382\n",
      "[22,   102] loss: 0.398\n",
      "[22,   112] loss: 0.364\n",
      "[22,   122] loss: 0.382\n",
      "[22,   132] loss: 0.389\n",
      "[22,   142] loss: 0.378\n",
      "[22,   152] loss: 0.404\n",
      "[23,     2] loss: 0.074\n",
      "[23,    12] loss: 0.394\n",
      "[23,    22] loss: 0.398\n",
      "[23,    32] loss: 0.400\n",
      "[23,    42] loss: 0.361\n",
      "[23,    52] loss: 0.377\n",
      "[23,    62] loss: 0.393\n",
      "[23,    72] loss: 0.381\n",
      "[23,    82] loss: 0.371\n",
      "[23,    92] loss: 0.397\n",
      "[23,   102] loss: 0.381\n",
      "[23,   112] loss: 0.386\n",
      "[23,   122] loss: 0.385\n",
      "[23,   132] loss: 0.371\n",
      "[23,   142] loss: 0.386\n",
      "[23,   152] loss: 0.386\n",
      "[24,     2] loss: 0.070\n",
      "[24,    12] loss: 0.415\n",
      "[24,    22] loss: 0.380\n",
      "[24,    32] loss: 0.392\n",
      "[24,    42] loss: 0.378\n",
      "[24,    52] loss: 0.376\n",
      "[24,    62] loss: 0.388\n",
      "[24,    72] loss: 0.376\n",
      "[24,    82] loss: 0.354\n",
      "[24,    92] loss: 0.391\n",
      "[24,   102] loss: 0.385\n",
      "[24,   112] loss: 0.400\n",
      "[24,   122] loss: 0.389\n",
      "[24,   132] loss: 0.397\n",
      "[24,   142] loss: 0.365\n",
      "[24,   152] loss: 0.386\n",
      "[25,     2] loss: 0.073\n",
      "[25,    12] loss: 0.377\n",
      "[25,    22] loss: 0.410\n",
      "[25,    32] loss: 0.356\n",
      "[25,    42] loss: 0.374\n",
      "[25,    52] loss: 0.381\n",
      "[25,    62] loss: 0.372\n",
      "[25,    72] loss: 0.372\n",
      "[25,    82] loss: 0.396\n",
      "[25,    92] loss: 0.363\n",
      "[25,   102] loss: 0.370\n",
      "[25,   112] loss: 0.363\n",
      "[25,   122] loss: 0.372\n",
      "[25,   132] loss: 0.372\n",
      "[25,   142] loss: 0.362\n",
      "[25,   152] loss: 0.356\n",
      "[26,     2] loss: 0.080\n",
      "[26,    12] loss: 0.372\n",
      "[26,    22] loss: 0.346\n",
      "[26,    32] loss: 0.372\n",
      "[26,    42] loss: 0.387\n",
      "[26,    52] loss: 0.383\n",
      "[26,    62] loss: 0.381\n",
      "[26,    72] loss: 0.403\n",
      "[26,    82] loss: 0.379\n",
      "[26,    92] loss: 0.379\n",
      "[26,   102] loss: 0.370\n",
      "[26,   112] loss: 0.379\n",
      "[26,   122] loss: 0.379\n",
      "[26,   132] loss: 0.387\n",
      "[26,   142] loss: 0.377\n",
      "[26,   152] loss: 0.356\n",
      "[27,     2] loss: 0.077\n",
      "[27,    12] loss: 0.356\n",
      "[27,    22] loss: 0.376\n",
      "[27,    32] loss: 0.409\n",
      "[27,    42] loss: 0.352\n",
      "[27,    52] loss: 0.356\n",
      "[27,    62] loss: 0.367\n",
      "[27,    72] loss: 0.389\n",
      "[27,    82] loss: 0.385\n",
      "[27,    92] loss: 0.384\n",
      "[27,   102] loss: 0.371\n",
      "[27,   112] loss: 0.365\n",
      "[27,   122] loss: 0.371\n",
      "[27,   132] loss: 0.385\n",
      "[27,   142] loss: 0.375\n",
      "[27,   152] loss: 0.378\n",
      "[28,     2] loss: 0.077\n",
      "[28,    12] loss: 0.344\n",
      "[28,    22] loss: 0.390\n",
      "[28,    32] loss: 0.361\n",
      "[28,    42] loss: 0.383\n",
      "[28,    52] loss: 0.381\n",
      "[28,    62] loss: 0.383\n",
      "[28,    72] loss: 0.370\n",
      "[28,    82] loss: 0.380\n",
      "[28,    92] loss: 0.373\n",
      "[28,   102] loss: 0.363\n",
      "[28,   112] loss: 0.358\n",
      "[28,   122] loss: 0.367\n",
      "[28,   132] loss: 0.377\n",
      "[28,   142] loss: 0.392\n",
      "[28,   152] loss: 0.390\n",
      "[29,     2] loss: 0.082\n",
      "[29,    12] loss: 0.353\n",
      "[29,    22] loss: 0.370\n",
      "[29,    32] loss: 0.390\n",
      "[29,    42] loss: 0.386\n",
      "[29,    52] loss: 0.373\n",
      "[29,    62] loss: 0.369\n",
      "[29,    72] loss: 0.371\n",
      "[29,    82] loss: 0.358\n",
      "[29,    92] loss: 0.372\n",
      "[29,   102] loss: 0.388\n",
      "[29,   112] loss: 0.366\n",
      "[29,   122] loss: 0.363\n",
      "[29,   132] loss: 0.388\n",
      "[29,   142] loss: 0.373\n",
      "[29,   152] loss: 0.367\n",
      "[30,     2] loss: 0.077\n",
      "[30,    12] loss: 0.395\n",
      "[30,    22] loss: 0.398\n",
      "[30,    32] loss: 0.366\n",
      "[30,    42] loss: 0.380\n",
      "[30,    52] loss: 0.377\n",
      "[30,    62] loss: 0.374\n",
      "[30,    72] loss: 0.385\n",
      "[30,    82] loss: 0.383\n",
      "[30,    92] loss: 0.360\n",
      "[30,   102] loss: 0.371\n",
      "[30,   112] loss: 0.368\n",
      "[30,   122] loss: 0.368\n",
      "[30,   132] loss: 0.346\n",
      "[30,   142] loss: 0.373\n",
      "[30,   152] loss: 0.390\n",
      "[31,     2] loss: 0.083\n",
      "[31,    12] loss: 0.382\n",
      "[31,    22] loss: 0.372\n",
      "[31,    32] loss: 0.396\n",
      "[31,    42] loss: 0.376\n",
      "[31,    52] loss: 0.382\n",
      "[31,    62] loss: 0.369\n",
      "[31,    72] loss: 0.371\n",
      "[31,    82] loss: 0.370\n",
      "[31,    92] loss: 0.392\n",
      "[31,   102] loss: 0.367\n",
      "[31,   112] loss: 0.405\n",
      "[31,   122] loss: 0.354\n",
      "[31,   132] loss: 0.375\n",
      "[31,   142] loss: 0.380\n",
      "[31,   152] loss: 0.375\n",
      "[32,     2] loss: 0.067\n",
      "[32,    12] loss: 0.371\n",
      "[32,    22] loss: 0.358\n",
      "[32,    32] loss: 0.367\n",
      "[32,    42] loss: 0.369\n",
      "[32,    52] loss: 0.357\n",
      "[32,    62] loss: 0.365\n",
      "[32,    72] loss: 0.369\n",
      "[32,    82] loss: 0.376\n",
      "[32,    92] loss: 0.372\n",
      "[32,   102] loss: 0.399\n",
      "[32,   112] loss: 0.386\n",
      "[32,   122] loss: 0.363\n",
      "[32,   132] loss: 0.385\n",
      "[32,   142] loss: 0.394\n",
      "[32,   152] loss: 0.386\n",
      "[33,     2] loss: 0.073\n",
      "[33,    12] loss: 0.381\n",
      "[33,    22] loss: 0.365\n",
      "[33,    32] loss: 0.373\n",
      "[33,    42] loss: 0.385\n",
      "[33,    52] loss: 0.372\n",
      "[33,    62] loss: 0.363\n",
      "[33,    72] loss: 0.362\n",
      "[33,    82] loss: 0.371\n",
      "[33,    92] loss: 0.371\n",
      "[33,   102] loss: 0.365\n",
      "[33,   112] loss: 0.377\n",
      "[33,   122] loss: 0.390\n",
      "[33,   132] loss: 0.394\n",
      "[33,   142] loss: 0.385\n",
      "[33,   152] loss: 0.363\n",
      "[34,     2] loss: 0.079\n",
      "[34,    12] loss: 0.378\n",
      "[34,    22] loss: 0.388\n",
      "[34,    32] loss: 0.377\n",
      "[34,    42] loss: 0.351\n",
      "[34,    52] loss: 0.378\n",
      "[34,    62] loss: 0.364\n",
      "[34,    72] loss: 0.355\n",
      "[34,    82] loss: 0.360\n",
      "[34,    92] loss: 0.356\n",
      "[34,   102] loss: 0.380\n",
      "[34,   112] loss: 0.408\n",
      "[34,   122] loss: 0.394\n",
      "[34,   132] loss: 0.391\n",
      "[34,   142] loss: 0.369\n",
      "[34,   152] loss: 0.362\n",
      "[35,     2] loss: 0.067\n",
      "[35,    12] loss: 0.390\n",
      "[35,    22] loss: 0.378\n",
      "[35,    32] loss: 0.370\n",
      "[35,    42] loss: 0.364\n",
      "[35,    52] loss: 0.383\n",
      "[35,    62] loss: 0.380\n",
      "[35,    72] loss: 0.366\n",
      "[35,    82] loss: 0.361\n",
      "[35,    92] loss: 0.381\n",
      "[35,   102] loss: 0.385\n",
      "[35,   112] loss: 0.383\n",
      "[35,   122] loss: 0.357\n",
      "[35,   132] loss: 0.378\n",
      "[35,   142] loss: 0.391\n",
      "[35,   152] loss: 0.372\n",
      "[36,     2] loss: 0.073\n",
      "[36,    12] loss: 0.359\n",
      "[36,    22] loss: 0.386\n",
      "[36,    32] loss: 0.400\n",
      "[36,    42] loss: 0.353\n",
      "[36,    52] loss: 0.373\n",
      "[36,    62] loss: 0.363\n",
      "[36,    72] loss: 0.358\n",
      "[36,    82] loss: 0.368\n",
      "[36,    92] loss: 0.358\n",
      "[36,   102] loss: 0.373\n",
      "[36,   112] loss: 0.386\n",
      "[36,   122] loss: 0.365\n",
      "[36,   132] loss: 0.382\n",
      "[36,   142] loss: 0.364\n",
      "[36,   152] loss: 0.346\n",
      "[37,     2] loss: 0.068\n",
      "[37,    12] loss: 0.382\n",
      "[37,    22] loss: 0.369\n",
      "[37,    32] loss: 0.363\n",
      "[37,    42] loss: 0.379\n",
      "[37,    52] loss: 0.373\n",
      "[37,    62] loss: 0.355\n",
      "[37,    72] loss: 0.382\n",
      "[37,    82] loss: 0.365\n",
      "[37,    92] loss: 0.365\n",
      "[37,   102] loss: 0.361\n",
      "[37,   112] loss: 0.370\n",
      "[37,   122] loss: 0.369\n",
      "[37,   132] loss: 0.356\n",
      "[37,   142] loss: 0.357\n",
      "[37,   152] loss: 0.363\n",
      "[38,     2] loss: 0.078\n",
      "[38,    12] loss: 0.380\n",
      "[38,    22] loss: 0.383\n",
      "[38,    32] loss: 0.382\n",
      "[38,    42] loss: 0.363\n",
      "[38,    52] loss: 0.366\n",
      "[38,    62] loss: 0.376\n",
      "[38,    72] loss: 0.371\n",
      "[38,    82] loss: 0.370\n",
      "[38,    92] loss: 0.361\n",
      "[38,   102] loss: 0.358\n",
      "[38,   112] loss: 0.354\n",
      "[38,   122] loss: 0.376\n",
      "[38,   132] loss: 0.344\n",
      "[38,   142] loss: 0.378\n",
      "[38,   152] loss: 0.376\n",
      "[39,     2] loss: 0.077\n",
      "[39,    12] loss: 0.373\n",
      "[39,    22] loss: 0.373\n",
      "[39,    32] loss: 0.372\n",
      "[39,    42] loss: 0.356\n",
      "[39,    52] loss: 0.380\n",
      "[39,    62] loss: 0.384\n",
      "[39,    72] loss: 0.361\n",
      "[39,    82] loss: 0.348\n",
      "[39,    92] loss: 0.385\n",
      "[39,   102] loss: 0.383\n",
      "[39,   112] loss: 0.365\n",
      "[39,   122] loss: 0.375\n",
      "[39,   132] loss: 0.378\n",
      "[39,   142] loss: 0.358\n",
      "[39,   152] loss: 0.371\n",
      "[40,     2] loss: 0.082\n",
      "[40,    12] loss: 0.378\n",
      "[40,    22] loss: 0.357\n",
      "[40,    32] loss: 0.360\n",
      "[40,    42] loss: 0.354\n",
      "[40,    52] loss: 0.365\n",
      "[40,    62] loss: 0.368\n",
      "[40,    72] loss: 0.341\n",
      "[40,    82] loss: 0.372\n",
      "[40,    92] loss: 0.362\n",
      "[40,   102] loss: 0.379\n",
      "[40,   112] loss: 0.354\n",
      "[40,   122] loss: 0.363\n",
      "[40,   132] loss: 0.353\n",
      "[40,   142] loss: 0.360\n",
      "[40,   152] loss: 0.365\n",
      "[41,     2] loss: 0.083\n",
      "[41,    12] loss: 0.365\n",
      "[41,    22] loss: 0.375\n",
      "[41,    32] loss: 0.364\n",
      "[41,    42] loss: 0.388\n",
      "[41,    52] loss: 0.358\n",
      "[41,    62] loss: 0.350\n",
      "[41,    72] loss: 0.362\n",
      "[41,    82] loss: 0.347\n",
      "[41,    92] loss: 0.348\n",
      "[41,   102] loss: 0.384\n",
      "[41,   112] loss: 0.374\n",
      "[41,   122] loss: 0.380\n",
      "[41,   132] loss: 0.405\n",
      "[41,   142] loss: 0.364\n",
      "[41,   152] loss: 0.378\n",
      "[42,     2] loss: 0.062\n",
      "[42,    12] loss: 0.331\n",
      "[42,    22] loss: 0.358\n",
      "[42,    32] loss: 0.361\n",
      "[42,    42] loss: 0.354\n",
      "[42,    52] loss: 0.375\n",
      "[42,    62] loss: 0.376\n",
      "[42,    72] loss: 0.353\n",
      "[42,    82] loss: 0.353\n",
      "[42,    92] loss: 0.369\n",
      "[42,   102] loss: 0.374\n",
      "[42,   112] loss: 0.363\n",
      "[42,   122] loss: 0.363\n",
      "[42,   132] loss: 0.355\n",
      "[42,   142] loss: 0.361\n",
      "[42,   152] loss: 0.379\n",
      "[43,     2] loss: 0.057\n",
      "[43,    12] loss: 0.378\n",
      "[43,    22] loss: 0.362\n",
      "[43,    32] loss: 0.374\n",
      "[43,    42] loss: 0.355\n",
      "[43,    52] loss: 0.364\n",
      "[43,    62] loss: 0.362\n",
      "[43,    72] loss: 0.374\n",
      "[43,    82] loss: 0.352\n",
      "[43,    92] loss: 0.353\n",
      "[43,   102] loss: 0.377\n",
      "[43,   112] loss: 0.369\n",
      "[43,   122] loss: 0.369\n",
      "[43,   132] loss: 0.350\n",
      "[43,   142] loss: 0.367\n",
      "[43,   152] loss: 0.372\n",
      "[44,     2] loss: 0.080\n",
      "[44,    12] loss: 0.358\n",
      "[44,    22] loss: 0.357\n",
      "[44,    32] loss: 0.340\n",
      "[44,    42] loss: 0.358\n",
      "[44,    52] loss: 0.353\n",
      "[44,    62] loss: 0.361\n",
      "[44,    72] loss: 0.367\n",
      "[44,    82] loss: 0.347\n",
      "[44,    92] loss: 0.356\n",
      "[44,   102] loss: 0.366\n",
      "[44,   112] loss: 0.372\n",
      "[44,   122] loss: 0.347\n",
      "[44,   132] loss: 0.358\n",
      "[44,   142] loss: 0.376\n",
      "[44,   152] loss: 0.386\n",
      "[45,     2] loss: 0.073\n",
      "[45,    12] loss: 0.373\n",
      "[45,    22] loss: 0.349\n",
      "[45,    32] loss: 0.392\n",
      "[45,    42] loss: 0.385\n",
      "[45,    52] loss: 0.367\n",
      "[45,    62] loss: 0.354\n",
      "[45,    72] loss: 0.357\n",
      "[45,    82] loss: 0.350\n",
      "[45,    92] loss: 0.352\n",
      "[45,   102] loss: 0.347\n",
      "[45,   112] loss: 0.376\n",
      "[45,   122] loss: 0.369\n",
      "[45,   132] loss: 0.356\n",
      "[45,   142] loss: 0.377\n",
      "[45,   152] loss: 0.373\n",
      "[46,     2] loss: 0.069\n",
      "[46,    12] loss: 0.363\n",
      "[46,    22] loss: 0.354\n",
      "[46,    32] loss: 0.352\n",
      "[46,    42] loss: 0.361\n",
      "[46,    52] loss: 0.335\n",
      "[46,    62] loss: 0.358\n",
      "[46,    72] loss: 0.360\n",
      "[46,    82] loss: 0.352\n",
      "[46,    92] loss: 0.355\n",
      "[46,   102] loss: 0.353\n",
      "[46,   112] loss: 0.339\n",
      "[46,   122] loss: 0.355\n",
      "[46,   132] loss: 0.347\n",
      "[46,   142] loss: 0.372\n",
      "[46,   152] loss: 0.369\n",
      "[47,     2] loss: 0.071\n",
      "[47,    12] loss: 0.375\n",
      "[47,    22] loss: 0.349\n",
      "[47,    32] loss: 0.344\n",
      "[47,    42] loss: 0.342\n",
      "[47,    52] loss: 0.346\n",
      "[47,    62] loss: 0.346\n",
      "[47,    72] loss: 0.357\n",
      "[47,    82] loss: 0.353\n",
      "[47,    92] loss: 0.349\n",
      "[47,   102] loss: 0.349\n",
      "[47,   112] loss: 0.330\n",
      "[47,   122] loss: 0.345\n",
      "[47,   132] loss: 0.348\n",
      "[47,   142] loss: 0.354\n",
      "[47,   152] loss: 0.334\n",
      "[48,     2] loss: 0.072\n",
      "[48,    12] loss: 0.369\n",
      "[48,    22] loss: 0.358\n",
      "[48,    32] loss: 0.348\n",
      "[48,    42] loss: 0.359\n",
      "[48,    52] loss: 0.353\n",
      "[48,    62] loss: 0.353\n",
      "[48,    72] loss: 0.376\n",
      "[48,    82] loss: 0.366\n",
      "[48,    92] loss: 0.352\n",
      "[48,   102] loss: 0.347\n",
      "[48,   112] loss: 0.335\n",
      "[48,   122] loss: 0.350\n",
      "[48,   132] loss: 0.339\n",
      "[48,   142] loss: 0.345\n",
      "[48,   152] loss: 0.339\n",
      "[49,     2] loss: 0.066\n",
      "[49,    12] loss: 0.368\n",
      "[49,    22] loss: 0.377\n",
      "[49,    32] loss: 0.354\n",
      "[49,    42] loss: 0.361\n",
      "[49,    52] loss: 0.343\n",
      "[49,    62] loss: 0.358\n",
      "[49,    72] loss: 0.358\n",
      "[49,    82] loss: 0.341\n",
      "[49,    92] loss: 0.351\n",
      "[49,   102] loss: 0.349\n",
      "[49,   112] loss: 0.353\n",
      "[49,   122] loss: 0.343\n",
      "[49,   132] loss: 0.353\n",
      "[49,   142] loss: 0.359\n",
      "[49,   152] loss: 0.330\n",
      "[50,     2] loss: 0.067\n",
      "[50,    12] loss: 0.357\n",
      "[50,    22] loss: 0.352\n",
      "[50,    32] loss: 0.370\n",
      "[50,    42] loss: 0.346\n",
      "[50,    52] loss: 0.361\n",
      "[50,    62] loss: 0.354\n",
      "[50,    72] loss: 0.351\n",
      "[50,    82] loss: 0.357\n",
      "[50,    92] loss: 0.364\n",
      "[50,   102] loss: 0.353\n",
      "[50,   112] loss: 0.340\n",
      "[50,   122] loss: 0.353\n",
      "[50,   132] loss: 0.372\n",
      "[50,   142] loss: 0.352\n",
      "[50,   152] loss: 0.347\n",
      "[51,     2] loss: 0.072\n",
      "[51,    12] loss: 0.334\n",
      "[51,    22] loss: 0.346\n",
      "[51,    32] loss: 0.353\n",
      "[51,    42] loss: 0.357\n",
      "[51,    52] loss: 0.348\n",
      "[51,    62] loss: 0.370\n",
      "[51,    72] loss: 0.348\n",
      "[51,    82] loss: 0.358\n",
      "[51,    92] loss: 0.381\n",
      "[51,   102] loss: 0.356\n",
      "[51,   112] loss: 0.344\n",
      "[51,   122] loss: 0.354\n",
      "[51,   132] loss: 0.360\n",
      "[51,   142] loss: 0.355\n",
      "[51,   152] loss: 0.344\n",
      "[52,     2] loss: 0.066\n",
      "[52,    12] loss: 0.350\n",
      "[52,    22] loss: 0.346\n",
      "[52,    32] loss: 0.354\n",
      "[52,    42] loss: 0.362\n",
      "[52,    52] loss: 0.359\n",
      "[52,    62] loss: 0.368\n",
      "[52,    72] loss: 0.336\n",
      "[52,    82] loss: 0.354\n",
      "[52,    92] loss: 0.354\n",
      "[52,   102] loss: 0.365\n",
      "[52,   112] loss: 0.342\n",
      "[52,   122] loss: 0.342\n",
      "[52,   132] loss: 0.340\n",
      "[52,   142] loss: 0.350\n",
      "[52,   152] loss: 0.349\n",
      "[53,     2] loss: 0.075\n",
      "[53,    12] loss: 0.369\n",
      "[53,    22] loss: 0.347\n",
      "[53,    32] loss: 0.356\n",
      "[53,    42] loss: 0.332\n",
      "[53,    52] loss: 0.345\n",
      "[53,    62] loss: 0.359\n",
      "[53,    72] loss: 0.326\n",
      "[53,    82] loss: 0.367\n",
      "[53,    92] loss: 0.351\n",
      "[53,   102] loss: 0.351\n",
      "[53,   112] loss: 0.349\n",
      "[53,   122] loss: 0.361\n",
      "[53,   132] loss: 0.347\n",
      "[53,   142] loss: 0.328\n",
      "[53,   152] loss: 0.368\n",
      "[54,     2] loss: 0.063\n",
      "[54,    12] loss: 0.344\n",
      "[54,    22] loss: 0.338\n",
      "[54,    32] loss: 0.334\n",
      "[54,    42] loss: 0.373\n",
      "[54,    52] loss: 0.343\n",
      "[54,    62] loss: 0.373\n",
      "[54,    72] loss: 0.368\n",
      "[54,    82] loss: 0.355\n",
      "[54,    92] loss: 0.358\n",
      "[54,   102] loss: 0.354\n",
      "[54,   112] loss: 0.351\n",
      "[54,   122] loss: 0.359\n",
      "[54,   132] loss: 0.345\n",
      "[54,   142] loss: 0.346\n",
      "[54,   152] loss: 0.340\n",
      "[55,     2] loss: 0.078\n",
      "[55,    12] loss: 0.351\n",
      "[55,    22] loss: 0.364\n",
      "[55,    32] loss: 0.357\n",
      "[55,    42] loss: 0.330\n",
      "[55,    52] loss: 0.348\n",
      "[55,    62] loss: 0.362\n",
      "[55,    72] loss: 0.350\n",
      "[55,    82] loss: 0.344\n",
      "[55,    92] loss: 0.351\n",
      "[55,   102] loss: 0.347\n",
      "[55,   112] loss: 0.346\n",
      "[55,   122] loss: 0.354\n",
      "[55,   132] loss: 0.356\n",
      "[55,   142] loss: 0.364\n",
      "[55,   152] loss: 0.362\n",
      "[56,     2] loss: 0.063\n",
      "[56,    12] loss: 0.351\n",
      "[56,    22] loss: 0.334\n",
      "[56,    32] loss: 0.334\n",
      "[56,    42] loss: 0.345\n",
      "[56,    52] loss: 0.318\n",
      "[56,    62] loss: 0.341\n",
      "[56,    72] loss: 0.363\n",
      "[56,    82] loss: 0.385\n",
      "[56,    92] loss: 0.372\n",
      "[56,   102] loss: 0.384\n",
      "[56,   112] loss: 0.351\n",
      "[56,   122] loss: 0.379\n",
      "[56,   132] loss: 0.365\n",
      "[56,   142] loss: 0.331\n",
      "[56,   152] loss: 0.365\n",
      "[57,     2] loss: 0.074\n",
      "[57,    12] loss: 0.354\n",
      "[57,    22] loss: 0.327\n",
      "[57,    32] loss: 0.336\n",
      "[57,    42] loss: 0.342\n",
      "[57,    52] loss: 0.369\n",
      "[57,    62] loss: 0.348\n",
      "[57,    72] loss: 0.342\n",
      "[57,    82] loss: 0.346\n",
      "[57,    92] loss: 0.328\n",
      "[57,   102] loss: 0.344\n",
      "[57,   112] loss: 0.354\n",
      "[57,   122] loss: 0.364\n",
      "[57,   132] loss: 0.371\n",
      "[57,   142] loss: 0.337\n",
      "[57,   152] loss: 0.376\n",
      "[58,     2] loss: 0.066\n",
      "[58,    12] loss: 0.332\n",
      "[58,    22] loss: 0.350\n",
      "[58,    32] loss: 0.354\n",
      "[58,    42] loss: 0.357\n",
      "[58,    52] loss: 0.353\n",
      "[58,    62] loss: 0.325\n",
      "[58,    72] loss: 0.335\n",
      "[58,    82] loss: 0.352\n",
      "[58,    92] loss: 0.319\n",
      "[58,   102] loss: 0.345\n",
      "[58,   112] loss: 0.338\n",
      "[58,   122] loss: 0.347\n",
      "[58,   132] loss: 0.344\n",
      "[58,   142] loss: 0.354\n",
      "[58,   152] loss: 0.354\n",
      "[59,     2] loss: 0.062\n",
      "[59,    12] loss: 0.345\n",
      "[59,    22] loss: 0.354\n",
      "[59,    32] loss: 0.357\n",
      "[59,    42] loss: 0.361\n",
      "[59,    52] loss: 0.326\n",
      "[59,    62] loss: 0.345\n",
      "[59,    72] loss: 0.341\n",
      "[59,    82] loss: 0.344\n",
      "[59,    92] loss: 0.352\n",
      "[59,   102] loss: 0.352\n",
      "[59,   112] loss: 0.344\n",
      "[59,   122] loss: 0.332\n",
      "[59,   132] loss: 0.332\n",
      "[59,   142] loss: 0.340\n",
      "[59,   152] loss: 0.367\n",
      "[60,     2] loss: 0.061\n",
      "[60,    12] loss: 0.351\n",
      "[60,    22] loss: 0.363\n",
      "[60,    32] loss: 0.366\n",
      "[60,    42] loss: 0.361\n",
      "[60,    52] loss: 0.331\n",
      "[60,    62] loss: 0.348\n",
      "[60,    72] loss: 0.357\n",
      "[60,    82] loss: 0.336\n",
      "[60,    92] loss: 0.329\n",
      "[60,   102] loss: 0.345\n",
      "[60,   112] loss: 0.336\n",
      "[60,   122] loss: 0.319\n",
      "[60,   132] loss: 0.347\n",
      "[60,   142] loss: 0.349\n",
      "[60,   152] loss: 0.331\n",
      "[61,     2] loss: 0.073\n",
      "[61,    12] loss: 0.366\n",
      "[61,    22] loss: 0.341\n",
      "[61,    32] loss: 0.366\n",
      "[61,    42] loss: 0.334\n",
      "[61,    52] loss: 0.351\n",
      "[61,    62] loss: 0.320\n",
      "[61,    72] loss: 0.356\n",
      "[61,    82] loss: 0.336\n",
      "[61,    92] loss: 0.335\n",
      "[61,   102] loss: 0.349\n",
      "[61,   112] loss: 0.347\n",
      "[61,   122] loss: 0.340\n",
      "[61,   132] loss: 0.337\n",
      "[61,   142] loss: 0.319\n",
      "[61,   152] loss: 0.338\n",
      "[62,     2] loss: 0.069\n",
      "[62,    12] loss: 0.334\n",
      "[62,    22] loss: 0.342\n",
      "[62,    32] loss: 0.357\n",
      "[62,    42] loss: 0.350\n",
      "[62,    52] loss: 0.346\n",
      "[62,    62] loss: 0.345\n",
      "[62,    72] loss: 0.337\n",
      "[62,    82] loss: 0.326\n",
      "[62,    92] loss: 0.339\n",
      "[62,   102] loss: 0.344\n",
      "[62,   112] loss: 0.347\n",
      "[62,   122] loss: 0.352\n",
      "[62,   132] loss: 0.336\n",
      "[62,   142] loss: 0.366\n",
      "[62,   152] loss: 0.346\n",
      "[63,     2] loss: 0.061\n",
      "[63,    12] loss: 0.351\n",
      "[63,    22] loss: 0.342\n",
      "[63,    32] loss: 0.321\n",
      "[63,    42] loss: 0.349\n",
      "[63,    52] loss: 0.340\n",
      "[63,    62] loss: 0.337\n",
      "[63,    72] loss: 0.335\n",
      "[63,    82] loss: 0.325\n",
      "[63,    92] loss: 0.356\n",
      "[63,   102] loss: 0.334\n",
      "[63,   112] loss: 0.333\n",
      "[63,   122] loss: 0.340\n",
      "[63,   132] loss: 0.368\n",
      "[63,   142] loss: 0.341\n",
      "[63,   152] loss: 0.351\n",
      "[64,     2] loss: 0.065\n",
      "[64,    12] loss: 0.343\n",
      "[64,    22] loss: 0.356\n",
      "[64,    32] loss: 0.363\n",
      "[64,    42] loss: 0.329\n",
      "[64,    52] loss: 0.367\n",
      "[64,    62] loss: 0.330\n",
      "[64,    72] loss: 0.354\n",
      "[64,    82] loss: 0.345\n",
      "[64,    92] loss: 0.361\n",
      "[64,   102] loss: 0.346\n",
      "[64,   112] loss: 0.325\n",
      "[64,   122] loss: 0.327\n",
      "[64,   132] loss: 0.334\n",
      "[64,   142] loss: 0.330\n",
      "[64,   152] loss: 0.331\n",
      "[65,     2] loss: 0.075\n",
      "[65,    12] loss: 0.369\n",
      "[65,    22] loss: 0.379\n",
      "[65,    32] loss: 0.356\n",
      "[65,    42] loss: 0.337\n",
      "[65,    52] loss: 0.344\n",
      "[65,    62] loss: 0.321\n",
      "[65,    72] loss: 0.338\n",
      "[65,    82] loss: 0.345\n",
      "[65,    92] loss: 0.345\n",
      "[65,   102] loss: 0.316\n",
      "[65,   112] loss: 0.349\n",
      "[65,   122] loss: 0.352\n",
      "[65,   132] loss: 0.334\n",
      "[65,   142] loss: 0.340\n",
      "[65,   152] loss: 0.344\n",
      "[66,     2] loss: 0.075\n",
      "[66,    12] loss: 0.342\n",
      "[66,    22] loss: 0.326\n",
      "[66,    32] loss: 0.346\n",
      "[66,    42] loss: 0.345\n",
      "[66,    52] loss: 0.343\n",
      "[66,    62] loss: 0.332\n",
      "[66,    72] loss: 0.330\n",
      "[66,    82] loss: 0.327\n",
      "[66,    92] loss: 0.334\n",
      "[66,   102] loss: 0.325\n",
      "[66,   112] loss: 0.343\n",
      "[66,   122] loss: 0.356\n",
      "[66,   132] loss: 0.344\n",
      "[66,   142] loss: 0.331\n",
      "[66,   152] loss: 0.350\n",
      "[67,     2] loss: 0.071\n",
      "[67,    12] loss: 0.346\n",
      "[67,    22] loss: 0.338\n",
      "[67,    32] loss: 0.332\n",
      "[67,    42] loss: 0.344\n",
      "[67,    52] loss: 0.347\n",
      "[67,    62] loss: 0.335\n",
      "[67,    72] loss: 0.339\n",
      "[67,    82] loss: 0.327\n",
      "[67,    92] loss: 0.334\n",
      "[67,   102] loss: 0.319\n",
      "[67,   112] loss: 0.332\n",
      "[67,   122] loss: 0.318\n",
      "[67,   132] loss: 0.344\n",
      "[67,   142] loss: 0.322\n",
      "[67,   152] loss: 0.329\n",
      "[68,     2] loss: 0.064\n",
      "[68,    12] loss: 0.377\n",
      "[68,    22] loss: 0.326\n",
      "[68,    32] loss: 0.333\n",
      "[68,    42] loss: 0.353\n",
      "[68,    52] loss: 0.349\n",
      "[68,    62] loss: 0.325\n",
      "[68,    72] loss: 0.330\n",
      "[68,    82] loss: 0.355\n",
      "[68,    92] loss: 0.343\n",
      "[68,   102] loss: 0.341\n",
      "[68,   112] loss: 0.351\n",
      "[68,   122] loss: 0.336\n",
      "[68,   132] loss: 0.334\n",
      "[68,   142] loss: 0.331\n",
      "[68,   152] loss: 0.342\n",
      "[69,     2] loss: 0.067\n",
      "[69,    12] loss: 0.321\n",
      "[69,    22] loss: 0.338\n",
      "[69,    32] loss: 0.349\n",
      "[69,    42] loss: 0.350\n",
      "[69,    52] loss: 0.355\n",
      "[69,    62] loss: 0.340\n",
      "[69,    72] loss: 0.342\n",
      "[69,    82] loss: 0.351\n",
      "[69,    92] loss: 0.331\n",
      "[69,   102] loss: 0.324\n",
      "[69,   112] loss: 0.347\n",
      "[69,   122] loss: 0.322\n",
      "[69,   132] loss: 0.334\n",
      "[69,   142] loss: 0.335\n",
      "[69,   152] loss: 0.331\n",
      "[70,     2] loss: 0.067\n",
      "[70,    12] loss: 0.329\n",
      "[70,    22] loss: 0.344\n",
      "[70,    32] loss: 0.313\n",
      "[70,    42] loss: 0.333\n",
      "[70,    52] loss: 0.335\n",
      "[70,    62] loss: 0.328\n",
      "[70,    72] loss: 0.345\n",
      "[70,    82] loss: 0.328\n",
      "[70,    92] loss: 0.304\n",
      "[70,   102] loss: 0.331\n",
      "[70,   112] loss: 0.354\n",
      "[70,   122] loss: 0.323\n",
      "[70,   132] loss: 0.317\n",
      "[70,   142] loss: 0.321\n",
      "[70,   152] loss: 0.340\n",
      "[71,     2] loss: 0.066\n",
      "[71,    12] loss: 0.331\n",
      "[71,    22] loss: 0.326\n",
      "[71,    32] loss: 0.341\n",
      "[71,    42] loss: 0.334\n",
      "[71,    52] loss: 0.346\n",
      "[71,    62] loss: 0.314\n",
      "[71,    72] loss: 0.313\n",
      "[71,    82] loss: 0.313\n",
      "[71,    92] loss: 0.321\n",
      "[71,   102] loss: 0.314\n",
      "[71,   112] loss: 0.321\n",
      "[71,   122] loss: 0.319\n",
      "[71,   132] loss: 0.351\n",
      "[71,   142] loss: 0.315\n",
      "[71,   152] loss: 0.325\n",
      "[72,     2] loss: 0.068\n",
      "[72,    12] loss: 0.321\n",
      "[72,    22] loss: 0.336\n",
      "[72,    32] loss: 0.351\n",
      "[72,    42] loss: 0.308\n",
      "[72,    52] loss: 0.317\n",
      "[72,    62] loss: 0.346\n",
      "[72,    72] loss: 0.323\n",
      "[72,    82] loss: 0.315\n",
      "[72,    92] loss: 0.318\n",
      "[72,   102] loss: 0.311\n",
      "[72,   112] loss: 0.323\n",
      "[72,   122] loss: 0.323\n",
      "[72,   132] loss: 0.343\n",
      "[72,   142] loss: 0.326\n",
      "[72,   152] loss: 0.330\n",
      "[73,     2] loss: 0.068\n",
      "[73,    12] loss: 0.331\n",
      "[73,    22] loss: 0.357\n",
      "[73,    32] loss: 0.326\n",
      "[73,    42] loss: 0.319\n",
      "[73,    52] loss: 0.337\n",
      "[73,    62] loss: 0.343\n",
      "[73,    72] loss: 0.333\n",
      "[73,    82] loss: 0.321\n",
      "[73,    92] loss: 0.321\n",
      "[73,   102] loss: 0.345\n",
      "[73,   112] loss: 0.331\n",
      "[73,   122] loss: 0.323\n",
      "[73,   132] loss: 0.344\n",
      "[73,   142] loss: 0.322\n",
      "[73,   152] loss: 0.335\n",
      "[74,     2] loss: 0.068\n",
      "[74,    12] loss: 0.331\n",
      "[74,    22] loss: 0.340\n",
      "[74,    32] loss: 0.343\n",
      "[74,    42] loss: 0.344\n",
      "[74,    52] loss: 0.304\n",
      "[74,    62] loss: 0.337\n",
      "[74,    72] loss: 0.346\n",
      "[74,    82] loss: 0.358\n",
      "[74,    92] loss: 0.333\n",
      "[74,   102] loss: 0.329\n",
      "[74,   112] loss: 0.352\n",
      "[74,   122] loss: 0.306\n",
      "[74,   132] loss: 0.317\n",
      "[74,   142] loss: 0.318\n",
      "[74,   152] loss: 0.317\n",
      "[75,     2] loss: 0.065\n",
      "[75,    12] loss: 0.349\n",
      "[75,    22] loss: 0.354\n",
      "[75,    32] loss: 0.362\n",
      "[75,    42] loss: 0.334\n",
      "[75,    52] loss: 0.330\n",
      "[75,    62] loss: 0.335\n",
      "[75,    72] loss: 0.325\n",
      "[75,    82] loss: 0.332\n",
      "[75,    92] loss: 0.313\n",
      "[75,   102] loss: 0.324\n",
      "[75,   112] loss: 0.329\n",
      "[75,   122] loss: 0.323\n",
      "[75,   132] loss: 0.325\n",
      "[75,   142] loss: 0.330\n",
      "[75,   152] loss: 0.318\n",
      "Finished Training\n",
      "time: 13.333034992218018\n",
      "gpu memory: 0.1401529312133789\n",
      "gpu memory: 0.1401529312133789\n",
      "cell number 30000\n",
      "0\n",
      "['3' '2' '2' ... '3' '3' '3']\n",
      "[3 2 2 ... 3 3 3]\n",
      "[1,     2] loss: 0.359\n",
      "[1,    12] loss: 0.728\n",
      "[1,    22] loss: 0.539\n",
      "[1,    32] loss: 0.486\n",
      "[1,    42] loss: 0.500\n",
      "[1,    52] loss: 0.457\n",
      "[1,    62] loss: 0.465\n",
      "[1,    72] loss: 0.463\n",
      "[1,    82] loss: 0.471\n",
      "[1,    92] loss: 0.440\n",
      "[1,   102] loss: 0.437\n",
      "[1,   112] loss: 0.445\n",
      "[1,   122] loss: 0.483\n",
      "[1,   132] loss: 0.452\n",
      "[1,   142] loss: 0.432\n",
      "[1,   152] loss: 0.427\n",
      "[1,   162] loss: 0.419\n",
      "[1,   172] loss: 0.429\n",
      "[1,   182] loss: 0.459\n",
      "[1,   192] loss: 0.445\n",
      "[1,   202] loss: 0.442\n",
      "[1,   212] loss: 0.450\n",
      "[1,   222] loss: 0.449\n",
      "[1,   232] loss: 0.447\n",
      "[2,     2] loss: 0.092\n",
      "[2,    12] loss: 0.456\n",
      "[2,    22] loss: 0.433\n",
      "[2,    32] loss: 0.428\n",
      "[2,    42] loss: 0.465\n",
      "[2,    52] loss: 0.450\n",
      "[2,    62] loss: 0.443\n",
      "[2,    72] loss: 0.442\n",
      "[2,    82] loss: 0.427\n",
      "[2,    92] loss: 0.468\n",
      "[2,   102] loss: 0.451\n",
      "[2,   112] loss: 0.431\n",
      "[2,   122] loss: 0.443\n",
      "[2,   132] loss: 0.427\n",
      "[2,   142] loss: 0.429\n",
      "[2,   152] loss: 0.413\n",
      "[2,   162] loss: 0.438\n",
      "[2,   172] loss: 0.399\n",
      "[2,   182] loss: 0.415\n",
      "[2,   192] loss: 0.425\n",
      "[2,   202] loss: 0.431\n",
      "[2,   212] loss: 0.441\n",
      "[2,   222] loss: 0.422\n",
      "[2,   232] loss: 0.422\n",
      "[3,     2] loss: 0.090\n",
      "[3,    12] loss: 0.461\n",
      "[3,    22] loss: 0.410\n",
      "[3,    32] loss: 0.421\n",
      "[3,    42] loss: 0.421\n",
      "[3,    52] loss: 0.427\n",
      "[3,    62] loss: 0.436\n",
      "[3,    72] loss: 0.431\n",
      "[3,    82] loss: 0.415\n",
      "[3,    92] loss: 0.454\n",
      "[3,   102] loss: 0.407\n",
      "[3,   112] loss: 0.434\n",
      "[3,   122] loss: 0.460\n",
      "[3,   132] loss: 0.410\n",
      "[3,   142] loss: 0.417\n",
      "[3,   152] loss: 0.409\n",
      "[3,   162] loss: 0.394\n",
      "[3,   172] loss: 0.407\n",
      "[3,   182] loss: 0.441\n",
      "[3,   192] loss: 0.403\n",
      "[3,   202] loss: 0.410\n",
      "[3,   212] loss: 0.407\n",
      "[3,   222] loss: 0.416\n",
      "[3,   232] loss: 0.406\n",
      "[4,     2] loss: 0.086\n",
      "[4,    12] loss: 0.423\n",
      "[4,    22] loss: 0.418\n",
      "[4,    32] loss: 0.417\n",
      "[4,    42] loss: 0.389\n",
      "[4,    52] loss: 0.423\n",
      "[4,    62] loss: 0.405\n",
      "[4,    72] loss: 0.398\n",
      "[4,    82] loss: 0.416\n",
      "[4,    92] loss: 0.446\n",
      "[4,   102] loss: 0.418\n",
      "[4,   112] loss: 0.427\n",
      "[4,   122] loss: 0.435\n",
      "[4,   132] loss: 0.454\n",
      "[4,   142] loss: 0.417\n",
      "[4,   152] loss: 0.421\n",
      "[4,   162] loss: 0.409\n",
      "[4,   172] loss: 0.410\n",
      "[4,   182] loss: 0.408\n",
      "[4,   192] loss: 0.402\n",
      "[4,   202] loss: 0.431\n",
      "[4,   212] loss: 0.424\n",
      "[4,   222] loss: 0.414\n",
      "[4,   232] loss: 0.416\n",
      "[5,     2] loss: 0.090\n",
      "[5,    12] loss: 0.387\n",
      "[5,    22] loss: 0.417\n",
      "[5,    32] loss: 0.417\n",
      "[5,    42] loss: 0.398\n",
      "[5,    52] loss: 0.415\n",
      "[5,    62] loss: 0.386\n",
      "[5,    72] loss: 0.425\n",
      "[5,    82] loss: 0.407\n",
      "[5,    92] loss: 0.414\n",
      "[5,   102] loss: 0.409\n",
      "[5,   112] loss: 0.432\n",
      "[5,   122] loss: 0.417\n",
      "[5,   132] loss: 0.396\n",
      "[5,   142] loss: 0.425\n",
      "[5,   152] loss: 0.448\n",
      "[5,   162] loss: 0.418\n",
      "[5,   172] loss: 0.437\n",
      "[5,   182] loss: 0.396\n",
      "[5,   192] loss: 0.410\n",
      "[5,   202] loss: 0.405\n",
      "[5,   212] loss: 0.417\n",
      "[5,   222] loss: 0.419\n",
      "[5,   232] loss: 0.406\n",
      "[6,     2] loss: 0.081\n",
      "[6,    12] loss: 0.418\n",
      "[6,    22] loss: 0.402\n",
      "[6,    32] loss: 0.397\n",
      "[6,    42] loss: 0.416\n",
      "[6,    52] loss: 0.399\n",
      "[6,    62] loss: 0.416\n",
      "[6,    72] loss: 0.401\n",
      "[6,    82] loss: 0.423\n",
      "[6,    92] loss: 0.425\n",
      "[6,   102] loss: 0.414\n",
      "[6,   112] loss: 0.414\n",
      "[6,   122] loss: 0.417\n",
      "[6,   132] loss: 0.400\n",
      "[6,   142] loss: 0.391\n",
      "[6,   152] loss: 0.414\n",
      "[6,   162] loss: 0.415\n",
      "[6,   172] loss: 0.412\n",
      "[6,   182] loss: 0.397\n",
      "[6,   192] loss: 0.408\n",
      "[6,   202] loss: 0.408\n",
      "[6,   212] loss: 0.399\n",
      "[6,   222] loss: 0.427\n",
      "[6,   232] loss: 0.409\n",
      "[7,     2] loss: 0.085\n",
      "[7,    12] loss: 0.414\n",
      "[7,    22] loss: 0.415\n",
      "[7,    32] loss: 0.415\n",
      "[7,    42] loss: 0.386\n",
      "[7,    52] loss: 0.422\n",
      "[7,    62] loss: 0.415\n",
      "[7,    72] loss: 0.441\n",
      "[7,    82] loss: 0.412\n",
      "[7,    92] loss: 0.420\n",
      "[7,   102] loss: 0.416\n",
      "[7,   112] loss: 0.393\n",
      "[7,   122] loss: 0.424\n",
      "[7,   132] loss: 0.434\n",
      "[7,   142] loss: 0.427\n",
      "[7,   152] loss: 0.400\n",
      "[7,   162] loss: 0.396\n",
      "[7,   172] loss: 0.371\n",
      "[7,   182] loss: 0.411\n",
      "[7,   192] loss: 0.409\n",
      "[7,   202] loss: 0.393\n",
      "[7,   212] loss: 0.418\n",
      "[7,   222] loss: 0.404\n",
      "[7,   232] loss: 0.416\n",
      "[8,     2] loss: 0.079\n",
      "[8,    12] loss: 0.408\n",
      "[8,    22] loss: 0.398\n",
      "[8,    32] loss: 0.395\n",
      "[8,    42] loss: 0.423\n",
      "[8,    52] loss: 0.432\n",
      "[8,    62] loss: 0.420\n",
      "[8,    72] loss: 0.387\n",
      "[8,    82] loss: 0.416\n",
      "[8,    92] loss: 0.416\n",
      "[8,   102] loss: 0.414\n",
      "[8,   112] loss: 0.421\n",
      "[8,   122] loss: 0.418\n",
      "[8,   132] loss: 0.420\n",
      "[8,   142] loss: 0.412\n",
      "[8,   152] loss: 0.408\n",
      "[8,   162] loss: 0.403\n",
      "[8,   172] loss: 0.418\n",
      "[8,   182] loss: 0.400\n",
      "[8,   192] loss: 0.421\n",
      "[8,   202] loss: 0.408\n",
      "[8,   212] loss: 0.405\n",
      "[8,   222] loss: 0.410\n",
      "[8,   232] loss: 0.423\n",
      "[9,     2] loss: 0.081\n",
      "[9,    12] loss: 0.400\n",
      "[9,    22] loss: 0.398\n",
      "[9,    32] loss: 0.430\n",
      "[9,    42] loss: 0.383\n",
      "[9,    52] loss: 0.403\n",
      "[9,    62] loss: 0.400\n",
      "[9,    72] loss: 0.394\n",
      "[9,    82] loss: 0.401\n",
      "[9,    92] loss: 0.401\n",
      "[9,   102] loss: 0.400\n",
      "[9,   112] loss: 0.399\n",
      "[9,   122] loss: 0.434\n",
      "[9,   132] loss: 0.377\n",
      "[9,   142] loss: 0.408\n",
      "[9,   152] loss: 0.388\n",
      "[9,   162] loss: 0.420\n",
      "[9,   172] loss: 0.382\n",
      "[9,   182] loss: 0.410\n",
      "[9,   192] loss: 0.400\n",
      "[9,   202] loss: 0.389\n",
      "[9,   212] loss: 0.378\n",
      "[9,   222] loss: 0.379\n",
      "[9,   232] loss: 0.401\n",
      "[10,     2] loss: 0.070\n",
      "[10,    12] loss: 0.402\n",
      "[10,    22] loss: 0.436\n",
      "[10,    32] loss: 0.408\n",
      "[10,    42] loss: 0.391\n",
      "[10,    52] loss: 0.383\n",
      "[10,    62] loss: 0.401\n",
      "[10,    72] loss: 0.388\n",
      "[10,    82] loss: 0.394\n",
      "[10,    92] loss: 0.379\n",
      "[10,   102] loss: 0.408\n",
      "[10,   112] loss: 0.384\n",
      "[10,   122] loss: 0.416\n",
      "[10,   132] loss: 0.396\n",
      "[10,   142] loss: 0.381\n",
      "[10,   152] loss: 0.443\n",
      "[10,   162] loss: 0.383\n",
      "[10,   172] loss: 0.388\n",
      "[10,   182] loss: 0.419\n",
      "[10,   192] loss: 0.393\n",
      "[10,   202] loss: 0.396\n",
      "[10,   212] loss: 0.406\n",
      "[10,   222] loss: 0.402\n",
      "[10,   232] loss: 0.399\n",
      "[11,     2] loss: 0.077\n",
      "[11,    12] loss: 0.416\n",
      "[11,    22] loss: 0.393\n",
      "[11,    32] loss: 0.365\n",
      "[11,    42] loss: 0.398\n",
      "[11,    52] loss: 0.398\n",
      "[11,    62] loss: 0.409\n",
      "[11,    72] loss: 0.393\n",
      "[11,    82] loss: 0.408\n",
      "[11,    92] loss: 0.394\n",
      "[11,   102] loss: 0.390\n",
      "[11,   112] loss: 0.380\n",
      "[11,   122] loss: 0.391\n",
      "[11,   132] loss: 0.396\n",
      "[11,   142] loss: 0.395\n",
      "[11,   152] loss: 0.425\n",
      "[11,   162] loss: 0.376\n",
      "[11,   172] loss: 0.389\n",
      "[11,   182] loss: 0.397\n",
      "[11,   192] loss: 0.403\n",
      "[11,   202] loss: 0.394\n",
      "[11,   212] loss: 0.393\n",
      "[11,   222] loss: 0.406\n",
      "[11,   232] loss: 0.380\n",
      "[12,     2] loss: 0.079\n",
      "[12,    12] loss: 0.390\n",
      "[12,    22] loss: 0.416\n",
      "[12,    32] loss: 0.394\n",
      "[12,    42] loss: 0.354\n",
      "[12,    52] loss: 0.410\n",
      "[12,    62] loss: 0.399\n",
      "[12,    72] loss: 0.405\n",
      "[12,    82] loss: 0.403\n",
      "[12,    92] loss: 0.409\n",
      "[12,   102] loss: 0.442\n",
      "[12,   112] loss: 0.411\n",
      "[12,   122] loss: 0.403\n",
      "[12,   132] loss: 0.411\n",
      "[12,   142] loss: 0.406\n",
      "[12,   152] loss: 0.387\n",
      "[12,   162] loss: 0.389\n",
      "[12,   172] loss: 0.359\n",
      "[12,   182] loss: 0.397\n",
      "[12,   192] loss: 0.396\n",
      "[12,   202] loss: 0.375\n",
      "[12,   212] loss: 0.390\n",
      "[12,   222] loss: 0.359\n",
      "[12,   232] loss: 0.402\n",
      "[13,     2] loss: 0.078\n",
      "[13,    12] loss: 0.388\n",
      "[13,    22] loss: 0.391\n",
      "[13,    32] loss: 0.384\n",
      "[13,    42] loss: 0.400\n",
      "[13,    52] loss: 0.396\n",
      "[13,    62] loss: 0.406\n",
      "[13,    72] loss: 0.383\n",
      "[13,    82] loss: 0.410\n",
      "[13,    92] loss: 0.414\n",
      "[13,   102] loss: 0.414\n",
      "[13,   112] loss: 0.391\n",
      "[13,   122] loss: 0.393\n",
      "[13,   132] loss: 0.402\n",
      "[13,   142] loss: 0.382\n",
      "[13,   152] loss: 0.396\n",
      "[13,   162] loss: 0.385\n",
      "[13,   172] loss: 0.391\n",
      "[13,   182] loss: 0.394\n",
      "[13,   192] loss: 0.401\n",
      "[13,   202] loss: 0.379\n",
      "[13,   212] loss: 0.382\n",
      "[13,   222] loss: 0.405\n",
      "[13,   232] loss: 0.406\n",
      "[14,     2] loss: 0.072\n",
      "[14,    12] loss: 0.375\n",
      "[14,    22] loss: 0.377\n",
      "[14,    32] loss: 0.395\n",
      "[14,    42] loss: 0.404\n",
      "[14,    52] loss: 0.395\n",
      "[14,    62] loss: 0.413\n",
      "[14,    72] loss: 0.407\n",
      "[14,    82] loss: 0.407\n",
      "[14,    92] loss: 0.385\n",
      "[14,   102] loss: 0.379\n",
      "[14,   112] loss: 0.394\n",
      "[14,   122] loss: 0.388\n",
      "[14,   132] loss: 0.386\n",
      "[14,   142] loss: 0.385\n",
      "[14,   152] loss: 0.373\n",
      "[14,   162] loss: 0.393\n",
      "[14,   172] loss: 0.378\n",
      "[14,   182] loss: 0.360\n",
      "[14,   192] loss: 0.376\n",
      "[14,   202] loss: 0.416\n",
      "[14,   212] loss: 0.376\n",
      "[14,   222] loss: 0.397\n",
      "[14,   232] loss: 0.397\n",
      "[15,     2] loss: 0.078\n",
      "[15,    12] loss: 0.372\n",
      "[15,    22] loss: 0.389\n",
      "[15,    32] loss: 0.376\n",
      "[15,    42] loss: 0.378\n",
      "[15,    52] loss: 0.361\n",
      "[15,    62] loss: 0.352\n",
      "[15,    72] loss: 0.400\n",
      "[15,    82] loss: 0.367\n",
      "[15,    92] loss: 0.389\n",
      "[15,   102] loss: 0.390\n",
      "[15,   112] loss: 0.391\n",
      "[15,   122] loss: 0.364\n",
      "[15,   132] loss: 0.403\n",
      "[15,   142] loss: 0.386\n",
      "[15,   152] loss: 0.392\n",
      "[15,   162] loss: 0.388\n",
      "[15,   172] loss: 0.385\n",
      "[15,   182] loss: 0.370\n",
      "[15,   192] loss: 0.372\n",
      "[15,   202] loss: 0.389\n",
      "[15,   212] loss: 0.382\n",
      "[15,   222] loss: 0.400\n",
      "[15,   232] loss: 0.388\n",
      "[16,     2] loss: 0.079\n",
      "[16,    12] loss: 0.385\n",
      "[16,    22] loss: 0.389\n",
      "[16,    32] loss: 0.403\n",
      "[16,    42] loss: 0.379\n",
      "[16,    52] loss: 0.385\n",
      "[16,    62] loss: 0.400\n",
      "[16,    72] loss: 0.364\n",
      "[16,    82] loss: 0.382\n",
      "[16,    92] loss: 0.377\n",
      "[16,   102] loss: 0.401\n",
      "[16,   112] loss: 0.400\n",
      "[16,   122] loss: 0.393\n",
      "[16,   132] loss: 0.377\n",
      "[16,   142] loss: 0.399\n",
      "[16,   152] loss: 0.385\n",
      "[16,   162] loss: 0.375\n",
      "[16,   172] loss: 0.406\n",
      "[16,   182] loss: 0.405\n",
      "[16,   192] loss: 0.379\n",
      "[16,   202] loss: 0.391\n",
      "[16,   212] loss: 0.382\n",
      "[16,   222] loss: 0.391\n",
      "[16,   232] loss: 0.392\n",
      "[17,     2] loss: 0.068\n",
      "[17,    12] loss: 0.402\n",
      "[17,    22] loss: 0.383\n",
      "[17,    32] loss: 0.384\n",
      "[17,    42] loss: 0.399\n",
      "[17,    52] loss: 0.401\n",
      "[17,    62] loss: 0.398\n",
      "[17,    72] loss: 0.386\n",
      "[17,    82] loss: 0.374\n",
      "[17,    92] loss: 0.373\n",
      "[17,   102] loss: 0.371\n",
      "[17,   112] loss: 0.394\n",
      "[17,   122] loss: 0.365\n",
      "[17,   132] loss: 0.364\n",
      "[17,   142] loss: 0.391\n",
      "[17,   152] loss: 0.369\n",
      "[17,   162] loss: 0.401\n",
      "[17,   172] loss: 0.370\n",
      "[17,   182] loss: 0.378\n",
      "[17,   192] loss: 0.397\n",
      "[17,   202] loss: 0.394\n",
      "[17,   212] loss: 0.372\n",
      "[17,   222] loss: 0.386\n",
      "[17,   232] loss: 0.343\n",
      "[18,     2] loss: 0.078\n",
      "[18,    12] loss: 0.403\n",
      "[18,    22] loss: 0.367\n",
      "[18,    32] loss: 0.390\n",
      "[18,    42] loss: 0.414\n",
      "[18,    52] loss: 0.388\n",
      "[18,    62] loss: 0.390\n",
      "[18,    72] loss: 0.383\n",
      "[18,    82] loss: 0.389\n",
      "[18,    92] loss: 0.380\n",
      "[18,   102] loss: 0.391\n",
      "[18,   112] loss: 0.393\n",
      "[18,   122] loss: 0.372\n",
      "[18,   132] loss: 0.399\n",
      "[18,   142] loss: 0.391\n",
      "[18,   152] loss: 0.391\n",
      "[18,   162] loss: 0.427\n",
      "[18,   172] loss: 0.365\n",
      "[18,   182] loss: 0.394\n",
      "[18,   192] loss: 0.379\n",
      "[18,   202] loss: 0.412\n",
      "[18,   212] loss: 0.395\n",
      "[18,   222] loss: 0.386\n",
      "[18,   232] loss: 0.399\n",
      "[19,     2] loss: 0.078\n",
      "[19,    12] loss: 0.407\n",
      "[19,    22] loss: 0.415\n",
      "[19,    32] loss: 0.402\n",
      "[19,    42] loss: 0.380\n",
      "[19,    52] loss: 0.356\n",
      "[19,    62] loss: 0.404\n",
      "[19,    72] loss: 0.402\n",
      "[19,    82] loss: 0.381\n",
      "[19,    92] loss: 0.370\n",
      "[19,   102] loss: 0.406\n",
      "[19,   112] loss: 0.370\n",
      "[19,   122] loss: 0.405\n",
      "[19,   132] loss: 0.376\n",
      "[19,   142] loss: 0.396\n",
      "[19,   152] loss: 0.387\n",
      "[19,   162] loss: 0.400\n",
      "[19,   172] loss: 0.387\n",
      "[19,   182] loss: 0.371\n",
      "[19,   192] loss: 0.380\n",
      "[19,   202] loss: 0.387\n",
      "[19,   212] loss: 0.372\n",
      "[19,   222] loss: 0.395\n",
      "[19,   232] loss: 0.380\n",
      "[20,     2] loss: 0.070\n",
      "[20,    12] loss: 0.384\n",
      "[20,    22] loss: 0.375\n",
      "[20,    32] loss: 0.366\n",
      "[20,    42] loss: 0.389\n",
      "[20,    52] loss: 0.395\n",
      "[20,    62] loss: 0.387\n",
      "[20,    72] loss: 0.384\n",
      "[20,    82] loss: 0.372\n",
      "[20,    92] loss: 0.395\n",
      "[20,   102] loss: 0.352\n",
      "[20,   112] loss: 0.407\n",
      "[20,   122] loss: 0.381\n",
      "[20,   132] loss: 0.375\n",
      "[20,   142] loss: 0.383\n",
      "[20,   152] loss: 0.384\n",
      "[20,   162] loss: 0.377\n",
      "[20,   172] loss: 0.393\n",
      "[20,   182] loss: 0.392\n",
      "[20,   192] loss: 0.372\n",
      "[20,   202] loss: 0.365\n",
      "[20,   212] loss: 0.372\n",
      "[20,   222] loss: 0.379\n",
      "[20,   232] loss: 0.371\n",
      "[21,     2] loss: 0.074\n",
      "[21,    12] loss: 0.389\n",
      "[21,    22] loss: 0.371\n",
      "[21,    32] loss: 0.390\n",
      "[21,    42] loss: 0.367\n",
      "[21,    52] loss: 0.372\n",
      "[21,    62] loss: 0.397\n",
      "[21,    72] loss: 0.403\n",
      "[21,    82] loss: 0.390\n",
      "[21,    92] loss: 0.390\n",
      "[21,   102] loss: 0.375\n",
      "[21,   112] loss: 0.376\n",
      "[21,   122] loss: 0.382\n",
      "[21,   132] loss: 0.387\n",
      "[21,   142] loss: 0.366\n",
      "[21,   152] loss: 0.358\n",
      "[21,   162] loss: 0.398\n",
      "[21,   172] loss: 0.385\n",
      "[21,   182] loss: 0.375\n",
      "[21,   192] loss: 0.383\n",
      "[21,   202] loss: 0.411\n",
      "[21,   212] loss: 0.388\n",
      "[21,   222] loss: 0.393\n",
      "[21,   232] loss: 0.397\n",
      "[22,     2] loss: 0.077\n",
      "[22,    12] loss: 0.383\n",
      "[22,    22] loss: 0.395\n",
      "[22,    32] loss: 0.360\n",
      "[22,    42] loss: 0.372\n",
      "[22,    52] loss: 0.402\n",
      "[22,    62] loss: 0.365\n",
      "[22,    72] loss: 0.392\n",
      "[22,    82] loss: 0.377\n",
      "[22,    92] loss: 0.363\n",
      "[22,   102] loss: 0.396\n",
      "[22,   112] loss: 0.384\n",
      "[22,   122] loss: 0.333\n",
      "[22,   132] loss: 0.375\n",
      "[22,   142] loss: 0.383\n",
      "[22,   152] loss: 0.387\n",
      "[22,   162] loss: 0.387\n",
      "[22,   172] loss: 0.346\n",
      "[22,   182] loss: 0.366\n",
      "[22,   192] loss: 0.375\n",
      "[22,   202] loss: 0.399\n",
      "[22,   212] loss: 0.401\n",
      "[22,   222] loss: 0.367\n",
      "[22,   232] loss: 0.375\n",
      "[23,     2] loss: 0.077\n",
      "[23,    12] loss: 0.369\n",
      "[23,    22] loss: 0.404\n",
      "[23,    32] loss: 0.378\n",
      "[23,    42] loss: 0.370\n",
      "[23,    52] loss: 0.370\n",
      "[23,    62] loss: 0.386\n",
      "[23,    72] loss: 0.369\n",
      "[23,    82] loss: 0.381\n",
      "[23,    92] loss: 0.380\n",
      "[23,   102] loss: 0.394\n",
      "[23,   112] loss: 0.367\n",
      "[23,   122] loss: 0.387\n",
      "[23,   132] loss: 0.363\n",
      "[23,   142] loss: 0.384\n",
      "[23,   152] loss: 0.375\n",
      "[23,   162] loss: 0.351\n",
      "[23,   172] loss: 0.388\n",
      "[23,   182] loss: 0.372\n",
      "[23,   192] loss: 0.384\n",
      "[23,   202] loss: 0.381\n",
      "[23,   212] loss: 0.372\n",
      "[23,   222] loss: 0.382\n",
      "[23,   232] loss: 0.369\n",
      "[24,     2] loss: 0.062\n",
      "[24,    12] loss: 0.380\n",
      "[24,    22] loss: 0.381\n",
      "[24,    32] loss: 0.346\n",
      "[24,    42] loss: 0.371\n",
      "[24,    52] loss: 0.366\n",
      "[24,    62] loss: 0.382\n",
      "[24,    72] loss: 0.359\n",
      "[24,    82] loss: 0.379\n",
      "[24,    92] loss: 0.379\n",
      "[24,   102] loss: 0.380\n",
      "[24,   112] loss: 0.378\n",
      "[24,   122] loss: 0.403\n",
      "[24,   132] loss: 0.365\n",
      "[24,   142] loss: 0.374\n",
      "[24,   152] loss: 0.367\n",
      "[24,   162] loss: 0.358\n",
      "[24,   172] loss: 0.388\n",
      "[24,   182] loss: 0.385\n",
      "[24,   192] loss: 0.377\n",
      "[24,   202] loss: 0.368\n",
      "[24,   212] loss: 0.369\n",
      "[24,   222] loss: 0.360\n",
      "[24,   232] loss: 0.367\n",
      "[25,     2] loss: 0.069\n",
      "[25,    12] loss: 0.345\n",
      "[25,    22] loss: 0.372\n",
      "[25,    32] loss: 0.375\n",
      "[25,    42] loss: 0.397\n",
      "[25,    52] loss: 0.388\n",
      "[25,    62] loss: 0.378\n",
      "[25,    72] loss: 0.394\n",
      "[25,    82] loss: 0.356\n",
      "[25,    92] loss: 0.362\n",
      "[25,   102] loss: 0.351\n",
      "[25,   112] loss: 0.374\n",
      "[25,   122] loss: 0.372\n",
      "[25,   132] loss: 0.385\n",
      "[25,   142] loss: 0.357\n",
      "[25,   152] loss: 0.372\n",
      "[25,   162] loss: 0.367\n",
      "[25,   172] loss: 0.369\n",
      "[25,   182] loss: 0.388\n",
      "[25,   192] loss: 0.374\n",
      "[25,   202] loss: 0.354\n",
      "[25,   212] loss: 0.376\n",
      "[25,   222] loss: 0.374\n",
      "[25,   232] loss: 0.397\n",
      "[26,     2] loss: 0.069\n",
      "[26,    12] loss: 0.383\n",
      "[26,    22] loss: 0.380\n",
      "[26,    32] loss: 0.359\n",
      "[26,    42] loss: 0.392\n",
      "[26,    52] loss: 0.380\n",
      "[26,    62] loss: 0.380\n",
      "[26,    72] loss: 0.391\n",
      "[26,    82] loss: 0.371\n",
      "[26,    92] loss: 0.403\n",
      "[26,   102] loss: 0.378\n",
      "[26,   112] loss: 0.403\n",
      "[26,   122] loss: 0.363\n",
      "[26,   132] loss: 0.378\n",
      "[26,   142] loss: 0.391\n",
      "[26,   152] loss: 0.355\n",
      "[26,   162] loss: 0.353\n",
      "[26,   172] loss: 0.381\n",
      "[26,   182] loss: 0.355\n",
      "[26,   192] loss: 0.362\n",
      "[26,   202] loss: 0.391\n",
      "[26,   212] loss: 0.372\n",
      "[26,   222] loss: 0.394\n",
      "[26,   232] loss: 0.369\n",
      "[27,     2] loss: 0.073\n",
      "[27,    12] loss: 0.384\n",
      "[27,    22] loss: 0.404\n",
      "[27,    32] loss: 0.378\n",
      "[27,    42] loss: 0.376\n",
      "[27,    52] loss: 0.368\n",
      "[27,    62] loss: 0.371\n",
      "[27,    72] loss: 0.372\n",
      "[27,    82] loss: 0.388\n",
      "[27,    92] loss: 0.371\n",
      "[27,   102] loss: 0.379\n",
      "[27,   112] loss: 0.376\n",
      "[27,   122] loss: 0.383\n",
      "[27,   132] loss: 0.361\n",
      "[27,   142] loss: 0.387\n",
      "[27,   152] loss: 0.363\n",
      "[27,   162] loss: 0.362\n",
      "[27,   172] loss: 0.376\n",
      "[27,   182] loss: 0.388\n",
      "[27,   192] loss: 0.396\n",
      "[27,   202] loss: 0.380\n",
      "[27,   212] loss: 0.408\n",
      "[27,   222] loss: 0.368\n",
      "[27,   232] loss: 0.374\n",
      "[28,     2] loss: 0.085\n",
      "[28,    12] loss: 0.379\n",
      "[28,    22] loss: 0.373\n",
      "[28,    32] loss: 0.365\n",
      "[28,    42] loss: 0.364\n",
      "[28,    52] loss: 0.379\n",
      "[28,    62] loss: 0.379\n",
      "[28,    72] loss: 0.392\n",
      "[28,    82] loss: 0.395\n",
      "[28,    92] loss: 0.373\n",
      "[28,   102] loss: 0.355\n",
      "[28,   112] loss: 0.368\n",
      "[28,   122] loss: 0.401\n",
      "[28,   132] loss: 0.389\n",
      "[28,   142] loss: 0.374\n",
      "[28,   152] loss: 0.363\n",
      "[28,   162] loss: 0.390\n",
      "[28,   172] loss: 0.376\n",
      "[28,   182] loss: 0.377\n",
      "[28,   192] loss: 0.374\n",
      "[28,   202] loss: 0.376\n",
      "[28,   212] loss: 0.355\n",
      "[28,   222] loss: 0.395\n",
      "[28,   232] loss: 0.365\n",
      "[29,     2] loss: 0.068\n",
      "[29,    12] loss: 0.387\n",
      "[29,    22] loss: 0.368\n",
      "[29,    32] loss: 0.382\n",
      "[29,    42] loss: 0.391\n",
      "[29,    52] loss: 0.370\n",
      "[29,    62] loss: 0.367\n",
      "[29,    72] loss: 0.360\n",
      "[29,    82] loss: 0.383\n",
      "[29,    92] loss: 0.398\n",
      "[29,   102] loss: 0.384\n",
      "[29,   112] loss: 0.382\n",
      "[29,   122] loss: 0.361\n",
      "[29,   132] loss: 0.371\n",
      "[29,   142] loss: 0.368\n",
      "[29,   152] loss: 0.374\n",
      "[29,   162] loss: 0.388\n",
      "[29,   172] loss: 0.366\n",
      "[29,   182] loss: 0.348\n",
      "[29,   192] loss: 0.367\n",
      "[29,   202] loss: 0.356\n",
      "[29,   212] loss: 0.367\n",
      "[29,   222] loss: 0.369\n",
      "[29,   232] loss: 0.375\n",
      "[30,     2] loss: 0.079\n",
      "[30,    12] loss: 0.355\n",
      "[30,    22] loss: 0.382\n",
      "[30,    32] loss: 0.361\n",
      "[30,    42] loss: 0.364\n",
      "[30,    52] loss: 0.353\n",
      "[30,    62] loss: 0.376\n",
      "[30,    72] loss: 0.382\n",
      "[30,    82] loss: 0.360\n",
      "[30,    92] loss: 0.375\n",
      "[30,   102] loss: 0.345\n",
      "[30,   112] loss: 0.367\n",
      "[30,   122] loss: 0.388\n",
      "[30,   132] loss: 0.365\n",
      "[30,   142] loss: 0.374\n",
      "[30,   152] loss: 0.360\n",
      "[30,   162] loss: 0.371\n",
      "[30,   172] loss: 0.356\n",
      "[30,   182] loss: 0.358\n",
      "[30,   192] loss: 0.383\n",
      "[30,   202] loss: 0.359\n",
      "[30,   212] loss: 0.379\n",
      "[30,   222] loss: 0.343\n",
      "[30,   232] loss: 0.380\n",
      "[31,     2] loss: 0.088\n",
      "[31,    12] loss: 0.376\n",
      "[31,    22] loss: 0.379\n",
      "[31,    32] loss: 0.376\n",
      "[31,    42] loss: 0.377\n",
      "[31,    52] loss: 0.375\n",
      "[31,    62] loss: 0.386\n",
      "[31,    72] loss: 0.387\n",
      "[31,    82] loss: 0.385\n",
      "[31,    92] loss: 0.371\n",
      "[31,   102] loss: 0.377\n",
      "[31,   112] loss: 0.373\n",
      "[31,   122] loss: 0.381\n",
      "[31,   132] loss: 0.389\n",
      "[31,   142] loss: 0.351\n",
      "[31,   152] loss: 0.368\n",
      "[31,   162] loss: 0.359\n",
      "[31,   172] loss: 0.382\n",
      "[31,   182] loss: 0.363\n",
      "[31,   192] loss: 0.377\n",
      "[31,   202] loss: 0.360\n",
      "[31,   212] loss: 0.369\n",
      "[31,   222] loss: 0.376\n",
      "[31,   232] loss: 0.377\n",
      "[32,     2] loss: 0.073\n",
      "[32,    12] loss: 0.369\n",
      "[32,    22] loss: 0.395\n",
      "[32,    32] loss: 0.369\n",
      "[32,    42] loss: 0.402\n",
      "[32,    52] loss: 0.377\n",
      "[32,    62] loss: 0.382\n",
      "[32,    72] loss: 0.381\n",
      "[32,    82] loss: 0.373\n",
      "[32,    92] loss: 0.383\n",
      "[32,   102] loss: 0.362\n",
      "[32,   112] loss: 0.365\n",
      "[32,   122] loss: 0.371\n",
      "[32,   132] loss: 0.353\n",
      "[32,   142] loss: 0.367\n",
      "[32,   152] loss: 0.380\n",
      "[32,   162] loss: 0.350\n",
      "[32,   172] loss: 0.389\n",
      "[32,   182] loss: 0.377\n",
      "[32,   192] loss: 0.371\n",
      "[32,   202] loss: 0.366\n",
      "[32,   212] loss: 0.374\n",
      "[32,   222] loss: 0.360\n",
      "[32,   232] loss: 0.364\n",
      "[33,     2] loss: 0.086\n",
      "[33,    12] loss: 0.359\n",
      "[33,    22] loss: 0.340\n",
      "[33,    32] loss: 0.367\n",
      "[33,    42] loss: 0.375\n",
      "[33,    52] loss: 0.364\n",
      "[33,    62] loss: 0.361\n",
      "[33,    72] loss: 0.380\n",
      "[33,    82] loss: 0.370\n",
      "[33,    92] loss: 0.375\n",
      "[33,   102] loss: 0.342\n",
      "[33,   112] loss: 0.390\n",
      "[33,   122] loss: 0.392\n",
      "[33,   132] loss: 0.389\n",
      "[33,   142] loss: 0.373\n",
      "[33,   152] loss: 0.373\n",
      "[33,   162] loss: 0.357\n",
      "[33,   172] loss: 0.396\n",
      "[33,   182] loss: 0.368\n",
      "[33,   192] loss: 0.371\n",
      "[33,   202] loss: 0.369\n",
      "[33,   212] loss: 0.374\n",
      "[33,   222] loss: 0.366\n",
      "[33,   232] loss: 0.353\n",
      "[34,     2] loss: 0.076\n",
      "[34,    12] loss: 0.353\n",
      "[34,    22] loss: 0.379\n",
      "[34,    32] loss: 0.388\n",
      "[34,    42] loss: 0.373\n",
      "[34,    52] loss: 0.379\n",
      "[34,    62] loss: 0.391\n",
      "[34,    72] loss: 0.344\n",
      "[34,    82] loss: 0.363\n",
      "[34,    92] loss: 0.373\n",
      "[34,   102] loss: 0.368\n",
      "[34,   112] loss: 0.373\n",
      "[34,   122] loss: 0.382\n",
      "[34,   132] loss: 0.374\n",
      "[34,   142] loss: 0.355\n",
      "[34,   152] loss: 0.362\n",
      "[34,   162] loss: 0.361\n",
      "[34,   172] loss: 0.393\n",
      "[34,   182] loss: 0.363\n",
      "[34,   192] loss: 0.359\n",
      "[34,   202] loss: 0.369\n",
      "[34,   212] loss: 0.360\n",
      "[34,   222] loss: 0.360\n",
      "[34,   232] loss: 0.365\n",
      "[35,     2] loss: 0.071\n",
      "[35,    12] loss: 0.359\n",
      "[35,    22] loss: 0.352\n",
      "[35,    32] loss: 0.368\n",
      "[35,    42] loss: 0.369\n",
      "[35,    52] loss: 0.356\n",
      "[35,    62] loss: 0.335\n",
      "[35,    72] loss: 0.370\n",
      "[35,    82] loss: 0.373\n",
      "[35,    92] loss: 0.372\n",
      "[35,   102] loss: 0.364\n",
      "[35,   112] loss: 0.352\n",
      "[35,   122] loss: 0.399\n",
      "[35,   132] loss: 0.390\n",
      "[35,   142] loss: 0.374\n",
      "[35,   152] loss: 0.376\n",
      "[35,   162] loss: 0.359\n",
      "[35,   172] loss: 0.353\n",
      "[35,   182] loss: 0.370\n",
      "[35,   192] loss: 0.379\n",
      "[35,   202] loss: 0.351\n",
      "[35,   212] loss: 0.352\n",
      "[35,   222] loss: 0.372\n",
      "[35,   232] loss: 0.371\n",
      "[36,     2] loss: 0.069\n",
      "[36,    12] loss: 0.372\n",
      "[36,    22] loss: 0.348\n",
      "[36,    32] loss: 0.356\n",
      "[36,    42] loss: 0.360\n",
      "[36,    52] loss: 0.371\n",
      "[36,    62] loss: 0.340\n",
      "[36,    72] loss: 0.378\n",
      "[36,    82] loss: 0.350\n",
      "[36,    92] loss: 0.356\n",
      "[36,   102] loss: 0.382\n",
      "[36,   112] loss: 0.382\n",
      "[36,   122] loss: 0.362\n",
      "[36,   132] loss: 0.358\n",
      "[36,   142] loss: 0.372\n",
      "[36,   152] loss: 0.397\n",
      "[36,   162] loss: 0.362\n",
      "[36,   172] loss: 0.364\n",
      "[36,   182] loss: 0.381\n",
      "[36,   192] loss: 0.354\n",
      "[36,   202] loss: 0.376\n",
      "[36,   212] loss: 0.360\n",
      "[36,   222] loss: 0.349\n",
      "[36,   232] loss: 0.369\n",
      "[37,     2] loss: 0.081\n",
      "[37,    12] loss: 0.372\n",
      "[37,    22] loss: 0.361\n",
      "[37,    32] loss: 0.341\n",
      "[37,    42] loss: 0.379\n",
      "[37,    52] loss: 0.361\n",
      "[37,    62] loss: 0.357\n",
      "[37,    72] loss: 0.351\n",
      "[37,    82] loss: 0.376\n",
      "[37,    92] loss: 0.373\n",
      "[37,   102] loss: 0.354\n",
      "[37,   112] loss: 0.356\n",
      "[37,   122] loss: 0.373\n",
      "[37,   132] loss: 0.363\n",
      "[37,   142] loss: 0.385\n",
      "[37,   152] loss: 0.343\n",
      "[37,   162] loss: 0.348\n",
      "[37,   172] loss: 0.368\n",
      "[37,   182] loss: 0.349\n",
      "[37,   192] loss: 0.378\n",
      "[37,   202] loss: 0.370\n",
      "[37,   212] loss: 0.358\n",
      "[37,   222] loss: 0.359\n",
      "[37,   232] loss: 0.387\n",
      "[38,     2] loss: 0.069\n",
      "[38,    12] loss: 0.371\n",
      "[38,    22] loss: 0.384\n",
      "[38,    32] loss: 0.374\n",
      "[38,    42] loss: 0.373\n",
      "[38,    52] loss: 0.356\n",
      "[38,    62] loss: 0.376\n",
      "[38,    72] loss: 0.387\n",
      "[38,    82] loss: 0.395\n",
      "[38,    92] loss: 0.370\n",
      "[38,   102] loss: 0.369\n",
      "[38,   112] loss: 0.358\n",
      "[38,   122] loss: 0.377\n",
      "[38,   132] loss: 0.369\n",
      "[38,   142] loss: 0.354\n",
      "[38,   152] loss: 0.348\n",
      "[38,   162] loss: 0.362\n",
      "[38,   172] loss: 0.356\n",
      "[38,   182] loss: 0.357\n",
      "[38,   192] loss: 0.357\n",
      "[38,   202] loss: 0.361\n",
      "[38,   212] loss: 0.363\n",
      "[38,   222] loss: 0.393\n",
      "[38,   232] loss: 0.359\n",
      "[39,     2] loss: 0.079\n",
      "[39,    12] loss: 0.371\n",
      "[39,    22] loss: 0.376\n",
      "[39,    32] loss: 0.388\n",
      "[39,    42] loss: 0.360\n",
      "[39,    52] loss: 0.359\n",
      "[39,    62] loss: 0.360\n",
      "[39,    72] loss: 0.361\n",
      "[39,    82] loss: 0.355\n",
      "[39,    92] loss: 0.347\n",
      "[39,   102] loss: 0.348\n",
      "[39,   112] loss: 0.373\n",
      "[39,   122] loss: 0.376\n",
      "[39,   132] loss: 0.384\n",
      "[39,   142] loss: 0.356\n",
      "[39,   152] loss: 0.361\n",
      "[39,   162] loss: 0.380\n",
      "[39,   172] loss: 0.355\n",
      "[39,   182] loss: 0.364\n",
      "[39,   192] loss: 0.362\n",
      "[39,   202] loss: 0.351\n",
      "[39,   212] loss: 0.355\n",
      "[39,   222] loss: 0.360\n",
      "[39,   232] loss: 0.340\n",
      "[40,     2] loss: 0.069\n",
      "[40,    12] loss: 0.342\n",
      "[40,    22] loss: 0.350\n",
      "[40,    32] loss: 0.335\n",
      "[40,    42] loss: 0.361\n",
      "[40,    52] loss: 0.370\n",
      "[40,    62] loss: 0.345\n",
      "[40,    72] loss: 0.344\n",
      "[40,    82] loss: 0.342\n",
      "[40,    92] loss: 0.366\n",
      "[40,   102] loss: 0.368\n",
      "[40,   112] loss: 0.361\n",
      "[40,   122] loss: 0.349\n",
      "[40,   132] loss: 0.365\n",
      "[40,   142] loss: 0.358\n",
      "[40,   152] loss: 0.343\n",
      "[40,   162] loss: 0.365\n",
      "[40,   172] loss: 0.362\n",
      "[40,   182] loss: 0.364\n",
      "[40,   192] loss: 0.360\n",
      "[40,   202] loss: 0.388\n",
      "[40,   212] loss: 0.364\n",
      "[40,   222] loss: 0.357\n",
      "[40,   232] loss: 0.373\n",
      "[41,     2] loss: 0.070\n",
      "[41,    12] loss: 0.364\n",
      "[41,    22] loss: 0.383\n",
      "[41,    32] loss: 0.345\n",
      "[41,    42] loss: 0.365\n",
      "[41,    52] loss: 0.366\n",
      "[41,    62] loss: 0.363\n",
      "[41,    72] loss: 0.353\n",
      "[41,    82] loss: 0.361\n",
      "[41,    92] loss: 0.347\n",
      "[41,   102] loss: 0.384\n",
      "[41,   112] loss: 0.366\n",
      "[41,   122] loss: 0.352\n",
      "[41,   132] loss: 0.360\n",
      "[41,   142] loss: 0.362\n",
      "[41,   152] loss: 0.354\n",
      "[41,   162] loss: 0.375\n",
      "[41,   172] loss: 0.362\n",
      "[41,   182] loss: 0.373\n",
      "[41,   192] loss: 0.375\n",
      "[41,   202] loss: 0.360\n",
      "[41,   212] loss: 0.364\n",
      "[41,   222] loss: 0.365\n",
      "[41,   232] loss: 0.378\n",
      "[42,     2] loss: 0.068\n",
      "[42,    12] loss: 0.355\n",
      "[42,    22] loss: 0.365\n",
      "[42,    32] loss: 0.371\n",
      "[42,    42] loss: 0.380\n",
      "[42,    52] loss: 0.360\n",
      "[42,    62] loss: 0.365\n",
      "[42,    72] loss: 0.353\n",
      "[42,    82] loss: 0.370\n",
      "[42,    92] loss: 0.365\n",
      "[42,   102] loss: 0.379\n",
      "[42,   112] loss: 0.357\n",
      "[42,   122] loss: 0.366\n",
      "[42,   132] loss: 0.376\n",
      "[42,   142] loss: 0.340\n",
      "[42,   152] loss: 0.359\n",
      "[42,   162] loss: 0.363\n",
      "[42,   172] loss: 0.361\n",
      "[42,   182] loss: 0.376\n",
      "[42,   192] loss: 0.370\n",
      "[42,   202] loss: 0.391\n",
      "[42,   212] loss: 0.355\n",
      "[42,   222] loss: 0.358\n",
      "[42,   232] loss: 0.357\n",
      "[43,     2] loss: 0.065\n",
      "[43,    12] loss: 0.365\n",
      "[43,    22] loss: 0.348\n",
      "[43,    32] loss: 0.351\n",
      "[43,    42] loss: 0.375\n",
      "[43,    52] loss: 0.346\n",
      "[43,    62] loss: 0.375\n",
      "[43,    72] loss: 0.359\n",
      "[43,    82] loss: 0.360\n",
      "[43,    92] loss: 0.375\n",
      "[43,   102] loss: 0.358\n",
      "[43,   112] loss: 0.375\n",
      "[43,   122] loss: 0.342\n",
      "[43,   132] loss: 0.362\n",
      "[43,   142] loss: 0.359\n",
      "[43,   152] loss: 0.345\n",
      "[43,   162] loss: 0.356\n",
      "[43,   172] loss: 0.350\n",
      "[43,   182] loss: 0.347\n",
      "[43,   192] loss: 0.357\n",
      "[43,   202] loss: 0.376\n",
      "[43,   212] loss: 0.356\n",
      "[43,   222] loss: 0.350\n",
      "[43,   232] loss: 0.363\n",
      "[44,     2] loss: 0.080\n",
      "[44,    12] loss: 0.377\n",
      "[44,    22] loss: 0.354\n",
      "[44,    32] loss: 0.395\n",
      "[44,    42] loss: 0.380\n",
      "[44,    52] loss: 0.355\n",
      "[44,    62] loss: 0.378\n",
      "[44,    72] loss: 0.349\n",
      "[44,    82] loss: 0.357\n",
      "[44,    92] loss: 0.360\n",
      "[44,   102] loss: 0.351\n",
      "[44,   112] loss: 0.358\n",
      "[44,   122] loss: 0.360\n",
      "[44,   132] loss: 0.381\n",
      "[44,   142] loss: 0.368\n",
      "[44,   152] loss: 0.365\n",
      "[44,   162] loss: 0.373\n",
      "[44,   172] loss: 0.387\n",
      "[44,   182] loss: 0.366\n",
      "[44,   192] loss: 0.392\n",
      "[44,   202] loss: 0.386\n",
      "[44,   212] loss: 0.351\n",
      "[44,   222] loss: 0.347\n",
      "[44,   232] loss: 0.354\n",
      "[45,     2] loss: 0.082\n",
      "[45,    12] loss: 0.334\n",
      "[45,    22] loss: 0.353\n",
      "[45,    32] loss: 0.351\n",
      "[45,    42] loss: 0.387\n",
      "[45,    52] loss: 0.365\n",
      "[45,    62] loss: 0.379\n",
      "[45,    72] loss: 0.369\n",
      "[45,    82] loss: 0.350\n",
      "[45,    92] loss: 0.376\n",
      "[45,   102] loss: 0.357\n",
      "[45,   112] loss: 0.361\n",
      "[45,   122] loss: 0.370\n",
      "[45,   132] loss: 0.342\n",
      "[45,   142] loss: 0.355\n",
      "[45,   152] loss: 0.371\n",
      "[45,   162] loss: 0.350\n",
      "[45,   172] loss: 0.373\n",
      "[45,   182] loss: 0.357\n",
      "[45,   192] loss: 0.349\n",
      "[45,   202] loss: 0.372\n",
      "[45,   212] loss: 0.348\n",
      "[45,   222] loss: 0.349\n",
      "[45,   232] loss: 0.344\n",
      "[46,     2] loss: 0.075\n",
      "[46,    12] loss: 0.357\n",
      "[46,    22] loss: 0.352\n",
      "[46,    32] loss: 0.362\n",
      "[46,    42] loss: 0.360\n",
      "[46,    52] loss: 0.332\n",
      "[46,    62] loss: 0.367\n",
      "[46,    72] loss: 0.371\n",
      "[46,    82] loss: 0.348\n",
      "[46,    92] loss: 0.383\n",
      "[46,   102] loss: 0.348\n",
      "[46,   112] loss: 0.361\n",
      "[46,   122] loss: 0.360\n",
      "[46,   132] loss: 0.340\n",
      "[46,   142] loss: 0.365\n",
      "[46,   152] loss: 0.363\n",
      "[46,   162] loss: 0.366\n",
      "[46,   172] loss: 0.361\n",
      "[46,   182] loss: 0.363\n",
      "[46,   192] loss: 0.390\n",
      "[46,   202] loss: 0.368\n",
      "[46,   212] loss: 0.353\n",
      "[46,   222] loss: 0.370\n",
      "[46,   232] loss: 0.360\n",
      "[47,     2] loss: 0.075\n",
      "[47,    12] loss: 0.356\n",
      "[47,    22] loss: 0.362\n",
      "[47,    32] loss: 0.353\n",
      "[47,    42] loss: 0.345\n",
      "[47,    52] loss: 0.365\n",
      "[47,    62] loss: 0.367\n",
      "[47,    72] loss: 0.371\n",
      "[47,    82] loss: 0.374\n",
      "[47,    92] loss: 0.341\n",
      "[47,   102] loss: 0.348\n",
      "[47,   112] loss: 0.345\n",
      "[47,   122] loss: 0.377\n",
      "[47,   132] loss: 0.361\n",
      "[47,   142] loss: 0.352\n",
      "[47,   152] loss: 0.359\n",
      "[47,   162] loss: 0.381\n",
      "[47,   172] loss: 0.349\n",
      "[47,   182] loss: 0.372\n",
      "[47,   192] loss: 0.343\n",
      "[47,   202] loss: 0.379\n",
      "[47,   212] loss: 0.352\n",
      "[47,   222] loss: 0.364\n",
      "[47,   232] loss: 0.370\n",
      "[48,     2] loss: 0.066\n",
      "[48,    12] loss: 0.363\n",
      "[48,    22] loss: 0.350\n",
      "[48,    32] loss: 0.343\n",
      "[48,    42] loss: 0.344\n",
      "[48,    52] loss: 0.358\n",
      "[48,    62] loss: 0.349\n",
      "[48,    72] loss: 0.358\n",
      "[48,    82] loss: 0.357\n",
      "[48,    92] loss: 0.359\n",
      "[48,   102] loss: 0.354\n",
      "[48,   112] loss: 0.346\n",
      "[48,   122] loss: 0.376\n",
      "[48,   132] loss: 0.348\n",
      "[48,   142] loss: 0.366\n",
      "[48,   152] loss: 0.363\n",
      "[48,   162] loss: 0.371\n",
      "[48,   172] loss: 0.374\n",
      "[48,   182] loss: 0.357\n",
      "[48,   192] loss: 0.364\n",
      "[48,   202] loss: 0.378\n",
      "[48,   212] loss: 0.357\n",
      "[48,   222] loss: 0.349\n",
      "[48,   232] loss: 0.350\n",
      "[49,     2] loss: 0.072\n",
      "[49,    12] loss: 0.354\n",
      "[49,    22] loss: 0.355\n",
      "[49,    32] loss: 0.362\n",
      "[49,    42] loss: 0.361\n",
      "[49,    52] loss: 0.349\n",
      "[49,    62] loss: 0.334\n",
      "[49,    72] loss: 0.355\n",
      "[49,    82] loss: 0.364\n",
      "[49,    92] loss: 0.367\n",
      "[49,   102] loss: 0.377\n",
      "[49,   112] loss: 0.340\n",
      "[49,   122] loss: 0.362\n",
      "[49,   132] loss: 0.355\n",
      "[49,   142] loss: 0.351\n",
      "[49,   152] loss: 0.331\n",
      "[49,   162] loss: 0.360\n",
      "[49,   172] loss: 0.350\n",
      "[49,   182] loss: 0.360\n",
      "[49,   192] loss: 0.348\n",
      "[49,   202] loss: 0.365\n",
      "[49,   212] loss: 0.353\n",
      "[49,   222] loss: 0.366\n",
      "[49,   232] loss: 0.343\n",
      "[50,     2] loss: 0.077\n",
      "[50,    12] loss: 0.368\n",
      "[50,    22] loss: 0.368\n",
      "[50,    32] loss: 0.353\n",
      "[50,    42] loss: 0.330\n",
      "[50,    52] loss: 0.371\n",
      "[50,    62] loss: 0.359\n",
      "[50,    72] loss: 0.353\n",
      "[50,    82] loss: 0.357\n",
      "[50,    92] loss: 0.373\n",
      "[50,   102] loss: 0.354\n",
      "[50,   112] loss: 0.342\n",
      "[50,   122] loss: 0.338\n",
      "[50,   132] loss: 0.337\n",
      "[50,   142] loss: 0.347\n",
      "[50,   152] loss: 0.337\n",
      "[50,   162] loss: 0.351\n",
      "[50,   172] loss: 0.361\n",
      "[50,   182] loss: 0.372\n",
      "[50,   192] loss: 0.362\n",
      "[50,   202] loss: 0.371\n",
      "[50,   212] loss: 0.370\n",
      "[50,   222] loss: 0.365\n",
      "[50,   232] loss: 0.350\n",
      "[51,     2] loss: 0.068\n",
      "[51,    12] loss: 0.354\n",
      "[51,    22] loss: 0.360\n",
      "[51,    32] loss: 0.376\n",
      "[51,    42] loss: 0.357\n",
      "[51,    52] loss: 0.331\n",
      "[51,    62] loss: 0.358\n",
      "[51,    72] loss: 0.345\n",
      "[51,    82] loss: 0.346\n",
      "[51,    92] loss: 0.360\n",
      "[51,   102] loss: 0.371\n",
      "[51,   112] loss: 0.357\n",
      "[51,   122] loss: 0.346\n",
      "[51,   132] loss: 0.347\n",
      "[51,   142] loss: 0.351\n",
      "[51,   152] loss: 0.376\n",
      "[51,   162] loss: 0.343\n",
      "[51,   172] loss: 0.351\n",
      "[51,   182] loss: 0.355\n",
      "[51,   192] loss: 0.349\n",
      "[51,   202] loss: 0.372\n",
      "[51,   212] loss: 0.364\n",
      "[51,   222] loss: 0.352\n",
      "[51,   232] loss: 0.358\n",
      "[52,     2] loss: 0.078\n",
      "[52,    12] loss: 0.377\n",
      "[52,    22] loss: 0.362\n",
      "[52,    32] loss: 0.349\n",
      "[52,    42] loss: 0.370\n",
      "[52,    52] loss: 0.342\n",
      "[52,    62] loss: 0.371\n",
      "[52,    72] loss: 0.346\n",
      "[52,    82] loss: 0.340\n",
      "[52,    92] loss: 0.350\n",
      "[52,   102] loss: 0.352\n",
      "[52,   112] loss: 0.351\n",
      "[52,   122] loss: 0.333\n",
      "[52,   132] loss: 0.343\n",
      "[52,   142] loss: 0.350\n",
      "[52,   152] loss: 0.337\n",
      "[52,   162] loss: 0.347\n",
      "[52,   172] loss: 0.337\n",
      "[52,   182] loss: 0.347\n",
      "[52,   192] loss: 0.355\n",
      "[52,   202] loss: 0.342\n",
      "[52,   212] loss: 0.346\n",
      "[52,   222] loss: 0.355\n",
      "[52,   232] loss: 0.362\n",
      "[53,     2] loss: 0.070\n",
      "[53,    12] loss: 0.339\n",
      "[53,    22] loss: 0.360\n",
      "[53,    32] loss: 0.353\n",
      "[53,    42] loss: 0.356\n",
      "[53,    52] loss: 0.327\n",
      "[53,    62] loss: 0.332\n",
      "[53,    72] loss: 0.367\n",
      "[53,    82] loss: 0.362\n",
      "[53,    92] loss: 0.358\n",
      "[53,   102] loss: 0.348\n",
      "[53,   112] loss: 0.342\n",
      "[53,   122] loss: 0.379\n",
      "[53,   132] loss: 0.358\n",
      "[53,   142] loss: 0.392\n",
      "[53,   152] loss: 0.349\n",
      "[53,   162] loss: 0.357\n",
      "[53,   172] loss: 0.356\n",
      "[53,   182] loss: 0.347\n",
      "[53,   192] loss: 0.349\n",
      "[53,   202] loss: 0.349\n",
      "[53,   212] loss: 0.349\n",
      "[53,   222] loss: 0.350\n",
      "[53,   232] loss: 0.346\n",
      "[54,     2] loss: 0.061\n",
      "[54,    12] loss: 0.331\n",
      "[54,    22] loss: 0.346\n",
      "[54,    32] loss: 0.338\n",
      "[54,    42] loss: 0.348\n",
      "[54,    52] loss: 0.335\n",
      "[54,    62] loss: 0.347\n",
      "[54,    72] loss: 0.348\n",
      "[54,    82] loss: 0.381\n",
      "[54,    92] loss: 0.343\n",
      "[54,   102] loss: 0.374\n",
      "[54,   112] loss: 0.379\n",
      "[54,   122] loss: 0.331\n",
      "[54,   132] loss: 0.352\n",
      "[54,   142] loss: 0.354\n",
      "[54,   152] loss: 0.353\n",
      "[54,   162] loss: 0.347\n",
      "[54,   172] loss: 0.344\n",
      "[54,   182] loss: 0.343\n",
      "[54,   192] loss: 0.357\n",
      "[54,   202] loss: 0.361\n",
      "[54,   212] loss: 0.349\n",
      "[54,   222] loss: 0.341\n",
      "[54,   232] loss: 0.342\n",
      "[55,     2] loss: 0.079\n",
      "[55,    12] loss: 0.368\n",
      "[55,    22] loss: 0.367\n",
      "[55,    32] loss: 0.338\n",
      "[55,    42] loss: 0.347\n",
      "[55,    52] loss: 0.340\n",
      "[55,    62] loss: 0.362\n",
      "[55,    72] loss: 0.349\n",
      "[55,    82] loss: 0.355\n",
      "[55,    92] loss: 0.356\n",
      "[55,   102] loss: 0.348\n",
      "[55,   112] loss: 0.349\n",
      "[55,   122] loss: 0.372\n",
      "[55,   132] loss: 0.339\n",
      "[55,   142] loss: 0.353\n",
      "[55,   152] loss: 0.349\n",
      "[55,   162] loss: 0.351\n",
      "[55,   172] loss: 0.346\n",
      "[55,   182] loss: 0.359\n",
      "[55,   192] loss: 0.349\n",
      "[55,   202] loss: 0.345\n",
      "[55,   212] loss: 0.362\n",
      "[55,   222] loss: 0.354\n",
      "[55,   232] loss: 0.356\n",
      "[56,     2] loss: 0.068\n",
      "[56,    12] loss: 0.347\n",
      "[56,    22] loss: 0.355\n",
      "[56,    32] loss: 0.351\n",
      "[56,    42] loss: 0.366\n",
      "[56,    52] loss: 0.345\n",
      "[56,    62] loss: 0.349\n",
      "[56,    72] loss: 0.351\n",
      "[56,    82] loss: 0.372\n",
      "[56,    92] loss: 0.352\n",
      "[56,   102] loss: 0.370\n",
      "[56,   112] loss: 0.376\n",
      "[56,   122] loss: 0.348\n",
      "[56,   132] loss: 0.359\n",
      "[56,   142] loss: 0.366\n",
      "[56,   152] loss: 0.358\n",
      "[56,   162] loss: 0.347\n",
      "[56,   172] loss: 0.342\n",
      "[56,   182] loss: 0.352\n",
      "[56,   192] loss: 0.370\n",
      "[56,   202] loss: 0.343\n",
      "[56,   212] loss: 0.363\n",
      "[56,   222] loss: 0.366\n",
      "[56,   232] loss: 0.327\n",
      "[57,     2] loss: 0.066\n",
      "[57,    12] loss: 0.347\n",
      "[57,    22] loss: 0.377\n",
      "[57,    32] loss: 0.341\n",
      "[57,    42] loss: 0.349\n",
      "[57,    52] loss: 0.334\n",
      "[57,    62] loss: 0.330\n",
      "[57,    72] loss: 0.355\n",
      "[57,    82] loss: 0.357\n",
      "[57,    92] loss: 0.355\n",
      "[57,   102] loss: 0.418\n",
      "[57,   112] loss: 0.357\n",
      "[57,   122] loss: 0.377\n",
      "[57,   132] loss: 0.361\n",
      "[57,   142] loss: 0.362\n",
      "[57,   152] loss: 0.349\n",
      "[57,   162] loss: 0.369\n",
      "[57,   172] loss: 0.367\n",
      "[57,   182] loss: 0.369\n",
      "[57,   192] loss: 0.339\n",
      "[57,   202] loss: 0.356\n",
      "[57,   212] loss: 0.334\n",
      "[57,   222] loss: 0.332\n",
      "[57,   232] loss: 0.335\n",
      "[58,     2] loss: 0.066\n",
      "[58,    12] loss: 0.373\n",
      "[58,    22] loss: 0.357\n",
      "[58,    32] loss: 0.330\n",
      "[58,    42] loss: 0.338\n",
      "[58,    52] loss: 0.339\n",
      "[58,    62] loss: 0.358\n",
      "[58,    72] loss: 0.343\n",
      "[58,    82] loss: 0.338\n",
      "[58,    92] loss: 0.345\n",
      "[58,   102] loss: 0.360\n",
      "[58,   112] loss: 0.351\n",
      "[58,   122] loss: 0.347\n",
      "[58,   132] loss: 0.344\n",
      "[58,   142] loss: 0.338\n",
      "[58,   152] loss: 0.345\n",
      "[58,   162] loss: 0.359\n",
      "[58,   172] loss: 0.335\n",
      "[58,   182] loss: 0.332\n",
      "[58,   192] loss: 0.351\n",
      "[58,   202] loss: 0.350\n",
      "[58,   212] loss: 0.334\n",
      "[58,   222] loss: 0.343\n",
      "[58,   232] loss: 0.331\n",
      "[59,     2] loss: 0.065\n",
      "[59,    12] loss: 0.350\n",
      "[59,    22] loss: 0.344\n",
      "[59,    32] loss: 0.336\n",
      "[59,    42] loss: 0.364\n",
      "[59,    52] loss: 0.349\n",
      "[59,    62] loss: 0.381\n",
      "[59,    72] loss: 0.351\n",
      "[59,    82] loss: 0.337\n",
      "[59,    92] loss: 0.338\n",
      "[59,   102] loss: 0.350\n",
      "[59,   112] loss: 0.352\n",
      "[59,   122] loss: 0.348\n",
      "[59,   132] loss: 0.356\n",
      "[59,   142] loss: 0.341\n",
      "[59,   152] loss: 0.343\n",
      "[59,   162] loss: 0.347\n",
      "[59,   172] loss: 0.343\n",
      "[59,   182] loss: 0.368\n",
      "[59,   192] loss: 0.359\n",
      "[59,   202] loss: 0.342\n",
      "[59,   212] loss: 0.343\n",
      "[59,   222] loss: 0.339\n",
      "[59,   232] loss: 0.362\n",
      "[60,     2] loss: 0.071\n",
      "[60,    12] loss: 0.388\n",
      "[60,    22] loss: 0.330\n",
      "[60,    32] loss: 0.340\n",
      "[60,    42] loss: 0.336\n",
      "[60,    52] loss: 0.356\n",
      "[60,    62] loss: 0.341\n",
      "[60,    72] loss: 0.341\n",
      "[60,    82] loss: 0.327\n",
      "[60,    92] loss: 0.332\n",
      "[60,   102] loss: 0.335\n",
      "[60,   112] loss: 0.326\n",
      "[60,   122] loss: 0.347\n",
      "[60,   132] loss: 0.362\n",
      "[60,   142] loss: 0.355\n",
      "[60,   152] loss: 0.348\n",
      "[60,   162] loss: 0.337\n",
      "[60,   172] loss: 0.349\n",
      "[60,   182] loss: 0.346\n",
      "[60,   192] loss: 0.359\n",
      "[60,   202] loss: 0.364\n",
      "[60,   212] loss: 0.317\n",
      "[60,   222] loss: 0.340\n",
      "[60,   232] loss: 0.333\n",
      "[61,     2] loss: 0.076\n",
      "[61,    12] loss: 0.344\n",
      "[61,    22] loss: 0.336\n",
      "[61,    32] loss: 0.338\n",
      "[61,    42] loss: 0.338\n",
      "[61,    52] loss: 0.345\n",
      "[61,    62] loss: 0.353\n",
      "[61,    72] loss: 0.345\n",
      "[61,    82] loss: 0.349\n",
      "[61,    92] loss: 0.350\n",
      "[61,   102] loss: 0.336\n",
      "[61,   112] loss: 0.359\n",
      "[61,   122] loss: 0.347\n",
      "[61,   132] loss: 0.348\n",
      "[61,   142] loss: 0.353\n",
      "[61,   152] loss: 0.355\n",
      "[61,   162] loss: 0.349\n",
      "[61,   172] loss: 0.346\n",
      "[61,   182] loss: 0.350\n",
      "[61,   192] loss: 0.343\n",
      "[61,   202] loss: 0.332\n",
      "[61,   212] loss: 0.364\n",
      "[61,   222] loss: 0.357\n",
      "[61,   232] loss: 0.342\n",
      "[62,     2] loss: 0.067\n",
      "[62,    12] loss: 0.348\n",
      "[62,    22] loss: 0.349\n",
      "[62,    32] loss: 0.349\n",
      "[62,    42] loss: 0.333\n",
      "[62,    52] loss: 0.353\n",
      "[62,    62] loss: 0.348\n",
      "[62,    72] loss: 0.353\n",
      "[62,    82] loss: 0.335\n",
      "[62,    92] loss: 0.355\n",
      "[62,   102] loss: 0.350\n",
      "[62,   112] loss: 0.349\n",
      "[62,   122] loss: 0.336\n",
      "[62,   132] loss: 0.325\n",
      "[62,   142] loss: 0.342\n",
      "[62,   152] loss: 0.364\n",
      "[62,   162] loss: 0.345\n",
      "[62,   172] loss: 0.328\n",
      "[62,   182] loss: 0.346\n",
      "[62,   192] loss: 0.332\n",
      "[62,   202] loss: 0.352\n",
      "[62,   212] loss: 0.349\n",
      "[62,   222] loss: 0.341\n",
      "[62,   232] loss: 0.366\n",
      "[63,     2] loss: 0.069\n",
      "[63,    12] loss: 0.342\n",
      "[63,    22] loss: 0.342\n",
      "[63,    32] loss: 0.337\n",
      "[63,    42] loss: 0.351\n",
      "[63,    52] loss: 0.339\n",
      "[63,    62] loss: 0.322\n",
      "[63,    72] loss: 0.348\n",
      "[63,    82] loss: 0.346\n",
      "[63,    92] loss: 0.334\n",
      "[63,   102] loss: 0.378\n",
      "[63,   112] loss: 0.346\n",
      "[63,   122] loss: 0.348\n",
      "[63,   132] loss: 0.328\n",
      "[63,   142] loss: 0.352\n",
      "[63,   152] loss: 0.338\n",
      "[63,   162] loss: 0.336\n",
      "[63,   172] loss: 0.336\n",
      "[63,   182] loss: 0.329\n",
      "[63,   192] loss: 0.345\n",
      "[63,   202] loss: 0.346\n",
      "[63,   212] loss: 0.341\n",
      "[63,   222] loss: 0.361\n",
      "[63,   232] loss: 0.347\n",
      "[64,     2] loss: 0.060\n",
      "[64,    12] loss: 0.340\n",
      "[64,    22] loss: 0.358\n",
      "[64,    32] loss: 0.365\n",
      "[64,    42] loss: 0.336\n",
      "[64,    52] loss: 0.342\n",
      "[64,    62] loss: 0.335\n",
      "[64,    72] loss: 0.339\n",
      "[64,    82] loss: 0.336\n",
      "[64,    92] loss: 0.340\n",
      "[64,   102] loss: 0.349\n",
      "[64,   112] loss: 0.337\n",
      "[64,   122] loss: 0.343\n",
      "[64,   132] loss: 0.330\n",
      "[64,   142] loss: 0.343\n",
      "[64,   152] loss: 0.346\n",
      "[64,   162] loss: 0.332\n",
      "[64,   172] loss: 0.349\n",
      "[64,   182] loss: 0.352\n",
      "[64,   192] loss: 0.345\n",
      "[64,   202] loss: 0.338\n",
      "[64,   212] loss: 0.351\n",
      "[64,   222] loss: 0.348\n",
      "[64,   232] loss: 0.349\n",
      "[65,     2] loss: 0.072\n",
      "[65,    12] loss: 0.367\n",
      "[65,    22] loss: 0.341\n",
      "[65,    32] loss: 0.345\n",
      "[65,    42] loss: 0.342\n",
      "[65,    52] loss: 0.359\n",
      "[65,    62] loss: 0.348\n",
      "[65,    72] loss: 0.337\n",
      "[65,    82] loss: 0.345\n",
      "[65,    92] loss: 0.346\n",
      "[65,   102] loss: 0.341\n",
      "[65,   112] loss: 0.352\n",
      "[65,   122] loss: 0.350\n",
      "[65,   132] loss: 0.336\n",
      "[65,   142] loss: 0.363\n",
      "[65,   152] loss: 0.323\n",
      "[65,   162] loss: 0.345\n",
      "[65,   172] loss: 0.335\n",
      "[65,   182] loss: 0.349\n",
      "[65,   192] loss: 0.346\n",
      "[65,   202] loss: 0.343\n",
      "[65,   212] loss: 0.378\n",
      "[65,   222] loss: 0.354\n",
      "[65,   232] loss: 0.327\n",
      "[66,     2] loss: 0.064\n",
      "[66,    12] loss: 0.342\n",
      "[66,    22] loss: 0.355\n",
      "[66,    32] loss: 0.319\n",
      "[66,    42] loss: 0.352\n",
      "[66,    52] loss: 0.330\n",
      "[66,    62] loss: 0.342\n",
      "[66,    72] loss: 0.336\n",
      "[66,    82] loss: 0.334\n",
      "[66,    92] loss: 0.341\n",
      "[66,   102] loss: 0.351\n",
      "[66,   112] loss: 0.358\n",
      "[66,   122] loss: 0.340\n",
      "[66,   132] loss: 0.314\n",
      "[66,   142] loss: 0.350\n",
      "[66,   152] loss: 0.320\n",
      "[66,   162] loss: 0.341\n",
      "[66,   172] loss: 0.344\n",
      "[66,   182] loss: 0.333\n",
      "[66,   192] loss: 0.340\n",
      "[66,   202] loss: 0.339\n",
      "[66,   212] loss: 0.335\n",
      "[66,   222] loss: 0.343\n",
      "[66,   232] loss: 0.353\n",
      "[67,     2] loss: 0.066\n",
      "[67,    12] loss: 0.338\n",
      "[67,    22] loss: 0.333\n",
      "[67,    32] loss: 0.344\n",
      "[67,    42] loss: 0.331\n",
      "[67,    52] loss: 0.328\n",
      "[67,    62] loss: 0.331\n",
      "[67,    72] loss: 0.355\n",
      "[67,    82] loss: 0.340\n",
      "[67,    92] loss: 0.343\n",
      "[67,   102] loss: 0.338\n",
      "[67,   112] loss: 0.354\n",
      "[67,   122] loss: 0.334\n",
      "[67,   132] loss: 0.336\n",
      "[67,   142] loss: 0.352\n",
      "[67,   152] loss: 0.337\n",
      "[67,   162] loss: 0.344\n",
      "[67,   172] loss: 0.344\n",
      "[67,   182] loss: 0.349\n",
      "[67,   192] loss: 0.338\n",
      "[67,   202] loss: 0.357\n",
      "[67,   212] loss: 0.339\n",
      "[67,   222] loss: 0.339\n",
      "[67,   232] loss: 0.349\n",
      "[68,     2] loss: 0.065\n",
      "[68,    12] loss: 0.355\n",
      "[68,    22] loss: 0.353\n",
      "[68,    32] loss: 0.374\n",
      "[68,    42] loss: 0.345\n",
      "[68,    52] loss: 0.335\n",
      "[68,    62] loss: 0.334\n",
      "[68,    72] loss: 0.357\n",
      "[68,    82] loss: 0.337\n",
      "[68,    92] loss: 0.341\n",
      "[68,   102] loss: 0.332\n",
      "[68,   112] loss: 0.363\n",
      "[68,   122] loss: 0.344\n",
      "[68,   132] loss: 0.353\n",
      "[68,   142] loss: 0.336\n",
      "[68,   152] loss: 0.347\n",
      "[68,   162] loss: 0.349\n",
      "[68,   172] loss: 0.314\n",
      "[68,   182] loss: 0.328\n",
      "[68,   192] loss: 0.335\n",
      "[68,   202] loss: 0.324\n",
      "[68,   212] loss: 0.320\n",
      "[68,   222] loss: 0.343\n",
      "[68,   232] loss: 0.328\n",
      "[69,     2] loss: 0.072\n",
      "[69,    12] loss: 0.347\n",
      "[69,    22] loss: 0.343\n",
      "[69,    32] loss: 0.337\n",
      "[69,    42] loss: 0.319\n",
      "[69,    52] loss: 0.330\n",
      "[69,    62] loss: 0.353\n",
      "[69,    72] loss: 0.340\n",
      "[69,    82] loss: 0.340\n",
      "[69,    92] loss: 0.330\n",
      "[69,   102] loss: 0.345\n",
      "[69,   112] loss: 0.339\n",
      "[69,   122] loss: 0.337\n",
      "[69,   132] loss: 0.334\n",
      "[69,   142] loss: 0.344\n",
      "[69,   152] loss: 0.338\n",
      "[69,   162] loss: 0.345\n",
      "[69,   172] loss: 0.340\n",
      "[69,   182] loss: 0.330\n",
      "[69,   192] loss: 0.335\n",
      "[69,   202] loss: 0.364\n",
      "[69,   212] loss: 0.332\n",
      "[69,   222] loss: 0.349\n",
      "[69,   232] loss: 0.324\n",
      "[70,     2] loss: 0.077\n",
      "[70,    12] loss: 0.335\n",
      "[70,    22] loss: 0.350\n",
      "[70,    32] loss: 0.324\n",
      "[70,    42] loss: 0.340\n",
      "[70,    52] loss: 0.332\n",
      "[70,    62] loss: 0.333\n",
      "[70,    72] loss: 0.340\n",
      "[70,    82] loss: 0.332\n",
      "[70,    92] loss: 0.331\n",
      "[70,   102] loss: 0.323\n",
      "[70,   112] loss: 0.331\n",
      "[70,   122] loss: 0.334\n",
      "[70,   132] loss: 0.337\n",
      "[70,   142] loss: 0.342\n",
      "[70,   152] loss: 0.316\n",
      "[70,   162] loss: 0.360\n",
      "[70,   172] loss: 0.331\n",
      "[70,   182] loss: 0.344\n",
      "[70,   192] loss: 0.342\n",
      "[70,   202] loss: 0.359\n",
      "[70,   212] loss: 0.340\n",
      "[70,   222] loss: 0.309\n",
      "[70,   232] loss: 0.332\n",
      "[71,     2] loss: 0.072\n",
      "[71,    12] loss: 0.355\n",
      "[71,    22] loss: 0.338\n",
      "[71,    32] loss: 0.349\n",
      "[71,    42] loss: 0.347\n",
      "[71,    52] loss: 0.355\n",
      "[71,    62] loss: 0.328\n",
      "[71,    72] loss: 0.321\n",
      "[71,    82] loss: 0.346\n",
      "[71,    92] loss: 0.341\n",
      "[71,   102] loss: 0.349\n",
      "[71,   112] loss: 0.340\n",
      "[71,   122] loss: 0.345\n",
      "[71,   132] loss: 0.341\n",
      "[71,   142] loss: 0.322\n",
      "[71,   152] loss: 0.341\n",
      "[71,   162] loss: 0.333\n",
      "[71,   172] loss: 0.372\n",
      "[71,   182] loss: 0.355\n",
      "[71,   192] loss: 0.360\n",
      "[71,   202] loss: 0.331\n",
      "[71,   212] loss: 0.346\n",
      "[71,   222] loss: 0.339\n",
      "[71,   232] loss: 0.341\n",
      "[72,     2] loss: 0.069\n",
      "[72,    12] loss: 0.339\n",
      "[72,    22] loss: 0.333\n",
      "[72,    32] loss: 0.339\n",
      "[72,    42] loss: 0.325\n",
      "[72,    52] loss: 0.326\n",
      "[72,    62] loss: 0.322\n",
      "[72,    72] loss: 0.339\n",
      "[72,    82] loss: 0.338\n",
      "[72,    92] loss: 0.362\n",
      "[72,   102] loss: 0.342\n",
      "[72,   112] loss: 0.335\n",
      "[72,   122] loss: 0.338\n",
      "[72,   132] loss: 0.363\n",
      "[72,   142] loss: 0.350\n",
      "[72,   152] loss: 0.336\n",
      "[72,   162] loss: 0.316\n",
      "[72,   172] loss: 0.338\n",
      "[72,   182] loss: 0.333\n",
      "[72,   192] loss: 0.333\n",
      "[72,   202] loss: 0.343\n",
      "[72,   212] loss: 0.323\n",
      "[72,   222] loss: 0.351\n",
      "[72,   232] loss: 0.306\n",
      "[73,     2] loss: 0.065\n",
      "[73,    12] loss: 0.338\n",
      "[73,    22] loss: 0.339\n",
      "[73,    32] loss: 0.351\n",
      "[73,    42] loss: 0.353\n",
      "[73,    52] loss: 0.329\n",
      "[73,    62] loss: 0.319\n",
      "[73,    72] loss: 0.331\n",
      "[73,    82] loss: 0.359\n",
      "[73,    92] loss: 0.341\n",
      "[73,   102] loss: 0.351\n",
      "[73,   112] loss: 0.349\n",
      "[73,   122] loss: 0.335\n",
      "[73,   132] loss: 0.347\n",
      "[73,   142] loss: 0.350\n",
      "[73,   152] loss: 0.320\n",
      "[73,   162] loss: 0.334\n",
      "[73,   172] loss: 0.352\n",
      "[73,   182] loss: 0.325\n",
      "[73,   192] loss: 0.339\n",
      "[73,   202] loss: 0.317\n",
      "[73,   212] loss: 0.339\n",
      "[73,   222] loss: 0.342\n",
      "[73,   232] loss: 0.322\n",
      "[74,     2] loss: 0.067\n",
      "[74,    12] loss: 0.330\n",
      "[74,    22] loss: 0.336\n",
      "[74,    32] loss: 0.335\n",
      "[74,    42] loss: 0.347\n",
      "[74,    52] loss: 0.333\n",
      "[74,    62] loss: 0.345\n",
      "[74,    72] loss: 0.349\n",
      "[74,    82] loss: 0.354\n",
      "[74,    92] loss: 0.333\n",
      "[74,   102] loss: 0.361\n",
      "[74,   112] loss: 0.327\n",
      "[74,   122] loss: 0.324\n",
      "[74,   132] loss: 0.340\n",
      "[74,   142] loss: 0.342\n",
      "[74,   152] loss: 0.343\n",
      "[74,   162] loss: 0.329\n",
      "[74,   172] loss: 0.346\n",
      "[74,   182] loss: 0.334\n",
      "[74,   192] loss: 0.340\n",
      "[74,   202] loss: 0.357\n",
      "[74,   212] loss: 0.351\n",
      "[74,   222] loss: 0.331\n",
      "[74,   232] loss: 0.342\n",
      "[75,     2] loss: 0.062\n",
      "[75,    12] loss: 0.332\n",
      "[75,    22] loss: 0.316\n",
      "[75,    32] loss: 0.335\n",
      "[75,    42] loss: 0.323\n",
      "[75,    52] loss: 0.324\n",
      "[75,    62] loss: 0.316\n",
      "[75,    72] loss: 0.328\n",
      "[75,    82] loss: 0.331\n",
      "[75,    92] loss: 0.316\n",
      "[75,   102] loss: 0.350\n",
      "[75,   112] loss: 0.350\n",
      "[75,   122] loss: 0.335\n",
      "[75,   132] loss: 0.348\n",
      "[75,   142] loss: 0.313\n",
      "[75,   152] loss: 0.340\n",
      "[75,   162] loss: 0.345\n",
      "[75,   172] loss: 0.330\n",
      "[75,   182] loss: 0.330\n",
      "[75,   192] loss: 0.331\n",
      "[75,   202] loss: 0.332\n",
      "[75,   212] loss: 0.345\n",
      "[75,   222] loss: 0.342\n",
      "[75,   232] loss: 0.342\n",
      "Finished Training\n",
      "time: 19.814422845840454\n",
      "gpu memory: 0.20513534545898438\n",
      "gpu memory: 0.20513534545898438\n",
      "cell number 40000\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "cell_num = [1000,5000,10000,20000,30000,40000,50000,60000,70000,80000,90000,100000]\n",
    "cell_num_mesured = []\n",
    "time_list = []\n",
    "memory_list = []\n",
    "for i in cell_num:\n",
    "    print(\"cell number\",i)\n",
    "    print(torch.cuda.memory_allocated())\n",
    "    _,_,time_elapsed,memory = train_and_measure_cor_with_change(cells=i)\n",
    "    time_list.append(time_elapsed)\n",
    "    memory_list.append(memory)\n",
    "gene_num = [1000,5000,10000,20000,30000,40000]\n",
    "time_list_gene = []\n",
    "memory_list_gene = []\n",
    "for i in gene_num:\n",
    "    print(i)\n",
    "    _,_,time_elapsed,memory = train_and_measure_cor_with_change(genes=i)\n",
    "    time_list_gene.append(time_elapsed)\n",
    "    memory_list_gene.append(memory)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-07-07T11:59:58.950262385Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 18,\n",
    "                     'xtick.labelsize' : 18,\n",
    "                     'ytick.labelsize' : 18})\n",
    "\n",
    "plt.plot(cell_num[0:len(time_list)],time_list,marker='o')\n",
    "plt.xlabel('Number of cells')\n",
    "plt.ylabel('Time')\n",
    "plt.title('Time vs Number of cells')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.ylim(0, max(time_list)+10)\n",
    "plt.savefig('figures/time_vs_cells_1.png',dpi=600)\n",
    "print(\"time_list\",time_list)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(gene_num[0:len(time_list_gene)],time_list_gene,marker='o')\n",
    "plt.xlabel('Number of genes')\n",
    "plt.ylabel('Time')\n",
    "plt.title('Time vs Number of cells')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.ylim(0, max(time_list_gene)+40)\n",
    "plt.savefig('figures/time_vs_genes_2.png',dpi=600)\n",
    "print(\"time_list_gene\",time_list_gene)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(cell_num,memory_list,marker='o')\n",
    "plt.xlabel('Number of cells')\n",
    "plt.ylabel('Memory')\n",
    "plt.title('Memory vs Number of cells')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.ylim(0, max(memory_list)+0.2)\n",
    "plt.savefig('figures/memory_vs_cells_3.png',dpi=600)\n",
    "print(\"memory_list\",memory_list)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(gene_num[0:len(memory_list_gene)],memory_list_gene,marker='o')\n",
    "plt.xlabel('Number of genes')\n",
    "plt.ylabel('Memory')\n",
    "plt.title('Memory vs Number of genes')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.ylim(0, max(memory_list_gene)+2)\n",
    "plt.savefig('figures/memory_vs_genes_4.png',dpi=600)\n",
    "print(\"memory_list_gene\",memory_list_gene)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the current device index\n",
    "    current_device = torch.cuda.current_device()\n",
    "\n",
    "    # Get the name of the current device\n",
    "    device_name = torch.cuda.get_device_name(current_device)\n",
    "\n",
    "    print(f\"Current GPU device index: {current_device}\")\n",
    "    print(f\"Current GPU device name: {device_name}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Running on CPU.\")\n",
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the current device index\n",
    "    current_device = torch.cuda.current_device()\n",
    "\n",
    "    # Get the name of the current device\n",
    "    device_name = torch.cuda.get_device_name(current_device)\n",
    "\n",
    "    print(f\"Current GPU device index: {current_device}\")\n",
    "    print(f\"Current GPU device name: {device_name}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Running on CPU.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cell_num[0:len(time_list)]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "# Load a sample dataset\n",
    "adata = sc.datasets.pbmc3k()\n",
    "\n",
    "# Preprocessing: Filtering, normalization, and log transformation\n",
    "sc.pp.filter_cells(adata, min_genes=200)\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "adata.var['mt'] = adata.var_names.str.startswith('MT-')\n",
    "sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n",
    "adata = adata[adata.obs.n_genes_by_counts < 2500, :]\n",
    "adata = adata[adata.obs.pct_counts_mt < 5, :]\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "# Highly variable genes and scaling\n",
    "sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "adata = adata[:, adata.var.highly_variable]\n",
    "sc.pp.scale(adata, max_value=10)\n",
    "\n",
    "# PCA\n",
    "sc.tl.pca(adata, svd_solver='arpack')\n",
    "\n",
    "# Compute the neighborhood graph\n",
    "sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)\n",
    "\n",
    "# Clustering using Leiden and Louvain methods\n",
    "sc.tl.leiden(adata)\n",
    "sc.tl.louvain(adata)\n",
    "\n",
    "# Run PAGA\n",
    "sc.tl.paga(adata, groups='leiden')\n",
    "\n",
    "# Plot PAGA graph\n",
    "sc.pl.paga(adata, plot=True)\n",
    "\n",
    "# Compute and plot UMAP with PAGA initialization\n",
    "sc.tl.umap(adata, init_pos='paga')\n",
    "sc.pl.umap(adata, color=['leiden', 'louvain', 'CST3', 'NKG7'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
